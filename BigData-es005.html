
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Frameworks y aplicaciones &#8212; Curso Introducción a Big Data</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'BigData-es005';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Tutorial Apache Hadoop" href="BigData-es005Hadoop.html" />
    <link rel="prev" title="Tutorial MongoDB" href="BigData-es004MongoDB.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Curso Introducción a Big Data - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Curso Introducción a Big Data - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Introducción a Big Data
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="BigData-es001.html">Definición y características</a></li>
<li class="toctree-l1"><a class="reference internal" href="BigData-es002.html">Ingesta y almacenamiento de datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="BigData-es003.html">Bases de datos para Big Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="BigData-es004.html">Consulta y visualización de datos</a></li>

<li class="toctree-l1"><a class="reference internal" href="BigData-es004MongoDB.html">Tutorial MongoDB</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Frameworks y aplicaciones</a></li>
<li class="toctree-l1"><a class="reference internal" href="BigData-es005Hadoop.html">Tutorial Apache Hadoop</a></li>
<li class="toctree-l1"><a class="reference internal" href="BigData-es005Kafka.html">Tutorial Apache Kafka</a></li>
<li class="toctree-l1"><a class="reference internal" href="BigData-es007.html">Big Data Science</a></li>
<li class="toctree-l1"><a class="reference internal" href="BigData-es008.html">Big Data stacks y Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="BigData-es008sparkMLlib.html">Tutorial Spark</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/fortinux/bigdata-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/fortinux/bigdata-book/issues/new?title=Issue%20on%20page%20%2FBigData-es005.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/BigData-es005.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Frameworks y aplicaciones</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#aplicaciones-para-big-data">Aplicaciones para Big Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hadoop">Hadoop</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modulos-de-apache-hadoop">Módulos de Apache Hadoop</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-hadoop-yarn">Apache Hadoop YARN</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-de-procesamiento-dag">Modelo de procesamiento DAG</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-hadoop-mapreduce">Apache Hadoop MapReduce</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sistema-de-ficheros-hdfs">Sistema de ficheros HDFS</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#caracteristicas-de-hdfs">Características de HDFS</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#proyectos-relacionados-con-apache-hadoop">Proyectos relacionados con Apache Hadoop</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tutorial-apache-hadoop">Tutorial Apache Hadoop</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-spark">Apache Spark</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#caracteristicas-de-apache-spark">Características de Apache Spark</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#casos-de-uso-de-spark">Casos de uso de Spark</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-storm">Apache Storm</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#caracteristicas-de-apache-storm">Características de Apache Storm</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#storm-vs-spark">Storm vs. Spark</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-kafka">Apache Kafka</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#caracteristicas-de-apache-kafka">Características de Apache Kafka</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#transmision-de-eventos">Transmisión de eventos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#procesos-de-apache-kafka">Procesos de Apache Kafka</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tutorial-apache-kafka">Tutorial Apache Kafka</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="frameworks-y-aplicaciones">
<h1>Frameworks y aplicaciones<a class="headerlink" href="#frameworks-y-aplicaciones" title="Link to this heading">#</a></h1>
<section id="aplicaciones-para-big-data">
<h2>Aplicaciones para Big Data<a class="headerlink" href="#aplicaciones-para-big-data" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Hadoop: HDFS, YARN &amp; MapReduce.</p></li>
<li><p>Apache Spark.</p></li>
<li><p>Apache Storm.</p></li>
<li><p>Apache Kafka.</p></li>
</ul>
</section>
<section id="hadoop">
<h2>Hadoop<a class="headerlink" href="#hadoop" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>El proyecto Apache™ Hadoop® desarrolla software de código abierto para computación distribuida, escalable y confiable.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://hadoop.apache.org/">https://hadoop.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Es un framework para el procesamiento distribuido de grandes conjuntos de datos en grupos de computadoras que utilizan modelos de programación simples.</p></li>
<li><p>Diseñado para escalar desde servidores individuales a miles de máquinas, cada una de las cuales ofrece computación y almacenamiento locales.</p></li>
</ul>
<ul class="simple">
<li><p>En lugar de depender del hardware para brindar alta disponibilidad, la biblioteca en sí está diseñada para detectar y manejar fallas en la capa de la aplicación, por lo que brinda un servicio de alta disponibilidad sobre un grupo de computadoras, cada una de las cuales puede ser propensa a fallas.</p></li>
</ul>
</section>
<section id="modulos-de-apache-hadoop">
<h2>Módulos de Apache Hadoop<a class="headerlink" href="#modulos-de-apache-hadoop" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Apache Hadoop cuenta con una serie de módulos que le permiten extender sus funcionalidades.</p></li>
<li><p>Los más utilizados son <em>Hadoop Common, HDFS, YARN y MapReduce</em>.</p></li>
</ul>
<ul class="simple">
<li><p>Hadoop Common:</p>
<ul>
<li><p>Las <em>common utilities</em> que soportan los otros módulos de Hadoop.</p></li>
</ul>
</li>
<li><p>Hadoop Distributed File System (HDFS™):</p>
<ul>
<li><p>Un sistema de archivos distribuido que proporciona acceso de alto rendimiento a los datos de la aplicación.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Hadoop YARN</p>
<ul>
<li><p>Un framework para <em>job scheduling</em> y gestión de recursos de los clústeres.</p></li>
<li><p>Tecnología de gestión de clústeres en Hadoop de segunda generación.</p></li>
<li><p>Extraído de: <a class="reference external" href="https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html">https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>MapReduce</p>
<ul>
<li><p>Un sistema basado en YARN para el procesamiento en paralelo de grandes volúmenes de datos.</p></li>
<li><p>Este framework procesa cantidades masivas de datos no estructurados en paralelo en un clúster distribuido.</p></li>
<li><p>Extraído de: <a class="reference external" href="https://hadoop.apache.org/docs/r1.2.1/mapred_tutorial.html">https://hadoop.apache.org/docs/r1.2.1/mapred_tutorial.html</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="apache-hadoop-yarn">
<h2>Apache Hadoop YARN<a class="headerlink" href="#apache-hadoop-yarn" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Tecnología de gestión de clústeres en Hadoop de segunda generación.</p></li>
<li><p>La idea de YARN es dividir las funcionalidades de gestión de recursos y programación/supervisión de trabajos en demonios separados:</p>
<ul>
<li><p>Un <em>ResourceManager (RM)</em> global.</p></li>
<li><p>Un <em>ApplicationMaster (AM)</em> por aplicación.</p></li>
</ul>
</li>
<li><p>Una aplicación es un solo trabajo o un DAG de trabajos.</p></li>
</ul>
<ul class="simple">
<li><p>El <em>ResourceManager</em> y el <em>NodeManager</em> forman el framework de cálculo de datos.</p></li>
<li><p>El <em>ResourceManager</em> arbitra los recursos entre todas las aplicaciones del sistema.</p></li>
<li><p>El <em>NodeManager</em> es el agente del framework por máquina que es responsable de los contenedores, monitorea el uso de sus recursos (CPU, memoria, disco, red) e informa al <em>ResourceManager / Scheduler</em>.</p></li>
</ul>
<ul class="simple">
<li><p>La aplicación <em>ApplicationMaster</em> es en efecto una biblioteca específica del framework y tiene la tarea de negociar recursos del <em>ResourceManager</em> y trabajar con los <em>NodeManagers</em> para ejecutar y monitorear las tareas.</p></li>
</ul>
<ul class="simple">
<li><p>Fuente: <a class="reference external" href="https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html">https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html</a></p></li>
</ul>
</section>
<section id="modelo-de-procesamiento-dag">
<h2>Modelo de procesamiento DAG<a class="headerlink" href="#modelo-de-procesamiento-dag" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Un modelo de procesamiento DAG (gráfico acíclico dirigido - <em>directed acyclic graph</em>) representa las dependencias entre tareas en un flujo de trabajo o canalización.</p></li>
<li><p>Éstas se representan como nodos en un DAG, donde los bordes representan las dependencias entre tareas que solamente se puede ejecutar una vez que se hayan completado todas sus dependencias.</p></li>
</ul>
<ul class="simple">
<li><p>Apache Spark, Apache Flink y Apache Beam implementan su modelo de procesamiento como un DAG mientras que Apache Airflow o Dagster <a class="reference external" href="https://dagster.io/">https://dagster.io/</a> son motores de orquestación que utilizan DAGa para definir tareas y dependencias en los trabajo a realizar.</p></li>
</ul>
<ul class="simple">
<li><p>Fuente: <a class="reference external" href="https://www.hopsworks.ai/dictionary/dag-processing-model">https://www.hopsworks.ai/dictionary/dag-processing-model</a>.</p></li>
</ul>
</section>
<section id="apache-hadoop-mapreduce">
<h2>Apache Hadoop MapReduce<a class="headerlink" href="#apache-hadoop-mapreduce" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Es un framework de software para escribir fácilmente aplicaciones que procesan grandes cantidades de datos (conjuntos de datos de varios <em>terabytes</em>) en paralelo en grandes clústeres (miles de nodos) de hardware básico de manera confiable y tolerante a fallas.</p></li>
</ul>
<p>Fuente: <span id="id1">[<a class="reference internal" href="intro.html#id5" title="Garry. Turkington. Hadoop Beginner's Guide. Packt Publishing, 2013.">Tur13</a>]</span></p>
<ul class="simple">
<li><p>Consta de un único <em>ResourceManager</em> maestro, un <em>NodeManager</em> trabajador por nodo de clúster y <em>MRAppMaster</em> por aplicación.</p></li>
<li><p>Las aplicaciones especifican las ubicaciones de entrada/salida y el mapa de suministro y reducen las funciones a través de implementaciones de interfaces apropiadas y/o clases abstractas.</p></li>
<li><p>Estos y otros parámetros del trabajo comprenden la configuración del trabajo.</p></li>
</ul>
<ul class="simple">
<li><p>El cliente de trabajo de Hadoop luego envía el trabajo (jar/ejecutable, etc.) y la configuración al <em>ResourceManager</em>, que entonces asume la responsabilidad de distribuir el software/configuración a los trabajadores, programar tareas y monitorearlas, proporcionando estado e información de diagnóstico al trabajo-cliente.</p></li>
</ul>
<ul class="simple">
<li><p>Las aplicaciones de <em>MapReduce</em> no necesitan estar escritas en Java.</p></li>
<li><p>Hadoop <em>Streaming</em> es una utilidad que permite a los usuarios crear y ejecutar trabajos con cualquier ejecutable (por ejemplo, utilidades de shell) como mapeador y/o reductor.</p></li>
<li><p>Hadoop <em>Pipes</em> es una API C++ compatible con SWIG para implementar aplicaciones <em>MapReduce</em> (no basadas en JNI™).</p></li>
</ul>
<ul class="simple">
<li><p>Entradas y salidas:</p></li>
<li><p>El framework <em>MapReduce</em> opera exclusivamente en pares &lt;clave, valor&gt;, es decir, el framework ve la entrada del trabajo como un conjunto de pares &lt;clave, valor&gt; y produce un conjunto de pares &lt;clave, valor&gt; como la salida de el trabajo, posiblemente de diferentes tipos.</p></li>
</ul>
<ul>
<li><p>Tipos de entradas y salidas de un <em>MapReduce job</em>:</p>
<p><code class="docutils literal notranslate"><span class="pre">(input)</span> <span class="pre">&lt;k1,</span> <span class="pre">v1&gt;</span> <span class="pre">-&gt;</span> <span class="pre">map</span> <span class="pre">-&gt;</span> <span class="pre">&lt;k2,</span> <span class="pre">v2&gt;</span> <span class="pre">-&gt;</span> <span class="pre">combine</span> <span class="pre">-&gt;</span> <span class="pre">&lt;k2,</span> <span class="pre">v2&gt;</span> <span class="pre">-&gt;</span> <span class="pre">reduce</span> <span class="pre">-&gt;</span> <span class="pre">&lt;k3,</span> <span class="pre">v3&gt;</span> <span class="pre">(output)</span></code></p>
</li>
</ul>
</section>
<section id="sistema-de-ficheros-hdfs">
<h2>Sistema de ficheros HDFS<a class="headerlink" href="#sistema-de-ficheros-hdfs" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>HDFS es un sistema de ficheros basado en Java que provee almacenamiento confiable y escalable.</p></li>
<li><p>Fue diseñado para abarcar grandes grupos de servidores básicos (<em>commodity servers</em>).</p></li>
<li><p>HDFS contiene una gran cantidad de datos y proporciona un acceso a los mismos de manera sencilla y fácil.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html">https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>HDFS proporciona acceso de alto rendimiento a los datos de la aplicación y es adecuado para aplicaciones que tienen grandes conjuntos de datos.</p></li>
<li><p>HDFS relaja algunos requisitos de POSIX para permitir el acceso de transmisión a los datos del sistema de archivos.</p></li>
<li><p>HDFS se creó originalmente como infraestructura para el proyecto de motor de búsqueda web Apache Nutch.</p></li>
</ul>
<ul class="simple">
<li><p>Supuestos y objetivos de HDFS:</p></li>
<li><p>La falla de hardware es la norma y no la excepción, por lo que la detección de fallas y la recuperación rápida y automática de ellas es un objetivo arquitectónico central de HDFS.</p></li>
<li><p>Las aplicaciones que se ejecutan en HDFS necesitan acceso de transmisión a sus conjuntos de datos.</p></li>
<li><p>HDFS está diseñado más para el procesamiento por lotes que para el uso interactivo por parte de los usuarios.</p></li>
</ul>
<ul class="simple">
<li><p>Las aplicaciones que se ejecutan en HDFS tienen grandes conjuntos de datos.</p></li>
<li><p>Las aplicaciones HDFS necesitan un modelo de acceso de escritura única, lectura múltiple para archivos, lo que permite un acceso de datos de alto rendimiento.</p></li>
<li><p>Una aplicación <em>MapReduce</em> o una aplicación de rastreo web encaja perfectamente con este modelo.</p></li>
</ul>
<ul class="simple">
<li><p>Mover computación es más barato que mover datos.</p></li>
<li><p>HDFS proporciona interfaces para que las aplicaciones se muevan más cerca de donde se encuentran los datos.</p></li>
<li><p>Portabilidad a través de plataformas heterogéneas de hardware y software.</p></li>
</ul>
</section>
<section id="caracteristicas-de-hdfs">
<h2>Características de HDFS<a class="headerlink" href="#caracteristicas-de-hdfs" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Para almacenar una inmensa cantidad de datos, los ficheros son guardados en varias máquinas.</p></li>
<li><p>Estos ficheros son guardados de forma redundante para poder rescatar el sistema en caso de pérdida de datos a causa de fallos.</p></li>
</ul>
<ul class="simple">
<li><p>HDFS también proporciona la disponibilidad de aplicaciones para procesamiento en paralelo durante el paso de <em>Data ingestion</em>.</p></li>
<li><p>HDFS fue construido para soportar aplicaciones con grandes conjuntos de datos, incluyendo ficheros con <em>terabytes</em> de tamaño.</p></li>
</ul>
<ul class="simple">
<li><p>Utiliza una arquitectura maestro/esclavo, en la que cada clúster consta de un solo <em>NameNode</em> que administra las operaciones del sistema de archivos y admite <em>DataNodes</em> que administran el almacenamiento de datos en nodos de cómputo individuales.</p></li>
</ul>
<ul class="simple">
<li><p>Cuando HDFS toma datos, divide la información en partes separadas y las distribuye a diferentes nodos en un clúster, lo que permite el procesamiento paralelo.</p></li>
<li><p>El sistema de archivos en Ingestión de datos también copia cada pieza de datos varias veces y distribuye las copias a nodos individuales, colocando al menos una copia en un rack de servidor diferente.</p></li>
</ul>
</section>
<section id="proyectos-relacionados-con-apache-hadoop">
<h2>Proyectos relacionados con Apache Hadoop<a class="headerlink" href="#proyectos-relacionados-con-apache-hadoop" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Ambari™: una herramienta basada en web para aprovisionar, administrar y monitorear clústeres de Apache Hadoop.</p></li>
<li><p>Avro™: Un sistema de serialización de datos.</p></li>
<li><p>Cassandra™: una base de datos multimaestro escalable sin puntos únicos de falla.</p></li>
<li><p>Chukwa™: un sistema de recopilación de datos para gestionar grandes sistemas distribuidos.</p></li>
<li><p>HBase™: una base de datos distribuida escalable que admite el almacenamiento de datos estructurados para tablas grandes.</p></li>
<li><p>Hive™: una infraestructura de almacenamiento de datos que proporciona resúmenes de datos y consultas ad hoc.</p></li>
<li><p>Mahout™: una biblioteca escalable de aprendizaje automático y minería de datos.</p></li>
</ul>
<ul class="simple">
<li><p>Ozone™: un almacén de objetos escalable, redundante y distribuido para Hadoop.</p></li>
<li><p>Pig™: un lenguaje de flujo de datos de alto nivel y un marco de ejecución para computación paralela.</p></li>
<li><p>Spark™: un motor de cómputo rápido y general para datos de Hadoop. .</p></li>
<li><p>Submarine: una plataforma de IA unificada que permite a los ingenieros y científicos de datos ejecutar cargas de trabajo de ML y DL en un clúster distribuido.</p></li>
<li><p>Tez™: un marco de programación de flujo de datos generalizado, basado en Hadoop YARN, que proporciona un motor potente y flexible para ejecutar un DAG arbitrario de tareas para procesar datos tanto para casos de uso por lotes como interactivos. Tez está siendo adoptado por Hive™, Pig™ y otros marcos en el ecosistema de Hadoop, y también por otro software comercial (por ejemplo, herramientas ETL), para reemplazar a Hadoop™ MapReduce como el motor de ejecución subyacente.</p></li>
<li><p>ZooKeeper™: un servicio de coordinación de alto rendimiento para aplicaciones distribuidas.</p></li>
</ul>
</section>
<section id="tutorial-apache-hadoop">
<h2>Tutorial Apache Hadoop<a class="headerlink" href="#tutorial-apache-hadoop" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Instalación de Hadoop en CentOS 8</p></li>
<li><p>Fuente: <a class="reference external" href="https://fortinux.com/linux-2-tutoriales/hadoop-installation-centos8/">https://fortinux.com/linux-2-tutoriales/hadoop-installation-centos8/</a>.</p></li>
</ul>
</section>
<section id="apache-spark">
<h2>Apache Spark<a class="headerlink" href="#apache-spark" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Framework de procesamiento paralelo y de código abierto para ejecutar aplicaciones de análisis de datos a gran escala en sistemas agrupados.</p></li>
<li><p>Proporciona APIs de alto nivel en Java, Scala, Python y R, y un motor optimizado que soporta grafos de ejecución general.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://spark.apache.org/">https://spark.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Sus funcionalidades básicas son:</p>
<ul>
<li><p>Procesamiento de datos en <em>batch/streaming</em> utilizando Python, SQL, Scala, Java o R.</p></li>
<li><p>Analíticas mediante SQL ejecutando consultas para <em>dashboards</em> e informes más rápidas que la mayoría de los <em>data warehouses</em>.</p></li>
<li><p>Ciencia de datos en escala realizando <em>Exploratory Data Analysis - EDA</em> con petabytes de datos.</p></li>
<li><p><em>Machine Learning</em> para entrenar algoritmos en un ordenador portátil usando el mismo código que luego se utilizará en clústeres de miles de máquinas.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>También es compatible con un amplio conjunto de herramientas de alto nivel, que incluyen:</p>
<ul>
<li><p>Spark SQL para SQL y procesamiento de datos estructurados,</p></li>
<li><p>MLlib para aprendizaje automático,</p></li>
<li><p>GraphX para procesamiento de gráficos, y</p></li>
<li><p>Transmisión estructurada para procesamiento incremental y en <em>streaming</em>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Spark SQL incluye un optimizador basado en costes, almacenamiento en columnas y generación de código para agilizar las consultas.</p></li>
<li><p>Al mismo tiempo, se escala a miles de nodos y consultas de varias horas mediante el motor Spark, que proporciona tolerancia completa a fallas en la mitad de la consulta.</p></li>
</ul>
<ul class="simple">
<li><p>Facilidad de uso: Es posible escribir aplicaciones rápidamente en Java, Scala, Python, R y SQL.</p></li>
<li><p>Spark ofrece más de 80 operadores de alto nivel que facilitan la creación de aplicaciones paralelas.</p></li>
<li><p>Además se puede usar de forma interactiva desde los shells de Scala, Python, R y SQL.</p></li>
</ul>
<ul class="simple">
<li><p>Velocidad: Se ejecutan cargas de trabajo 100 veces más rápidas.</p></li>
<li><p>Apache Spark logra un alto rendimiento tanto para datos por lotes como en <em>streaming</em>, utilizando un programador DAG de última generación, un optimizador de consultas y un motor de ejecución física.</p></li>
</ul>
<ul class="simple">
<li><p>Se ejecuta en todas partes: Se puede ejecutar Spark utilizando su modo de clúster independiente, en EC2, en Hadoop YARN, en Mesos o en Kubernetes.</p></li>
<li><p>Se acceden a los datos en HDFS, Alluxio, Apache Cassandra, Apache HBase, Apache Hive y cientos de otras fuentes de datos.</p></li>
</ul>
</section>
<section id="caracteristicas-de-apache-spark">
<h2>Características de Apache Spark<a class="headerlink" href="#caracteristicas-de-apache-spark" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>La máquina en la que se ejecuta la aplicación Spark (<em>Spark Context</em>) se denomina nodo de controlador (<em>driver node</em>), que ejecuta varias operaciones paralelas en los nodos de trabajo del clúster.</p></li>
</ul>
<ul class="simple">
<li><p>Spark utiliza el concepto de un conjunto de datos distribuido resiliente (<em>Resilient Distributed Dataset - RDD</em>), que representa una colección de objetos de solo lectura particionados en un conjunto de máquinas que se pueden reconstruir si se pierde una partición.</p></li>
</ul>
<ul class="simple">
<li><p>La seguridad en Spark está DESACTIVADA de forma predeterminada.</p></li>
<li><p>Esto podría significar que se es vulnerable a un ataque por defecto.</p></li>
<li><p>Es necesario leer la documentación sobre seguridad antes de descargar y ejecutar Spark.</p></li>
</ul>
</section>
<section id="casos-de-uso-de-spark">
<h2>Casos de uso de Spark<a class="headerlink" href="#casos-de-uso-de-spark" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Se utiliza para realizar trabajos informáticos con grandes cargas de datos junto a Apache Kafka.</p></li>
<li><p>Fue desarrollado en la University of California, Berkeley.</p></li>
</ul>
<ul class="simple">
<li><p>Con Spark ejecutándose en Apache Hadoop YARN, los desarrolladores pueden crear aplicaciones para explotar el poder de Spark, obtener información y enriquecer sus cargas de trabajo de ciencia de datos dentro de un único conjunto de datos compartidos en Hadoop.</p></li>
</ul>
<ul class="simple">
<li><p>Ejemplo: Monitoramento del tránsito automotor utilizando IoT, Kafka y Spark Streaming.</p></li>
<li><p><a class="reference external" href="https://www.infoq.com/articles/traffic-data-monitoring-iot-kafka-and-spark-streaming/">https://www.infoq.com/articles/traffic-data-monitoring-iot-kafka-and-spark-streaming/</a>.</p></li>
</ul>
</section>
<section id="apache-storm">
<h2>Apache Storm<a class="headerlink" href="#apache-storm" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Es un sistema distribuido open source para procesar datos en tiempo real durante la ingesta de datos.</p></li>
<li><p>Es escalable, tiene tolerancia a fallos, y es fácil de configurar y operar.</p></li>
<li><p>Facilita el procesamiento confiable de flujos ilimitados de datos, haciendo para el procesamiento en tiempo real lo que Hadoop hizo para el procesamiento por lotes.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://storm.apache.org/">https://storm.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>No existe ningún truco que convierta a Hadoop en un sistema en tiempo real.</p></li>
<li><p>El procesamiento de datos en tiempo real tiene un conjunto de requisitos fundamentalmente diferente al procesamiento por lotes.</p></li>
<li><p>Apache Storm agrega a Hadoop esta funcionalidad de manera sencilla.</p></li>
</ul>
<ul class="simple">
<li><p>Apache Storm en YARN es poderoso para escenarios que requieren análisis en tiempo real, aprendizaje automático (ML) y monitoreo continuo de operaciones.</p></li>
</ul>
<ul class="simple">
<li><p>Casos de uso:</p>
<ul>
<li><p>Análisis en tiempo real.</p></li>
<li><p>Aprendizaje automático.</p></li>
<li><p>Monitoreo continuo de operaciones.</p></li>
<li><p>RPC distribuido, ETL, y más.</p></li>
</ul>
</li>
</ul>
</section>
<section id="caracteristicas-de-apache-storm">
<h2>Características de Apache Storm<a class="headerlink" href="#caracteristicas-de-apache-storm" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Es rápido: un <em>benchmark</em> registró más de un millón de tuplas procesadas por segundo por nodo.</p></li>
<li><p>Es escalable, tolerante a fallas, garantiza que los datos serán procesados y es fácil de configurar y operar.</p></li>
</ul>
<ul class="simple">
<li><p>Se integra con las tecnologías de colas (<em>queueing</em>) y bases de datos que ya se utilizan.</p></li>
<li><p>Una topología de Apache Storm consume flujos de datos y procesa esos flujos de formas arbitrariamente complejas, repartiendo los flujos entre cada etapa del cálculo según sea necesario.</p></li>
</ul>
<ul class="simple">
<li><p>Storm se puede utilizar para:</p>
<ul>
<li><p>Procesamiento de mensajes y actualización de bases de datos (<em>stream processing</em>).</p></li>
<li><p>Consulta continua sobre flujos de datos y transmisión de los resultados a los clientes (computación continua).</p></li>
<li><p>Paralelizar una consulta intensa como una consulta de búsqueda sobre la marcha (RPC distribuido), y más.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Escalable: Storm se escala a cantidades masivas de mensajes por segundo.</p></li>
<li><p>Para escalar una topología, todo lo que se tiene que hacer es agregar máquinas y aumentar la configuración de paralelismo de la topología.</p></li>
</ul>
<ul class="simple">
<li><p>Como ejemplo de la escala de Storm, una de las aplicaciones iniciales de Storm procesó 1000000 de mensajes por segundo en un clúster de 10 nodos, incluidos cientos de llamadas a la base de datos por segundo como parte de la topología.</p></li>
<li><p>El uso de Zookeeper por parte de Storm para la coordinación de clústeres lo hace escalar a tamaños de clúster mucho más grandes.</p></li>
</ul>
<ul class="simple">
<li><p>Garantías de no pérdida de datos: un sistema en tiempo real debe tener fuertes garantías de que los datos se procesarán con éxito.</p></li>
<li><p>Un sistema que distribuye datos tiene un conjunto muy limitado de casos de uso.</p></li>
<li><p>Storm garantiza que todos los mensajes serán procesados, y esto contrasta directamente con otros sistemas como S4.</p></li>
</ul>
<ul class="simple">
<li><p>Extremadamente robusto: a diferencia de sistemas como Hadoop, que son conocidos por ser difíciles de administrar, los clústeres de Storm simplemente funcionan.</p></li>
<li><p>Es un objetivo explícito del proyecto Storm hacer que la experiencia del usuario al administrar los clústeres de Storm sea lo menos dolorosa posible.</p></li>
</ul>
<ul class="simple">
<li><p>Tolerante a fallas: si hay fallas durante la ejecución de cálculos, Storm reasignará las tareas según sea necesario.</p></li>
<li><p>Storm se asegura de que un cómputo pueda ejecutarse para siempre (o hasta que éste se elimine).</p></li>
</ul>
<ul class="simple">
<li><p>Independiente del lenguaje de programación: el procesamiento en tiempo real robusto y escalable no debe limitarse a una sola plataforma.</p></li>
<li><p>Las topologías y los componentes de procesamiento de Storm se pueden definir en cualquier idioma, lo que hace que Storm sea accesible para casi cualquier persona.</p></li>
</ul>
<ul class="simple">
<li><p>Fuente: <a class="reference external" href="https://storm.apache.org/releases/2.6.3/Concepts.html">https://storm.apache.org/releases/2.6.3/Concepts.html</a>.</p></li>
</ul>
</section>
<section id="storm-vs-spark">
<h2>Storm vs. Spark<a class="headerlink" href="#storm-vs-spark" title="Link to this heading">#</a></h2>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Situation</p></th>
<th class="head"><p>Spark</p></th>
<th class="head"><p>Storm</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Stream processing</p></td>
<td><p>Batch processing</p></td>
<td><p>Micro-batch processing</p></td>
</tr>
<tr class="row-odd"><td><p>Latency</p></td>
<td><p>Latency of a few seconds</p></td>
<td><p>Latency of milliseconds</p></td>
</tr>
<tr class="row-even"><td><p>Multi-language support</p></td>
<td><p>Multiple language support</p></td>
<td><p>Lesser language support</p></td>
</tr>
<tr class="row-odd"><td><p>Languages</p></td>
<td><p>Java – Scala - Python - R - SQL</p></td>
<td><p>Java – Scala – Clojure</p></td>
</tr>
<tr class="row-even"><td><p>Stream sources</p></td>
<td><p>HDFS</p></td>
<td><p>Spout</p></td>
</tr>
<tr class="row-odd"><td><p>Resource management</p></td>
<td><p>Yarn, Mesos</p></td>
<td><p>Yarn, Mesos</p></td>
</tr>
<tr class="row-even"><td><p>Provisioning</p></td>
<td><p>Basic using Ganglia</p></td>
<td><p>Apache Ambari</p></td>
</tr>
<tr class="row-odd"><td><p>Messaging</p></td>
<td><p>Netty, Akka</p></td>
<td><p>ZeroMQ, Netty</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="apache-kafka">
<h2>Apache Kafka<a class="headerlink" href="#apache-kafka" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Apache Kafka es una plataforma de transmisión de eventos distribuidos de código abierto utilizada por miles de empresas para canalizaciones de datos de alto rendimiento, análisis de streaming, integración de datos y aplicaciones de misión crítica.</p></li>
<li><p>Es un sistema de mensajería escalable que permite a los usuarios publicar y consumir grandes cantidades de mensajes en tiempo real por suscripción.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://kafka.apache.org/">https://kafka.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="caracteristicas-de-apache-kafka">
<h2>Características de Apache Kafka<a class="headerlink" href="#caracteristicas-de-apache-kafka" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Alto rendimiento:</p>
<ul>
<li><p>Entrega mensajes con un rendimiento limitado de la red utilizando un grupo de máquinas (clúster) con una latencia de tan solo 2 ms.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Escalable:</p>
<ul>
<li><p>Es posible escalar clústeres de producción con hasta mil <em>brokers</em>, billones de mensajes por día, <em>petabytes</em> de datos, cientos de miles de particiones.</p></li>
<li><p>También expandir y contraer elásticamente el almacenamiento y procesamiento.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Almacenamiento permanente:</p>
<ul>
<li><p>Almacena flujos de datos de forma segura en un clúster distribuido, duradero y tolerante a fallas.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Alta disponibilidad:</p>
<ul>
<li><p>Extiende los clústeres de manera eficiente sobre las zonas de disponibilidad o los conecta separados en regiones geográficas.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Procesamiento de flujo incorporado:</p>
<ul>
<li><p>Procesa secuencias de eventos con uniones, agregaciones, filtros, transformaciones y más, utilizando el procesamiento solo una vez con el tiempo de evento.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Conexión a múltiples fuentes:</p>
<ul>
<li><p>La interfaz <em>Connect</em> lista para usar de Kafka se integra con cientos de orígenes de eventos y receptores de eventos, incluidos PostgreSQL, JMS, Elasticsearch, AWS S3 y más.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Bibliotecas de clientes:</p>
<ul>
<li><p>Posibilidad de Leer, escribir y procesar flujos de eventos en una amplia gama de lenguajes de programación.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Herramientas de código abierto para grandes ecosistemas:</p>
<ul>
<li><p>Gran ecosistema de herramientas de código abierto: existe una amplia gama de herramientas impulsadas por la comunidad.</p></li>
</ul>
</li>
</ul>
</section>
<section id="transmision-de-eventos">
<h2>Transmisión de eventos<a class="headerlink" href="#transmision-de-eventos" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>La transmisión de eventos es el equivalente digital del sistema nervioso central del cuerpo humano.</p></li>
<li><p>Es la base tecnológica para el mundo ‘siempre activo’ donde las empresas están cada vez más definidas por software y automatizadas, y donde el usuario de software es más software (Inteligencia Artificial).</p></li>
</ul>
<ul class="simple">
<li><p>Técnicamente hablando, la transmisión de eventos es la práctica de capturar datos en tiempo real de fuentes de eventos como bases de datos, sensores, dispositivos móviles, servicios en la nube y aplicaciones de software en forma de flujos de eventos; almacenar estos flujos de eventos de forma duradera para su posterior recuperación; manipular, procesar y reaccionar a los flujos de eventos en tiempo real y retrospectivamente; y enrutar los flujos de eventos a diferentes tecnologías de destino según sea necesario.</p></li>
</ul>
<ul class="simple">
<li><p>La transmisión de eventos garantiza un flujo continuo y una interpretación de los datos para que la información correcta esté en el lugar correcto, en el momento correcto.</p></li>
</ul>
<ul class="simple">
<li><p>Kafka combina tres capacidades clave para que pueda implementar sus casos de uso para la transmisión de eventos de extremo a extremo con una única solución exitosamente testeada.</p></li>
</ul>
<ul class="simple">
<li><p>Para publicar (escribir) y suscribirse a (leer) flujos de eventos, incluida la importación/exportación continua de sus datos desde otros sistemas.</p></li>
<li><p>Para almacenar secuencias de eventos de forma duradera y fiable durante el tiempo que desee.</p></li>
<li><p>Procesar flujos de eventos a medida que ocurren o retrospectivamente.</p></li>
</ul>
<ul class="simple">
<li><p>Toda esta funcionalidad se proporciona de forma distribuida, altamente escalable, elástica, tolerante a fallos y segura.</p></li>
<li><p>Kafka se puede implementar en hardware básico, máquinas virtuales y contenedores, tanto en las instalaciones propias como en la nube.</p></li>
<li><p>Es posible elegir entre la autogestión de los entornos Kafka y el uso de servicios totalmente gestionados ofrecidos por una variedad de proveedores.</p></li>
</ul>
</section>
<section id="procesos-de-apache-kafka">
<h2>Procesos de Apache Kafka<a class="headerlink" href="#procesos-de-apache-kafka" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Kafka se ejecuta como un clúster de uno o más servidores que pueden abarcar varios centros de datos o regiones de la nube.</p></li>
<li><p>Algunos de estos servidores forman la capa de almacenamiento, llamados intermediarios (<em>brokers</em>).</p></li>
</ul>
<ul class="simple">
<li><p>Clientes: le permiten escribir aplicaciones distribuidas y microservicios que leen, escriben y procesan flujos de eventos en paralelo, a escala y con tolerancia a fallas, incluso en el caso de problemas de red o fallas de máquinas.</p></li>
</ul>
<ul class="simple">
<li><p>Un evento registra el hecho de que “algo pasó” en el mundo o en el negocio.</p></li>
<li><p>También se le llama registro o mensaje en la documentación.</p></li>
<li><p>Cuando lee o escribe datos en Kafka, lo hace en forma de eventos.</p></li>
<li><p>Conceptualmente, un evento tiene una clave, un valor, una marca de tiempo, y encabezados de metadatos opcionales.</p></li>
</ul>
<ul class="simple">
<li><p>Los productores son aquellas aplicaciones cliente que publican (escriben) eventos en Kafka, y los consumidores son los que se suscriben (leen y procesan) estos eventos.</p></li>
</ul>
<ul class="simple">
<li><p>Los eventos se organizan y almacenan de forma duradera en temas (<em>topics</em>).</p></li>
<li><p>Muy simplificado, un tema es similar a una carpeta en un sistema de archivos, y los eventos son los archivos en esa carpeta.</p></li>
<li><p>Un nombre de tema de ejemplo podría ser “pagos”.</p></li>
</ul>
<ul class="simple">
<li><p>Los temas están particionados, lo que significa que un tema se distribuye en varios “cubos” (<em>buckets</em>) ubicados en diferentes <em>brokers</em> de Kafka.</p></li>
<li><p>Esta ubicación distribuida de los datos es muy importante para la escalabilidad porque permite que las aplicaciones cliente lean y escriban los datos desde/hacia muchos <em>brokers</em> al mismo tiempo.</p></li>
</ul>
</section>
<section id="tutorial-apache-kafka">
<h2>Tutorial Apache Kafka<a class="headerlink" href="#tutorial-apache-kafka" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Descargar e instalar Kafka en una máquina virtual</p></li>
<li><p><a class="reference external" href="https://kafka.apache.org/quickstart">https://kafka.apache.org/quickstart</a>.</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="BigData-es004MongoDB.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Tutorial MongoDB</p>
      </div>
    </a>
    <a class="right-next"
       href="BigData-es005Hadoop.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Tutorial Apache Hadoop</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#aplicaciones-para-big-data">Aplicaciones para Big Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hadoop">Hadoop</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modulos-de-apache-hadoop">Módulos de Apache Hadoop</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-hadoop-yarn">Apache Hadoop YARN</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-de-procesamiento-dag">Modelo de procesamiento DAG</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-hadoop-mapreduce">Apache Hadoop MapReduce</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sistema-de-ficheros-hdfs">Sistema de ficheros HDFS</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#caracteristicas-de-hdfs">Características de HDFS</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#proyectos-relacionados-con-apache-hadoop">Proyectos relacionados con Apache Hadoop</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tutorial-apache-hadoop">Tutorial Apache Hadoop</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-spark">Apache Spark</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#caracteristicas-de-apache-spark">Características de Apache Spark</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#casos-de-uso-de-spark">Casos de uso de Spark</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-storm">Apache Storm</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#caracteristicas-de-apache-storm">Características de Apache Storm</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#storm-vs-spark">Storm vs. Spark</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-kafka">Apache Kafka</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#caracteristicas-de-apache-kafka">Características de Apache Kafka</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#transmision-de-eventos">Transmisión de eventos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#procesos-de-apache-kafka">Procesos de Apache Kafka</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tutorial-apache-kafka">Tutorial Apache Kafka</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Fortinux - Marcelo Horacio Fortino
</p>

  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <div>
<a href="https://creativecommons.org/licenses/by-sa/4.0/"><img src="https://licensebuttons.net/l/by-sa/3.0/88x31.png"></a>
    Esta obra está sujeta a la licencia Reconocimiento-CompartirIgual 4.0 Internacional de Creative Commons. Para ver una copia de esta licencia, visite <a href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0 license</a>. Puede hallar permisos más allá de los concedidos con esta licencia en <a href="https://fortinux.com" rel="nofollow">https://fortinux.com</a>. Sugerencias y comentarios a <a href="mailto:info@fortinux.com">info@fortinux.com</a>.
</div>

</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>