

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Big Data tema 2 &#8212; Curso Introducción a Big Data</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../_static/styles/theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="../../../../_static/styles/bootstrap.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="../../../../_static/styles/pydata-sphinx-theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />

  
  <link href="../../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=ac02cc09edc035673794" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../_static/scripts/bootstrap.js?digest=ac02cc09edc035673794" />
<link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794" />
  <script src="../../../../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=ac02cc09edc035673794"></script>

    <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/clipboard.min.js"></script>
    <script src="../../../../_static/copybutton.js"></script>
    <script src="../../../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'docs/jupyter_execute/docs/jupyter_execute/BigData-es002';</script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../../../intro.html">
  
  
  
  
    
    
      
    
    
    <img src="../../../../_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../../../../_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../../intro.html">
                    Introducción a Big Data
                </a>
            </li>
        </ul>
        <ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../../BigData-es001.html">Definición y características</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../BigData-es002.html">Ingesta y almacenamiento de datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../BigData-es003.html">Consulta y visualización de datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../BigData-es004.html">Bases de datos para Big Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../BigData-es004MongoDB.html">Tutorial MongoDB</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../BigData-es005.html">Frameworks y aplicaciones</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../BigData-es005Hadoop.html">Tutorial Apache Hadoop</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../BigData-es005Kafka.html">Tutorial Apache Kafka</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../BigData-es006.html">Elastic stack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../BigData-es007.html">Big Data stacks y Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../BigData-es007sparkMLlib.html">Tutorial Spark</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/fortinux/bigdata-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/fortinux/bigdata-book/issues/new?title=Issue%20on%20page%20%2Fdocs/jupyter_execute/docs/jupyter_execute/BigData-es002.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../../_sources/docs/jupyter_execute/docs/jupyter_execute/BigData-es002.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Big Data tema 2</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#procesos-en-big-data">Procesos en Big Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ingestion-de-datos">Ingestión de datos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cuestiones-a-considerar">Cuestiones a considerar</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#buenas-practicas-en-ingestion-de-datos">Buenas prácticas en ingestión de datos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#herramientas-para-la-ingesta-de-datos">Herramientas para la ingesta de datos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sistemas-de-mensajeria">Sistemas de mensajería</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problemas-en-la-ingesta-de-datos">Problemas en la ingesta de datos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-semantico-de-datos-sdm">Modelo semántico de datos (SDM)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#almacenamiento-de-datos-data-storage">Almacenamiento de datos (Data Storage)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#herramientas-de-almacenamiento-para-big-data">Herramientas de almacenamiento para Big Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hdfs">HDFS</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-ozone">Apache Ozone</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#glusterfs">GlusterFS</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ceph">Ceph</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#amazon-services">Amazon Services</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#microsoft-azure-data-lake-store">Microsoft Azure Data Lake Store</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#google-bigquery">Google BigQuery</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#databricks">Databricks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#snowflake">Snowflake</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nosql-databases">NoSQL databases</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bases-de-datos-de-documentos">Bases de datos de documentos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mongodb">MongoDB</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-couchdb">Apache CouchDB</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#couchbase">Couchbase</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bases-de-datos-con-pares-de-valores">Bases de datos con pares de valores</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#redis-database">Redis database</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bases-de-datos-columnares">Bases de datos columnares</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-cassandra">Apache Cassandra</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-hbase">Apache HBase</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bases-de-datos-graficas">Bases de datos gráficas</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#amazon-neptune">Amazon Neptune</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stardog">Stardog</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#neo4j">Neo4j</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#procesamiento-analisis-y-consulta-de-datos">Procesamiento, análisis y consulta de datos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-sqoop-in-the-attic">Apache Sqoop (in the Attic)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-spark">Apache Spark</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-storm">Apache Storm</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizacion-de-datos-big-data-visualization">Visualización de datos (Big Data Visualization)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#elastic-stack">Elastic Stack</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#salesforce-google-y-microsoft">Salesforce, Google y Microsoft</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#monitoreo-de-datos">Monitoreo de datos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#herramientas-para-big-data">Herramientas para Big Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-mesos">Apache Mesos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-zookeeper">Apache Zookeeper</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-ambari-in-the-attic">Apache Ambari (in the Attic)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-ranger">Apache Ranger</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-sentry">Apache Sentry</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-airflow">Apache Airflow</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="big-data-tema-2">
<h1>Big Data tema 2<a class="headerlink" href="#big-data-tema-2" title="Permalink to this heading">#</a></h1>
<section id="procesos-en-big-data">
<h2>Procesos en Big Data<a class="headerlink" href="#procesos-en-big-data" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Existen varias metodologías disponibles en el mercado para la recopilación, almacenamiento, consulta y visualización de datos.</p></li>
<li><p>Provienen del mundo de la minería de datos, y entre ellas se pueden mencionar KDD (<em>Knowledge Discovery in Databases</em>), SEMMA y CRISP-DM.</p></li>
<li><p>CRISP-DM (<em>Cross Industry Standard Process for Data Mining</em>) por ejemplo, es un proceso iterativo centrado en el negocio.</p></li>
<li><p>Sus fases son: comprensión del negocio, Comprensión de los datos, Preparación de los datos, Fase de Modelado, Evaluación e Implantación.</p>
<ul>
<li><p>Fuente: Metodología para el Desarrollo de proyectos en Minería de Datos CRISP-DM</p></li>
<li><p><a class="reference external" href="http://www.oldemarrodriguez.com/yahoo_site_admin/assets/docs/Documento_CRISP-DM.2385037.pdf">http://www.oldemarrodriguez.com/yahoo_site_admin/assets/docs/Documento_CRISP-DM.2385037.pdf</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Para proyectos de Big Data los procesos básicamente se pueden dividir en cuatro fases:</p>
<ul>
<li><p>Ingestión de datos (<em>Data Ingestion</em>).</p></li>
<li><p>Almacenamiento de datos (<em>Data Storage</em>).</p></li>
<li><p>Procesamiento, análisis y consulta de datos (<em>Data Processing / Data Query</em>).</p></li>
<li><p>Visalización de datos (<em>Data Visualization</em>).</p></li>
</ul>
</li>
</ul>
</section>
<section id="ingestion-de-datos">
<h2>Ingestión de datos<a class="headerlink" href="#ingestion-de-datos" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Obtención, procesado (separación, agrupación, filtrado) y limpieza de datos (eliminar duplicados y errores).</p></li>
<li><p>Es el primer paso donde se obtienen los datos que provienen de varias fuentes y que irán a dispositivos de almacenamiento para su posterior acceso, uso y análisis por parte de la organización.</p></li>
<li><p>En esta etapa los datos son priorizados y categorizados.</p></li>
</ul>
<ul class="simple">
<li><p>Su destinación es generalmente:</p>
<ul>
<li><p>Un <em>data warehouse</em> (<em>Snowflake, Amazon Redshift, Google BigQuery, Azure Synapse</em>), o</p></li>
<li><p>Un <em>data lake</em> (<em>Databricks</em>) con datos estructurados, semi estructurados y no estructurados.</p></li>
</ul>
</li>
</ul>
</section>
<section id="cuestiones-a-considerar">
<h2>Cuestiones a considerar<a class="headerlink" href="#cuestiones-a-considerar" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Velocidad de la entrada de datos (frecuencia: <em>Batch, Real-Time</em>).</p></li>
<li><p>Volumen de los datos.</p></li>
<li><p>Variedad (formato: datos estructurados, Semi-estructurados, no estructurados).</p></li>
</ul>
<ul class="simple">
<li><p>Otras cuestiones a tener en cuenta son la veracidad de esos datos (si son confiables) y el valor de los mismos.</p></li>
</ul>
<ul class="simple">
<li><p>La velocidad de datos se ocupa de la velocidad a la que fluyen los datos desde diferentes fuentes, como máquinas, redes, IoT, interacción humana, sitios de medios, redes sociales.</p></li>
<li><p>El movimiento de datos puede ser masivo o continuo en la ingestión de datos.</p></li>
</ul>
<ul class="simple">
<li><p>El volumen de los datos gestionados puede ser enorme.</p></li>
<li><p>Los datos son generados desde diversas fuentes.</p></li>
<li><p>Éstas pueden aumentar cada día tanto en cantidad como en volumen de datos.</p></li>
</ul>
<ul class="simple">
<li><p>Frecuencia de datos:</p></li>
<li><p>Los datos se pueden procesar en tiempo real o por lotes.</p></li>
<li><p>En tiempo real, el procesamiento ocurre cuando los datos se reciben al mismo tiempo que se generan.</p></li>
<li><p>Los datos por lotes se almacenan mediante un proceso por lotes fijo en algún intervalo de tiempo y luego se trasladan al flujo del proceso de administración de datos.</p></li>
</ul>
<ul class="simple">
<li><p>La ingestión de datos se puede realizar utilizando formatos de distinto tipo.</p>
<ul>
<li><p>Datos estructurados (formato tabular).</p></li>
<li><p>Semi-estructurados (ficheros JSON, CSV, etc.).</p></li>
<li><p>No estructurados (imágenes, audio, video, etc.).</p></li>
</ul>
</li>
</ul>
<p>Fuente: <span id="id1">[<a class="reference internal" href="../../../../intro.html#id7" title="Edd. Dumbill. Planning for Big Data: A CIO's Handbook to the Changing Data Landscape. O’Reilly Media, Inc., 2012.">Dum12</a>]</span></p>
</section>
<section id="buenas-practicas-en-ingestion-de-datos">
<h2>Buenas prácticas en ingestión de datos<a class="headerlink" href="#buenas-practicas-en-ingestion-de-datos" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Ancho de banda de la red:</p></li>
<li><p>El flujo de datos (<em>Data Pipeline</em>) debe poder competir con el tráfico comercial.</p></li>
<li><p>A veces el tráfico aumenta o disminuye, por lo que la escalabilidad del ancho de banda de la red es el mayor desafío del <em>Data Pipeline</em>.</p></li>
<li><p>Se requieren herramientas de ingestión de datos que permitan la limitación y compresión del ancho de banda en base a las necesidades del momento.</p></li>
</ul>
<ul class="simple">
<li><p>Soporte para red no confiable:</p></li>
<li><p>La canalización en la ingestión de datos toma datos con múltiples estructuras, es decir, archivos de texto, datos de archivos tabulares, archivos XML, archivos de registro, etc. y debido a la velocidad variable de los datos que llegan, es posible que viajen a través de una red poco confiable.</p></li>
<li><p>La implementación del flujo de datos o <em>Data Pipeline</em> también debería ser capaz de soportar esto.</p></li>
</ul>
<ul class="simple">
<li><p>Transmisión de datos:</p></li>
<li><p>Las mejores prácticas de ingestión de datos dependen de la necesidad empresarial, ya sea para procesar los datos por lotes, flujos o en tiempo real.</p></li>
<li><p>En ocasiones, es posible que se necesiten todos a la vez para el procesamiento a través de la canalización de ingesta de datos, por lo que las herramientas deben ser capaces de admitirlos.</p></li>
</ul>
<ul class="simple">
<li><p>Tecnologías y Sistemas Heterogéneos:</p></li>
<li><p>Las herramientas para la canalización de la ingesta de datos deben poder utilizar diferentes tecnologías de fuentes de datos y diferentes sistemas operativos.</p></li>
</ul>
<ul class="simple">
<li><p>Elección del formato de datos correcto:</p></li>
<li><p>Las herramientas de ingesta de datos deben proporcionar un formato de serialización de datos, lo que significa que, dado que los datos vienen en formatos variables, los convierte a un solo formato para proporcionar una forma más fácil de comprenderlos o relacionarlos.</p></li>
</ul>
<ul class="simple">
<li><p>Repositorio único:</p></li>
<li><p>El análisis crítico es más efectivo cuando se combinan datos de múltiples fuentes.</p></li>
<li><p>Para la toma de decisiones de negocio, se debe tener un repositorio único para todos los datos que llegan.</p></li>
</ul>
<ul class="simple">
<li><p>Integraciones:</p></li>
<li><p>Todo el tiempo los datos siguen aumentando en el proceso de ingesta de datos, llegan datos nuevos y se modifican los datos antiguos, por lo cual a veces cada nueva integración puede tardar entre unos días y unos meses en completarse.</p></li>
</ul>
<ul class="simple">
<li><p>Alta precisión:</p></li>
<li><p>La única forma de generar confianza con los datos es asegurarse de que los datos son auditables.</p></li>
<li><p>Una buena práctica que es fácil de implementar es nunca descartar entradas o formularios intermedios al modificar datos en el flujo del proceso de ingesta de datos.</p></li>
</ul>
<ul class="simple">
<li><p>Latencia:</p></li>
<li><p>Cuanto más actualizados sean los datos, más ágil puede ser la toma de decisiones en la organización, pero hay un coste a considerar.</p></li>
<li><p>La extracción de datos de APIs y bases de datos en tiempo real puede ser difícil, y muchas fuentes de datos de destino, incluidos grandes almacenes de objetos como Amazon S3 y bases de datos de análisis como Amazon Redshift, están optimizadas para recibir datos en fragmentos en lugar de una secuencia.</p></li>
</ul>
<ul class="simple">
<li><p>Mantener la escalabilidad:</p></li>
<li><p>La ingesta de datos se puede aumentar o disminuir durante algunos períodos de tiempo.</p></li>
<li><p>El uso y tratamiento de los datos no es uniforme.</p></li>
<li><p>Se debe hacer que la canalización sea tan escalable que pueda manejar cualquier cantidad de datos que lleguen a una velocidad variable.</p></li>
</ul>
</section>
<section id="herramientas-para-la-ingesta-de-datos">
<h2>Herramientas para la ingesta de datos<a class="headerlink" href="#herramientas-para-la-ingesta-de-datos" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Apache Flume</p>
<ul>
<li><p>Un servicio distribuido, confiable y de alta disponibilidad que colecta, agrupa y mueve eficientemente grandes cantidades de logs y datos.</p></li>
<li><p>Extraído de: <a class="reference external" href="https://flume.apache.org/">https://flume.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Es robusto y tolerante a fallas con mecanismos de confiabilidad ajustables.</p></li>
<li><p>Cuenta también con mecanismos de conmutación por error y recuperación.</p></li>
<li><p>Utiliza un modelo de datos extensible simple que permite la aplicación analítica en línea.</p></li>
</ul>
<ul class="simple">
<li><p>Un evento Flume se define como una unidad de flujo de datos que tiene una carga útil de bytes y un conjunto opcional de atributos de cadena.</p></li>
<li><p>Un agente de Flume es un proceso (JVM) que aloja los componentes a través de los cuales fluyen los eventos desde una fuente externa hasta el siguiente destino (salto).</p></li>
</ul>
<ul class="simple">
<li><p>Una fuente de Flume consume eventos que le envía una fuente externa como por ej. un servidor web.</p></li>
<li><p>La fuente externa envía eventos a Flume en un formato que es reconocido por la fuente de destino de Flume.</p></li>
</ul>
<ul class="simple">
<li><p>Extraído de: <a class="reference external" href="https://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html">https://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html</a>.</p></li>
</ul>
<ul class="simple">
<li><p>Apache Nifi</p>
<ul>
<li><p>Es una de las mejores herramientas de <em>data ingestion</em> del mercado.</p></li>
<li><p>Proveee un sistema fácil de usar, poderoso y confiable para procesar y distribuir datos.</p></li>
<li><p>Extraído de: <a class="reference external" href="https://nifi.apache.org/">https://nifi.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Documentación: <a class="reference external" href="https://nifi.apache.org/docs/nifi-docs/html/getting-started.html">https://nifi.apache.org/docs/nifi-docs/html/getting-started.html</a>.</p></li>
<li><p>Caso de uso: <em>Best practices and lessons learnt from Running Apache NiFi at Renault</em><br />
<a class="reference external" href="https://fr.slideshare.net/Hadoop_Summit/best-practices-and-lessons-learnt-from-running-apache-nifi-at-renault">https://fr.slideshare.net/Hadoop_Summit/best-practices-and-lessons-learnt-from-running-apache-nifi-at-renault</a>.</p></li>
</ul>
<ul class="simple">
<li><p>Apache Flink</p>
<ul>
<li><p>Framework utilizado para el procesamiento de flujos distribuidos (<em>distributed stream</em>) que facilita resultados precisos, aún en el caso de datos que están desordenados o que llegan con retraso en la distribución.</p></li>
<li><p>Extraído de: <a class="reference external" href="https://flink.apache.org/">https://flink.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Elastic Logstash</p>
<ul>
<li><p>Tubería (<em>pipeline</em>) de procesamiento de datos del lado del servidor de código abierto que ingiere datos de una multitud de fuentes, los transforma simultáneamente y luego los envía al reservatorio (<em>stash</em>), por ejemplo Elasticsearch.</p></li>
<li><p>Extraído de: <a class="reference external" href="https://www.elastic.co/">https://www.elastic.co/</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Apache Beam</p>
<ul>
<li><p>Es un modelo de programación unificado que permite implementar trabajos de procesamiento de datos por lotes y de <em>streaming</em> en cualquier motor de ejecución.</p></li>
<li><p>Lee los datos desde diversas fuentes, ejecuta la lógica del negocio para <em>batch</em> y <em>streaming</em>, y finalmente los deposita en las soluciones de almacenamiento disponibles.</p></li>
<li><p>Una canalización de Beam puede ejecutarse en los sistemas de procesamiento de datos distribuidos más populares, como Spark, Flink o Samza.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Apache Samza</p>
<ul>
<li><p>Permite crear aplicaciones con estado que procesan datos en tiempo real desde múltiples fuentes, incluido Apache Kafka.</p></li>
<li><p>Admite opciones de implementación flexibles para ejecutarse en YARN o como una biblioteca independiente.</p></li>
<li><p>Tutorial: <a class="reference external" href="https://samza.apache.org/startup/hello-samza/1.6.0/">https://samza.apache.org/startup/hello-samza/1.6.0/</a>.</p></li>
<li><p>Fuente: <a class="reference external" href="https://samza.apache.org/">https://samza.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Fivetran es una cloud-based platform para ETL.</p>
<ul>
<li><p><a class="reference external" href="https://www.fivetran.com/">https://www.fivetran.com/</a>.</p></li>
</ul>
</li>
<li><p>Stitch Data Loader mueve más de 130 tipos de fuentes al <em>data warehouse</em>.</p>
<ul>
<li><p><a class="reference external" href="https://www.stitchdata.com/">https://www.stitchdata.com/</a>.</p></li>
</ul>
</li>
<li><p>Airbyte es una herramienta open-source de integración de datos.</p>
<ul>
<li><p><a class="reference external" href="https://airbyte.com/">https://airbyte.com/</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="sistemas-de-mensajeria">
<h2>Sistemas de mensajería<a class="headerlink" href="#sistemas-de-mensajeria" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Apache Kafka</p>
<ul>
<li><p>Es una plataforma de transmisión de eventos distribuidos de código abierto utilizada por miles de empresas para canalizaciones de datos de alto rendimiento, análisis de streaming, integración de datos y aplicaciones de misión crítica.</p></li>
<li><p>Es también un sistema de mensajería escalable que permite a los usuarios publicar y consumir grandes cantidades de mensajes en tiempo real por suscripción.</p></li>
<li><p>Extraído de: <a class="reference external" href="https://kafka.apache.org/">https://kafka.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>La transmisión de eventos es el equivalente digital del sistema nervioso central del cuerpo humano.</p></li>
<li><p>Es la base tecnológica para el mundo ‘siempre activo’ donde las empresas están cada vez más definidas por software y automatizadas, y donde el usuario de software es más software (Inteligencia Artificial).</p></li>
</ul>
<ul class="simple">
<li><p>Técnicamente hablando, la transmisión de eventos es la práctica de capturar datos en tiempo real de fuentes de eventos como bases de datos, sensores, dispositivos móviles, servicios en la nube y aplicaciones de software en forma de flujos de eventos; almacenar estos flujos de eventos de forma duradera para su posterior recuperación; manipular, procesar y reaccionar a los flujos de eventos en tiempo real y retrospectivamente; y enrutar los flujos de eventos a diferentes tecnologías de destino según sea necesario.</p></li>
</ul>
<ul class="simple">
<li><p>La version comercial de Apache Kafka es Confluent <a class="reference external" href="https://www.confluent.io/es-es/">https://www.confluent.io/es-es/</a>.</p></li>
<li><p>Otro <em>broker</em> de mensajería es RabbitMQ <a class="reference external" href="https://www.rabbitmq.com/">https://www.rabbitmq.com/</a>.</p></li>
</ul>
<ul class="simple">
<li><p>Apache ActiveMQ</p>
<ul>
<li><p>Es el sistema de mensajería multi protocolo open source más popular del mercado.</p></li>
<li><p>Se conecta a clientes escritos en JavaScript, C, C++, Python, .Net, y más.</p></li>
<li><p>Integra aplicaciones multiplataforma utilizando el protocolo AMQP.</p></li>
<li><p>Intercambia mensajes mediante STOMP sobre <em>websockets</em>, gestiona dispositivos IoT con MQTT.</p></li>
<li><p>Soporta la infraestructura JMS (<em>Java Message Service</em>).</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Fuente: <a class="reference external" href="https://activemq.apache.org/">https://activemq.apache.org/</a></p></li>
</ul>
<ul class="simple">
<li><p>Apache Pulsar</p>
<ul>
<li><p>Apache Pulsar es una plataforma de eventos distribuidos cloud similar a Kafka originalmente creada por Yahoo!</p></li>
<li><p><a class="reference external" href="https://pulsar.apache.org/">https://pulsar.apache.org/</a>.</p></li>
<li><p>La versión comercial de sus creadores es StreamNative <a class="reference external" href="https://streamnative.io/">https://streamnative.io/</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Pub/Sub</p>
<ul>
<li><p>Es un sistema de mensajería que combina la escalabilidad horizontal de Apache Kafka y Pulsar con funciones del middleware como colas y filtros de mensajes no entregados de Apache ActiveMQ y RabbitMQ.</p></li>
<li><p>Se complementa con Dataflow, que controla la anulación de mensajes duplicados, el procesamiento “solo una vez” y generación de marcas de agua a partir de eventos con marcas de tiempo.</p></li>
<li><p>Para usar Dataflow se escribe la canalización con el SDK de Apache Beam y luego se ejecuta.</p></li>
<li><p><a class="reference external" href="https://cloud.google.com/pubsub/docs/overview">https://cloud.google.com/pubsub/docs/overview</a></p></li>
</ul>
</li>
</ul>
</section>
<section id="problemas-en-la-ingesta-de-datos">
<h2>Problemas en la ingesta de datos<a class="headerlink" href="#problemas-en-la-ingesta-de-datos" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Cuando existen numerosas fuentes de Big Data con diferentes formatos, el mayor desafío para el negocio es ingerir datos a una velocidad razonable y procesarlos de manera eficiente.</p></li>
<li><p>De esta manera los datos pueden priorizarse y en consecuencia mejorar la toma de decisiones de negocio.</p></li>
</ul>
<ul class="simple">
<li><p>Las fuentes de datos, las herramientas de ingestión de datos y las aplicaciones de consumo evolucionan permanentemente durante el proceso de ingestión de datos.</p></li>
<li><p>Los datos pueden modificar sus atributos sin previo aviso independientemente de la aplicación utilizada.</p></li>
</ul>
<ul class="simple">
<li><p>Detección y captura de datos modificados: esta tarea es difícil, no solo por la naturaleza semiestructurada o no estructurada de los datos.</p></li>
<li><p>También lo es por tratar con baja latencia (una red informática que está optimizada para procesar un volumen muy alto de mensajes de datos con un retraso mínimo).</p></li>
<li><p>Estas redes están diseñadas para admitir operaciones que requieren acceso casi en tiempo real a datos que cambian rápidamente.</p></li>
</ul>
</section>
<section id="modelo-semantico-de-datos-sdm">
<h2>Modelo semántico de datos (SDM)<a class="headerlink" href="#modelo-semantico-de-datos-sdm" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>El modelo semántico de datos (SDM) también cambia con el tiempo.</p></li>
<li><p>Se necesita un modelo de datos (<em>DM</em>) en el que se incluya información semántica.</p></li>
<li><p>Un <em>DM</em> que incluya la capacidad de expresar e intercambiar información permite a las partes interpretar el significado (semántica) de las instancias.</p></li>
</ul>
<ul class="simple">
<li><p>Extraído de: Semantic Data Model: <a class="reference external" href="https://es.wikipedia.org/wiki/Modelo_sem%C3%A1ntico_de_datos">https://es.wikipedia.org/wiki/Modelo_semántico_de_datos</a>.</p></li>
</ul>
<ul class="simple">
<li><p>En un modelo semántico los hechos generalmente se expresan mediante relaciones binarias entre elementos de datos, mientras que las relaciones de orden superior se expresan como colecciones de relaciones binarias.</p></li>
<li><p>Típicamente las relaciones binarias tienen la forma de ternas: Objeto-&lt;Tipo de Relación&gt;-Objeto.</p></li>
<li><p>Por ejemplo: La Torre Eiffel <code class="docutils literal notranslate"><span class="pre">&lt;se</span> <span class="pre">encuentra</span> <span class="pre">en&gt;</span></code> París.</p></li>
</ul>
<ul class="simple">
<li><p>Según el conocido trabajo seminal de Smith y Smith (1977), tres abstracciones son muy importantes para el modelado de datos:</p>
<ul>
<li><p>Clasificación: modelo instancia_de_relaciones.</p></li>
<li><p>Agregación: modelo tiene_relaciones.</p></li>
<li><p>Generalización: modelo es_unas_relaciones.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Extraído de: Semantic Data Modelling: <a class="reference external" href="http://www.jhterbekke.net/SemanticDataModeling.html">http://www.jhterbekke.net/SemanticDataModeling.html</a>.</p></li>
</ul>
<ul class="simple">
<li><p>Integridad de datos: las especificaciones del modelo de datos implican la validez de ciertas reglas de integridad.</p></li>
<li><p>Relatividad: cada atributo en una definición de tipo está relacionado con uno y solo un tipo con el mismo nombre, mientras que cada tipo puede corresponder con varios atributos en otros tipos.</p></li>
<li><p>Convertibilidad: Cada definición de tipo es única: no hay definiciones de tipo que lleven el mismo nombre o la misma colección de atributos.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>database warehouse.

base description (A16).
type product kind (A8) = description.

base color (A10).
base stock (I8).
base price (R4,2).
type product (I7) = description, color, stock, price, product kind.

base company name (A20).
base address (A20).
base zip (A6).
base city (A16).
type supplier (A8) = company name, address, zip, city.

type purchased product (A9) = supplier, product, price.

…

base prepaid (R4,2).
type sale (A7) = sold product, quantity, price, customer, date, prepaid.

end.
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span>  Cell In [1], line 19
    …
    ^
SyntaxError: invalid character &#39;…&#39; (U+2026)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Artículo Semantic (Big) Data Analysis: An Extensive Literature Review.</p>
<ul>
<li><p><a class="reference external" href="https://latamt.ieeer9.org/index.php/transactions/article/download/673/207">https://latamt.ieeer9.org/index.php/transactions/article/download/673/207</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="almacenamiento-de-datos-data-storage">
<h2>Almacenamiento de datos (Data Storage)<a class="headerlink" href="#almacenamiento-de-datos-data-storage" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>El almacenamiento se convierte en un desafío cuando el tamaño de los datos es muy grande.</p></li>
<li><p>Varias posibles soluciones pueden ayudar a resolver este problema.</p></li>
<li><p>Encontrar la solución de almacenamiento más eficiente es el objetivo de este paso.</p></li>
</ul>
<ul class="simple">
<li><p>Se necesitan diferentes tipos de bases de datos para manejar las diferentes variedades de datos, pero el uso de las mismas crea una sobrecarga en el sistema.</p></li>
<li><p>Es por este motivo que hay un nuevo concepto en el mundo de las bases de datos: la persistencia políglota. Es la idea de usar múltiples bases de datos para impulsar una sola aplicación.</p>
<ul>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Polyglot_persistence">https://en.wikipedia.org/wiki/Polyglot_persistence</a></p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>La persistencia políglota es la forma de compartir o dividir los datos en múltiples bases de datos y aprovechar su poder juntas.</p>
<ul>
<li><p>Relacionales</p></li>
<li><p>No SQL</p></li>
<li><p>Gráficas</p></li>
<li><p>En memoria</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Polyglot Persistance tiene tiempos de respuesta más rápidos.</p></li>
<li><p>Las bases de datos NoSQL escalan bien cuando se modelan correctamente para los datos que se desean almacenar.</p></li>
<li><p>La experiencia de usuario es mejor cuando se aprovecha el poder de múltiples bases de datos al mismo tiempo.</p></li>
<li><p>Por ejemplo, si desea buscar productos en una aplicación de comercio electrónico, se utiliza ElasticSearch, que devuelve los resultados en función de la relevancia, lo que MongoDB no puede hacer fácilmente.</p></li>
</ul>
<ul class="simple">
<li><p>Como contrapartida, tiene como desventaja la necesidad de contratar personal especializado para la integración de las bases de datos y una mayor cantidad de recursos de almacenamiento.</p></li>
</ul>
</section>
<section id="herramientas-de-almacenamiento-para-big-data">
<h2>Herramientas de almacenamiento para Big Data<a class="headerlink" href="#herramientas-de-almacenamiento-para-big-data" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>HDFS : Hadoop Distributed File System.</p></li>
<li><p>Ozone: Un <em>object store</em> para Hadoop, la próxima generación de HDFS.</p></li>
<li><p>GlusterFS: Sistema de archivos distribuido confiable.</p></li>
<li><p>Ceph: Proporciona almacenamiento de objetos, bloques y sistemas de archivos en un solo clúster.</p></li>
<li><p>Cloud storage: Amazon S3 Storage Service, IBM Cloud Object Storage, Azure Blob Storage, Google Cloud Storage.</p></li>
</ul>
</section>
<section id="hdfs">
<h2>HDFS<a class="headerlink" href="#hdfs" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>HDFS es un sistema de ficheros basado en Java que provee almacenamiento confiable y escalable.</p></li>
<li><p>Fue diseñado para abarcar grandes grupos de servidores básicos (commodity servers).</p></li>
<li><p>HDFS contiene una gran cantidad de datos y proporciona un acceso a los mismos de manera sencilla y fácil.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html">https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Para almacenar una inmensa cantidad de datos, los ficheros son guardados en varias máquinas.</p></li>
<li><p>Estos ficheros son guardados de forma redundante para poder rescatar el sistema en caso de pérdida de datos a causa de fallos.</p></li>
</ul>
<ul class="simple">
<li><p>HDFS también proporciona la disponibilidad de aplicaciones para procesamiento en paralelo durante el paso de ingestión de datos.</p></li>
<li><p>HDFS fue construido para soportar aplicaciones con grandes conjuntos de datos, incluyendo ficheros con terabytes de tamaño.</p></li>
</ul>
<ul class="simple">
<li><p>Utiliza una arquitectura maestro/esclavo, en la que cada clúster consta de un solo <em>Namenode</em> que administra las operaciones del sistema de archivos y admite <em>Datanodes</em> que administran el almacenamiento de datos en nodos de cómputo individuales.</p></li>
</ul>
<ul class="simple">
<li><p>Cuando HDFS toma datos, divide la información en partes separadas y las distribuye a diferentes nodos en un clúster, lo que permite el procesamiento paralelo.</p></li>
<li><p>El sistema de archivos en Ingestión de datos también copia cada pieza de datos varias veces y distribuye las copias a nodos individuales, colocando al menos una copia en un rack de servidor diferente.</p></li>
</ul>
</section>
<section id="apache-ozone">
<h2>Apache Ozone<a class="headerlink" href="#apache-ozone" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Ozone es un <em>object store</em> escalable, redundante, y distribuído para Hadoop.</p></li>
<li><p>Además de escalar a billones de objetos de cualquier tamaño, Ozone puede trabajar puede funcionar de manera efectiva en entornos en contenedores como Kubernetes y YARN.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://ozone.apache.org/">https://ozone.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Aplicaciones que utilizan frameworks como Apache Spark, YARN y Hive trabajan de forma nativa sin modificaciones.</p></li>
<li><p>Ozone está construido en una capa de almacenamiento en bloques altamente disponible y replicada llamada <em>Hadoop Distributed Data Store (HDDS)</em>.</p></li>
<li><p>Ozone viene un una biblioteca cliente para Java, soporte para el protocolo S3, y una interfaz de línea de comandos.</p></li>
</ul>
<ul class="simple">
<li><p>Ozone consta de volúmenes, cubos (<em>buckets</em>) y claves:</p>
<ul>
<li><p>Los volúmenes son similares a las cuentas de usuario. Solo los administradores pueden crear o eliminar volúmenes.</p></li>
<li><p>Los cubos son similares a los directorios. Un cubo puede contener cualquier cantidad de claves, pero los cubos no pueden contener otros cubos.</p></li>
<li><p>Las claves son similares a los archivos.</p></li>
</ul>
</li>
</ul>
</section>
<section id="glusterfs">
<h2>GlusterFS<a class="headerlink" href="#glusterfs" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Gluster es un sistema de ficheros en red escalable libre y de fuente abierta.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://docs.gluster.org/en/latest/">https://docs.gluster.org/en/latest/</a> | <a class="reference external" href="https://www.gluster.org/">https://www.gluster.org/</a></p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Los sistemas de almacenamiento de escalamiento horizontal basados en GlusterFS son adecuados para datos no estructurados, como documentos, imágenes, archivos de audio y video, y archivos de registro.</p></li>
<li><p>Con esto, podemos crear grandes soluciones de almacenamiento distribuido para transmisión de medios, análisis de datos, ingesta de datos y otras tareas intensivas en datos y ancho de banda.</p></li>
</ul>
<ul class="simple">
<li><p>La arquitectura GlusterFS agrega recursos informáticos, de almacenamiento y de E/S en un espacio de nombres global.</p></li>
<li><p>Cada servidor más el almacenamiento básico adjunto (configurado como almacenamiento adjunto directo, JBOD o utilizando una red de área de almacenamiento) se considera un nodo.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://en.wikipedia.org/wiki/Gluster">https://en.wikipedia.org/wiki/Gluster</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>La capacidad se escala agregando nodos adicionales o agregando almacenamiento adicional a cada nodo.</p></li>
<li><p>El rendimiento aumenta al implementar el almacenamiento entre más nodos.</p></li>
<li><p>La alta disponibilidad se logra mediante la replicación de datos de <em>n</em> vías entre nodos.</p></li>
</ul>
</section>
<section id="ceph">
<h2>Ceph<a class="headerlink" href="#ceph" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>La base de Ceph es el <em>Reliable Autonomic Distributed Object Store (RADOS)</em></p></li>
<li><p>Proporciona a las aplicaciones almacenamiento de objetos, bloques y sistemas de archivos en un solo clúster de almacenamiento unificado.</p></li>
<li><p>Esto lo hace altamente confiable y fácil de gestionar.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://ceph.io/">https://ceph.io/</a></p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>El algoritmo CRUSH de Ceph libera a los clústeres de almacenamiento de las limitaciones de escalabilidad y rendimiento impuestas por el mapeo de tablas de datos centralizados.</p></li>
<li><p>Replica y reequilibra los datos dentro del clúster de forma dinámica, eliminando esta tediosa tarea para los administradores, al tiempo que ofrece escalabilidad infinita y alto rendimiento.</p></li>
</ul>
<ul class="simple">
<li><p>Recursos:</p>
<ul>
<li><p>Democratising Data Storage. DIGITAL REPORT 2021:</p></li>
<li><p><a class="reference external" href="https://ceph.io/assets/pdfs/report-dec2021.pdf">https://ceph.io/assets/pdfs/report-dec2021.pdf</a>.</p></li>
<li><p>Ceph Quickstart: <a class="reference external" href="https://rook.io/docs/rook/v1.8/quickstart.html">https://rook.io/docs/rook/v1.8/quickstart.html</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="amazon-services">
<h2>Amazon Services<a class="headerlink" href="#amazon-services" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Amazon Simple Storage Service (Amazon S3) es un almacenamiento de objetos con una interfaz web simple que permite almacenar y recuparar cualquier volumen de datos desde cualquier lugar en Internet.</p></li>
<li><p>Está diseñado para entregar un 99.999% de durabilidad y escalar a más de trillones de objetos en todo el mundo.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://aws.amazon.com/free/storage/s3/">https://aws.amazon.com/free/storage/s3/</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Amazon Redshift es un servicio de <em>data warehouse</em> en la nube.</p></li>
<li><p>Utiliza SQL para analizar datos estructurados y semiestructurados en almacenamientos de datos, bases de datos operativas y lagos de datos, con hardware y machine learning diseñado por AWS.</p></li>
<li><p>Redshift permite guardar los resultados de las consultas en el <em>S3 data lake</em> utilizando formatos abiertos como Apache Parquet para su posterior análisis con Amazon EMR, Amazon Athena, y Amazon SageMaker.</p>
<ul>
<li><p>Extraído de: Amazon Redshift <a class="reference external" href="https://aws.amazon.com/redshift/">https://aws.amazon.com/redshift/</a></p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Todos los servicios de Amazon para análisis en Amazon:</p>
<ul>
<li><p><a class="reference external" href="https://aws.amazon.com/es/big-data/datalakes-and-analytics/">https://aws.amazon.com/es/big-data/datalakes-and-analytics/</a></p></li>
</ul>
</li>
</ul>
</section>
<section id="microsoft-azure-data-lake-store">
<h2>Microsoft Azure Data Lake Store<a class="headerlink" href="#microsoft-azure-data-lake-store" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Lago de datos seguro y escalable de forma masiva para sus cargas de trabajo de análisis de alto rendimiento.</p></li>
<li><p>Fuente: <a class="reference external" href="https://azure.microsoft.com/es-es/services/storage/data-lake-storage/">https://azure.microsoft.com/es-es/services/storage/data-lake-storage/</a>.</p></li>
<li><p>Soluciones en Big Data: <a class="reference external" href="https://azure.microsoft.com/es-es/solutions/big-data/">https://azure.microsoft.com/es-es/solutions/big-data/</a>.</p></li>
</ul>
<ul class="simple">
<li><p>Microsoft Azure Data Lake Analytics</p></li>
<li><p>Servicio de análisis en la nube para desarrollar y ejecutar fácilmente programas de procesamiento y transformación de petabytes de datos en paralelo de forma masiva con los lenguajes U-SQL, R, Python y .NET.</p></li>
<li><p>Sin infraestructura para administrar, se procesan los datos a petición, escalando las unidades de análisis de forma instantánea.</p></li>
<li><p>Fuente: <a class="reference external" href="https://azure.microsoft.com/es-es/services/data-lake-analytics/#overview">https://azure.microsoft.com/es-es/services/data-lake-analytics/#overview</a>.</p></li>
</ul>
</section>
<section id="google-bigquery">
<h2>Google BigQuery<a class="headerlink" href="#google-bigquery" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Almacén de datos multinube de alta escalabilidad, rentable y sin servidor.</p>
<ul>
<li><p><a class="reference external" href="https://cloud.google.com/bigquery">https://cloud.google.com/bigquery</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Google Cloud Smart Analytics Platform:</p></li>
<li><p>Es una plataforma de analíticas flexible, abierta y segura que ayuda a convertirse en una organización basada en la inteligencia.</p></li>
<li><p>Se basa en décadas de innovación de Google en el sector de la inteligencia artificial y en el desarrollo de servicios a escala de Internet.</p>
<ul>
<li><p>Extraído de <a class="reference external" href="https://cloud.google.com/solutions/smart-analytics">https://cloud.google.com/solutions/smart-analytics</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="databricks">
<h2>Databricks<a class="headerlink" href="#databricks" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Fundada en 2013 por los creadores originales de Apache Spark, Delta Lake y MLflow, Databricks reúne ingeniería de datos, ciencia y análisis en una plataforma abierta y unificada para que los equipos de datos puedan colaborar e innovar más rápido.</p></li>
<li><p>Está alojada en Microsoft Azure.</p>
<ul>
<li><p>Fuente: <a class="reference external" href="https://databricks.com/">https://databricks.com/</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="snowflake">
<h2>Snowflake<a class="headerlink" href="#snowflake" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Permite acceder, integrar y analizar datos de manera fácil y segura con una escalabilidad casi infinita, habilitada automáticamente o sobre la marcha.</p></li>
<li><p>Está alojada en Amazon AWS.</p>
<ul>
<li><p>Fuente: <a class="reference external" href="https://www.snowflake.com/">https://www.snowflake.com/</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="nosql-databases">
<h2>NoSQL databases<a class="headerlink" href="#nosql-databases" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Las bases de datos NoSQL, (no solo SQL) o no relacionales, se utilizan mayoritariamente para la recopilación y análisis de Big Data.</p></li>
<li><p>Permiten la organización dinámica de datos no estructurados.</p></li>
<li><p>Las bases de datos relacionales, por otro lado, tienen un diseño estructurado y tabular.</p></li>
</ul>
<ul class="simple">
<li><p>Existen diversos tipos de bases de datos No SQL:</p>
<ul>
<li><p>Bases de datos de documentos (MongoDB, Couch DB)</p></li>
<li><p>Pares de valores (Amazon DynamoDB, Redis)</p></li>
<li><p>Columnares (Apache Cassandra, Apache HBase)</p></li>
<li><p>Gráficas (Neo4j, Stardog)</p></li>
</ul>
</li>
</ul>
</section>
<section id="bases-de-datos-de-documentos">
<h2>Bases de datos de documentos<a class="headerlink" href="#bases-de-datos-de-documentos" title="Permalink to this heading">#</a></h2>
</section>
<section id="mongodb">
<h2>MongoDB<a class="headerlink" href="#mongodb" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>MongoDB es una base de datos distribuida de propósito general, basada en documentos, creada para desarrolladores de aplicaciones modernas y para la era de la nube.</p></li>
<li><p>MongoDB es una base de datos de documentos, lo que significa que almacena datos en documentos similares a JSON.</p>
<ul>
<li><p>Fuente: <a class="reference external" href="https://www.mongodb.com/">https://www.mongodb.com/</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="apache-couchdb">
<h2>Apache CouchDB<a class="headerlink" href="#apache-couchdb" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Apache CouchDB es una base de datos NoSQL orientada a documentos de código abierto, implementada en Erlang.</p></li>
<li><p>CouchDB usa múltiples formatos y protocolos para almacenar, transferir y procesar sus datos.</p></li>
<li><p>Utiliza JSON para almacenar datos, JavaScript como lenguaje de consulta usando MapReduce, y HTTP para una API.</p></li>
</ul>
<ul class="simple">
<li><p>El protocolo <em>Couch Replication</em> permite que los datos fluyan sin problemas entre los clústeres de servidores y los teléfonos móviles / navegadores web.</p>
<ul>
<li><p>Fuente: <a class="reference external" href="https://couchdb.apache.org/">https://couchdb.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="couchbase">
<h2>Couchbase<a class="headerlink" href="#couchbase" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Couchbase es una base de datos en la nube NoSQL distribuida.</p></li>
<li><p>Ofrece versatilidad, rendimiento, escalabilidad y un valor financiero inigualables en implementaciones informáticas en la nube, en las instalaciones híbridas, en la nube distribuida y en edge computing.</p>
<ul>
<li><p>Fuente: <a class="reference external" href="https://couchbase.com/">https://couchbase.com/</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="bases-de-datos-con-pares-de-valores">
<h2>Bases de datos con pares de valores<a class="headerlink" href="#bases-de-datos-con-pares-de-valores" title="Permalink to this heading">#</a></h2>
</section>
<section id="redis-database">
<h2>Redis database<a class="headerlink" href="#redis-database" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Redis es un almacén de estructura de datos en memoria de código abierto (con licencia BSD), que se utiliza como base de datos, caché y agente de mensajes.</p>
<ul>
<li><p>Fuente: <a class="reference external" href="https://redislabs.com/">https://redislabs.com/</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="bases-de-datos-columnares">
<h2>Bases de datos columnares<a class="headerlink" href="#bases-de-datos-columnares" title="Permalink to this heading">#</a></h2>
</section>
<section id="apache-cassandra">
<h2>Apache Cassandra<a class="headerlink" href="#apache-cassandra" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Apache Cassandra es una base de datos distribuida NoSQL de código abierto.</p></li>
<li><p>La escalabilidad lineal y la tolerancia a fallas comprobada en hardware básico o infraestructura en la nube la convierten en la plataforma perfecta para datos de misión crítica.</p></li>
<li><p>El soporte de Cassandra para la replicación en múltiples centros de datos es el mejor en su clase, lo que proporciona una latencia más baja para sus usuarios.</p>
<ul>
<li><p>Fuente: <a class="reference external" href="https://cassandra.apache.org/">https://cassandra.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="apache-hbase">
<h2>Apache HBase<a class="headerlink" href="#apache-hbase" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Es una base de datos distribuida no relacional open source modelada en base al artículo científico <em>Google’s Bigtable: A Distributed Storage System for Structured Data</em> de Chang et al.</p></li>
</ul>
<ul class="simple">
<li><p>Así como Bigtable aprovecha el almacenamiento de datos distribuido proporcionado por el sistema de archivos de Google, Apache HBase proporciona capacidades similares a las de Bigtable junto con Hadoop y HDFS.</p>
<ul>
<li><p>Extraído de: Apache HBase Docs &amp; website: <a class="reference external" href="https://hbase.apache.com/">https://hbase.apache.com/</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="bases-de-datos-graficas">
<h2>Bases de datos gráficas<a class="headerlink" href="#bases-de-datos-graficas" title="Permalink to this heading">#</a></h2>
</section>
<section id="amazon-neptune">
<h2>Amazon Neptune<a class="headerlink" href="#amazon-neptune" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Amazon Neptune es un motor de base de datos de gráficos de alto rendimiento optimizado para almacenar miles de millones de relaciones y consultar el gráfico con una latencia de milisegundos.</p></li>
<li><p>Admite los modelos de gráficos populares Property Graph y Resource Description Framework (RDF) del W3C, así como sus lenguajes de consulta asociados, Apache TinkerPop Gremlin y SPARQL.</p>
<ul>
<li><p>Fuente: <a class="reference external" href="https://aws.amazon.com/es/nosql/graph/">https://aws.amazon.com/es/nosql/graph/</a>.</p></li>
<li><p><a class="reference external" href="https://aws.amazon.com/es/neptune/">https://aws.amazon.com/es/neptune/</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="stardog">
<h2>Stardog<a class="headerlink" href="#stardog" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Stardog es la única plataforma de gráficos que conecta datos en la capa de cómputo en lugar de la capa de almacenamiento.</p></li>
<li><p>No se necesita migrar las bases de datos ni copiarlas.</p></li>
<li><p>Los conectores facilitan la virtualización de datos en Stardog y consultan los datos conectados mediante aplicaciones, herramientas de BI y más.</p>
<ul>
<li><p>Fuente: <a class="reference external" href="https://www.stardog.com/">https://www.stardog.com/</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Cómo funcionan los gráficos de conocimiento:</p>
<ul>
<li><p><a class="reference external" href="https://www.stardog.com/knowledge-graph/">https://www.stardog.com/knowledge-graph/</a>.</p></li>
</ul>
</li>
<li><p>Tutorial Stardog:</p>
<ul>
<li><p><a class="reference external" href="https://www.stardog.com/tutorials/getting-started-1">https://www.stardog.com/tutorials/getting-started-1</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="neo4j">
<h2>Neo4j<a class="headerlink" href="#neo4j" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Neo4j permite construir aplicaciones y flujos de trabajos de ML.</p></li>
<li><p>Almacena y administra datos manteniendo relaciones que brindan consultas veloces, un contexto más profundo para el análisis y un modelo de datos modificable sin complicaciones.</p>
<ul>
<li><p>Fuente: <a class="reference external" href="https://neo4j.com/">https://neo4j.com/</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="procesamiento-analisis-y-consulta-de-datos">
<h2>Procesamiento, análisis y consulta de datos<a class="headerlink" href="#procesamiento-analisis-y-consulta-de-datos" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Los datos recolectados en la fase anterior serán procesados en este paso.</p></li>
<li><p>Aquí, el sistema de procesamiento de canalización de datos enruta los datos a un destino diferente, clasifica el flujo de datos y es el primer punto donde puede tener lugar el análisis.</p></li>
<li><p>Esta es la capa donde las consultas (<em>queries</em>) y el proceso analítico activo se ejecutan.</p></li>
</ul>
<ul class="simple">
<li><p>Para ello, los analistas emplean diferentes herramientas y estrategias como, por ejemplo:</p>
<ul>
<li><p>Modelado estadístico</p></li>
<li><p>Algoritmos</p></li>
<li><p>Inteligencia artificial (AI)</p></li>
<li><p>Minería de datos</p></li>
<li><p>Aprendizaje automático (ML)</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Para análisis fuera de línea, se utiliza un sistema de procesamiento por lotes simple.</p></li>
<li><p>Apache Sqoop es la aplicación que se encarga de esto.</p></li>
<li><p>Transfiere eficientemente datos estructurados entre Apache Hadoop y las bases de datos relacionales.</p></li>
<li><p>Spark por otro lado, es utilizado mayoritariamente para el análisis y procesamiento de datos en tiempo real.</p></li>
<li><p>Otra herramienta conocida pero menos utilizada es Apache Storm.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://sqoop.apache.org/">https://sqoop.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>KNIME hace que la comprensión de datos y el diseño de flujos de trabajo de ciencia de datos y componentes reutilizables sean accesibles para todos.</p>
<ul>
<li><p><a class="reference external" href="https://www.knime.com/">https://www.knime.com/</a>.</p></li>
</ul>
</li>
<li><p>Apache Mahout es un framework distribuido de álgebra linear y Scala DSL matemáticamente expresivo.</p>
<ul>
<li><p><a class="reference external" href="https://mahout.apache.org/">https://mahout.apache.org/</a>.</p></li>
</ul>
</li>
<li><p>Weka 3: Machine Learning Software en Java para hacer análisis simple.</p>
<ul>
<li><p><a class="reference external" href="https://www.cs.waikato.ac.nz/ml/weka/">https://www.cs.waikato.ac.nz/ml/weka/</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="apache-sqoop-in-the-attic">
<h2>Apache Sqoop (in the Attic)<a class="headerlink" href="#apache-sqoop-in-the-attic" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Transfiere eficientemente datos estructurados entre Apache Hadoop y las bases de datos relacionales.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://sqoop.apache.org/">https://sqoop.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Se puede usar Sqoop para importar datos desde un sistema de administración de bases de datos relacionales (RDBMS) como MySQL, Oracle, o un mainframe al sistema de archivos distribuidos de Hadoop (HDFS), transformar los datos utilizando Hadoop MapReduce, y luego exportar los datos nuevamente a un RDBMS.</p></li>
</ul>
</section>
<section id="apache-spark">
<h2>Apache Spark<a class="headerlink" href="#apache-spark" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Framework de procesamiento paralelo y de código abierto para ejecutar aplicaciones de análisis de datos a gran escala en sistemas agrupados.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://spark.apache.org/">https://spark.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Se utiliza para realizar trabajos informáticos con grandes cargas de datos junto a Apache Kafka.</p></li>
<li><p>Fue desarrollado en la University of California, Berkeley.</p></li>
<li><p>Con Spark ejecutándose en Apache Hadoop YARN, los desarrolladores pueden crear aplicaciones para explotar el poder de Spark, obtener información y enriquecer sus cargas de trabajo de ciencia de datos dentro de un único conjunto de datos compartidos en Hadoop.</p></li>
</ul>
</section>
<section id="apache-storm">
<h2>Apache Storm<a class="headerlink" href="#apache-storm" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Es un sistema distribuido open source para procesar datos en tiempo real durante la ingesta de datos.</p></li>
<li><p>Es escalable, tiene tolerancia a fallos, y es fácil de configurar y operar.</p></li>
<li><p>Facilita el procesamiento confiable de flujos ilimitados de datos, haciendo para el procesamiento en tiempo real lo que Hadoop hizo para el procesamiento por lotes.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://storm.apache.org/">https://storm.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Casos de uso:</p>
<ul>
<li><p>Análisis en tiempo real</p></li>
<li><p>Aprendizaje automático</p></li>
<li><p>Monitoreo continuo de operaciones</p></li>
<li><p>RPC distribuido, ETL, y más.</p></li>
</ul>
</li>
</ul>
</section>
<section id="visualizacion-de-datos-big-data-visualization">
<h2>Visualización de datos (Big Data Visualization)<a class="headerlink" href="#visualizacion-de-datos-big-data-visualization" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>La fase de visualización o presentación es donde los usuarios pueden sentir el VALOR de los DATOS.</p></li>
<li><p>La visualización de hallazgos ayuda a tomar mejores decisiones de negocios.</p></li>
<li><p>Aquí se generan informes por tipo de audiencia (comerciales, marketing, estrategia, técnicos, etc).</p></li>
</ul>
</section>
<section id="elastic-stack">
<h2>Elastic Stack<a class="headerlink" href="#elastic-stack" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Elasticsearch es el componente central de Elastic Stack, un conjunto de herramientas de código abierto para la ingesta, el enriquecimiento, el almacenamiento, el análisis y la visualización de datos.</p></li>
<li><p>El ELK Stack se compone de las aplicaciones Elasticsearch, Logstash, Kibana, y Beats.</p></li>
<li><p>Actualmente se lo conoce como Elastic Stack, nombre que le permite agregar nuevas funcionalidades.</p></li>
<li><p>Kibana es la interfaz de usuario gratuita y abierta que permite visualizar los datos.</p></li>
</ul>
<ul class="simple">
<li><p>Fuente: <a class="reference external" href="https://www.elastic.co/what-is/elasticsearch">https://www.elastic.co/what-is/elasticsearch</a>.</p></li>
</ul>
<ul class="simple">
<li><p>Casos de uso:</p>
<ul>
<li><p>Búsqueda de aplicaciones</p></li>
<li><p>Búsqueda de sitio web</p></li>
<li><p>Búsqueda Empresarial</p></li>
<li><p>Logging y analíticas de log</p></li>
<li><p>Métricas de infraestructura y monitoreo de contenedores</p></li>
<li><p>Monitoreo de rendimiento de aplicaciones</p></li>
<li><p>Análisis y visualización de datos geoespaciales</p></li>
<li><p>Analítica de Seguridad</p></li>
<li><p>Analítica de Negocios</p></li>
</ul>
</li>
</ul>
</section>
<section id="salesforce-google-y-microsoft">
<h2>Salesforce, Google y Microsoft<a class="headerlink" href="#salesforce-google-y-microsoft" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Otras herramientas de modelización y visualización de datos son las proporcionadas por Salesforce, Google y Microsoft.</p></li>
<li><p>Salesforce adquirió Tableau y google hizo lo mismo con Looker en 2019.</p></li>
<li><p>La reciente integración entre estos productos le permitirán al usuario modelar datos con LookML y usar Tableau, o Looker para explorar ese modelo.</p></li>
</ul>
<ul class="simple">
<li><p><a class="reference external" href="https://looker.com/google-cloud">https://looker.com/google-cloud</a>.</p></li>
<li><p><a class="reference external" href="https://www.tableau.com/">https://www.tableau.com/</a>.</p></li>
</ul>
<ul class="simple">
<li><p>Microsoft cuenta por su parte con PowerBI.</p>
<ul>
<li><p><a class="reference external" href="https://powerbi.microsoft.com/es-es/">https://powerbi.microsoft.com/es-es/</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="monitoreo-de-datos">
<h2>Monitoreo de datos<a class="headerlink" href="#monitoreo-de-datos" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>El seguimiento continuo de los datos es una parte importante de los mecanismos de gobernanza.</p></li>
<li><p>Apache Flume es útil para procesar datos de registro.</p></li>
<li><p>Apache Storm se utiliza para el monitoreo de operaciones.</p></li>
<li><p>Apache Spark sirve para transmisión de datos, procesamiento de gráficos y aprendizaje automático.</p></li>
<li><p>El monitoreo puede ocurrir en el paso de almacenamiento de datos.</p></li>
</ul>
</section>
<section id="herramientas-para-big-data">
<h2>Herramientas para Big Data<a class="headerlink" href="#herramientas-para-big-data" title="Permalink to this heading">#</a></h2>
</section>
<section id="apache-mesos">
<h2>Apache Mesos<a class="headerlink" href="#apache-mesos" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Un núcleo (<em>kernel</em>) de sistemas distribuidos.</p></li>
<li><p>Mesos está construido usando los mismos principios que el <em>kernel</em> de Linux, solo que en un nivel diferente de abstracción.</p></li>
<li><p>abstrae la CPU, la memoria, el almacenamiento y otros recursos informáticos de las máquinas (físicas o virtuales), lo que permite que los sistemas distribuidos elásticos y tolerantes a fallas se construyan fácilmente y se ejecuten de manera efectiva.</p></li>
</ul>
<ul class="simple">
<li><p>El <em>kernel</em> de Mesos se ejecuta en todas las máquinas y proporciona aplicaciones (p. ej., Hadoop, Spark, Kafka, Elasticsearch) y una API para la gestión y programación de recursos para todo el centro de datos y entornos de nube.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://mesos.apache.org/">https://mesos.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="apache-zookeeper">
<h2>Apache Zookeeper<a class="headerlink" href="#apache-zookeeper" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>ZooKeeper es un servicio centralizado para mantener la información de configuración, nombrar, brindar sincronización distribuida y servicios grupales.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://zookeeper.apache.org/">https://zookeeper.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="apache-ambari-in-the-attic">
<h2>Apache Ambari (in the Attic)<a class="headerlink" href="#apache-ambari-in-the-attic" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>El proyecto Apache Ambari tiene como objetivo simplificar la administración de Hadoop mediante el desarrollo de software para el aprovisionamiento, la administración y el monitoreo de clústeres de Apache Hadoop.</p></li>
<li><p>Ambari proporciona una interfaz de usuario web de administración de Hadoop intuitiva y fácil de usar respaldada por sus API RESTful.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://ambari.apache.org/">https://ambari.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="apache-ranger">
<h2>Apache Ranger<a class="headerlink" href="#apache-ranger" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Apache Ranger™ es un framework para habilitar, monitorear y administrar la seguridad integral de los datos en toda la plataforma Hadoop.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://ranger.apache.org/">https://ranger.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="apache-sentry">
<h2>Apache Sentry<a class="headerlink" href="#apache-sentry" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Apache Sentry™ es un sistema para hacer cumplir la autorización detallada basada en roles para datos y metadatos almacenados en un clúster de Hadoop.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://sentry.apache.org/">https://sentry.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="apache-airflow">
<h2>Apache Airflow<a class="headerlink" href="#apache-airflow" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Apache Airflow es una plataforma que permite crear, programar temporalmente, y monitorar flujos de trabajo utilizando Python como lenguaje.</p></li>
<li><p>Automatiza la ingestas de datos, acciones de mantenimiento periódicas y realiza tareas de administración.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://airflow.apache.org/">https://airflow.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Un flujo de trabajo de ejemplo puede ser:</p>
<ul>
<li><p>Obtener datos de una base de datos relacional como PosgreSQL para enviarlos a Kafka.</p></li>
<li><p>Transformar los datos con Apache Spark y finalmente enviar un mensaje de finalización.</p></li>
</ul>
</li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./docs/jupyter_execute/docs/jupyter_execute"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#procesos-en-big-data">Procesos en Big Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ingestion-de-datos">Ingestión de datos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cuestiones-a-considerar">Cuestiones a considerar</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#buenas-practicas-en-ingestion-de-datos">Buenas prácticas en ingestión de datos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#herramientas-para-la-ingesta-de-datos">Herramientas para la ingesta de datos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sistemas-de-mensajeria">Sistemas de mensajería</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problemas-en-la-ingesta-de-datos">Problemas en la ingesta de datos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-semantico-de-datos-sdm">Modelo semántico de datos (SDM)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#almacenamiento-de-datos-data-storage">Almacenamiento de datos (Data Storage)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#herramientas-de-almacenamiento-para-big-data">Herramientas de almacenamiento para Big Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hdfs">HDFS</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-ozone">Apache Ozone</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#glusterfs">GlusterFS</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ceph">Ceph</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#amazon-services">Amazon Services</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#microsoft-azure-data-lake-store">Microsoft Azure Data Lake Store</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#google-bigquery">Google BigQuery</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#databricks">Databricks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#snowflake">Snowflake</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nosql-databases">NoSQL databases</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bases-de-datos-de-documentos">Bases de datos de documentos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mongodb">MongoDB</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-couchdb">Apache CouchDB</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#couchbase">Couchbase</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bases-de-datos-con-pares-de-valores">Bases de datos con pares de valores</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#redis-database">Redis database</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bases-de-datos-columnares">Bases de datos columnares</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-cassandra">Apache Cassandra</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-hbase">Apache HBase</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bases-de-datos-graficas">Bases de datos gráficas</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#amazon-neptune">Amazon Neptune</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stardog">Stardog</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#neo4j">Neo4j</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#procesamiento-analisis-y-consulta-de-datos">Procesamiento, análisis y consulta de datos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-sqoop-in-the-attic">Apache Sqoop (in the Attic)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-spark">Apache Spark</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-storm">Apache Storm</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizacion-de-datos-big-data-visualization">Visualización de datos (Big Data Visualization)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#elastic-stack">Elastic Stack</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#salesforce-google-y-microsoft">Salesforce, Google y Microsoft</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#monitoreo-de-datos">Monitoreo de datos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#herramientas-para-big-data">Herramientas para Big Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-mesos">Apache Mesos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-zookeeper">Apache Zookeeper</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-ambari-in-the-attic">Apache Ambari (in the Attic)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-ranger">Apache Ranger</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-sentry">Apache Sentry</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-airflow">Apache Airflow</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Fortinux - Marcelo Horacio Fortino
</p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <div>
<a href="https://creativecommons.org/licenses/by-sa/4.0/"><img src="https://licensebuttons.net/l/by-sa/3.0/88x31.png"></a>
    Esta obra está sujeta a la licencia Reconocimiento-CompartirIgual 4.0 Internacional de Creative Commons. Para ver una copia de esta licencia, visite <a href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0 license</a>. Puede hallar permisos más allá de los concedidos con esta licencia en <a href="https://fortinux.com" rel="nofollow">https://fortinux.com</a>. Sugerencias y comentarios a <a href="mailto:info@fortinux.com">info@fortinux.com</a>.
</div>

</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../../_static/scripts/bootstrap.js?digest=ac02cc09edc035673794"></script>
<script src="../../../../_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>