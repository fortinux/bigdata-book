
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Ingesta y almacenamiento de datos &#8212; Curso Introducción a Big Data</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'BigData-es002';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Bases de datos para Big Data" href="BigData-es003.html" />
    <link rel="prev" title="Big Data: Definición y características" href="BigData-es001.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Curso Introducción a Big Data - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Curso Introducción a Big Data - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Introducción a Big Data
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="BigData-es001.html">Definición y características</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Ingesta y almacenamiento de datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="BigData-es003.html">Bases de datos para Big Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="BigData-es004.html">Consulta y visualización de datos</a></li>

<li class="toctree-l1"><a class="reference internal" href="BigData-es004MongoDB.html">Tutorial MongoDB</a></li>
<li class="toctree-l1"><a class="reference internal" href="BigData-es005.html">Frameworks y aplicaciones</a></li>
<li class="toctree-l1"><a class="reference internal" href="BigData-es005Hadoop.html">Tutorial Apache Hadoop</a></li>
<li class="toctree-l1"><a class="reference internal" href="BigData-es005Kafka.html">Tutorial Apache Kafka</a></li>
<li class="toctree-l1"><a class="reference internal" href="BigData-es007.html">Big Data Science</a></li>
<li class="toctree-l1"><a class="reference internal" href="BigData-es008.html">Big Data stacks y Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="BigData-es008sparkMLlib.html">Tutorial Spark</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/fortinux/bigdata-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/fortinux/bigdata-book/issues/new?title=Issue%20on%20page%20%2FBigData-es002.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/BigData-es002.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Ingesta y almacenamiento de datos</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#procesos-en-big-data">Procesos en Big Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ingestion-de-datos">Ingestión de datos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cuestiones-a-considerar">Cuestiones a considerar</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#buenas-practicas-en-ingestion-de-datos">Buenas prácticas en ingestión de datos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problemas-en-la-ingesta-de-datos">Problemas en la ingesta de datos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#procesamiento-de-datos-en-tiempo-real">Procesamiento de datos en tiempo real</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-spark">Apache Spark</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-flume">Apache Flume</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-flink">Apache Flink</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sistemas-de-mensajeria">Sistemas de mensajería</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-kafka">Apache Kafka</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-activemq">Apache ActiveMQ</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-pulsar">Apache Pulsar</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pub-sub">Pub/Sub</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#otras-herramientas">Otras herramientas</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#logstash">Logstash</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-nifi">Apache Nifi</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-beam">Apache Beam</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-samza">Apache Samza</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-airflow">Apache Airflow</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#astro">Astro</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dbt">DBT</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Otras herramientas</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-semantico-de-datos-sdm">Modelo semántico de datos (SDM)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#almacenamiento-de-datos-data-storage">Almacenamiento de datos (Data Storage)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#persistencia-poliglota">Persistencia políglota</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#herramientas-de-almacenamiento-para-big-data">Herramientas de almacenamiento para Big Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hdfs">HDFS</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-ozone">Apache Ozone</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#glusterfs">GlusterFS</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ceph">Ceph</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#minio">MinIO</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#amazon-services">Amazon Services</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#microsoft-azure-data-lake-store">Microsoft Azure Data Lake Store</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#google-bigquery">Google BigQuery</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-warehouses-data-lakes-lakehouses">Data warehouses / Data lakes / Lakehouses</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#snowflake">Snowflake</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#databricks">Databricks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#delta-lake">Delta Lake</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-iceberg">Apache Iceberg</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-hudi">Apache Hudi</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-xtable">Apache XTable</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nosql-databases">NoSQL databases</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#herramientas-de-la-asf-para-big-data">Herramientas de la ASF para Big Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-mesos">Apache Mesos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-zookeeper">Apache Zookeeper</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-ambari">Apache Ambari</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-ranger">Apache Ranger</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-sentry-attic">Apache Sentry (Attic)</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="ingesta-y-almacenamiento-de-datos">
<h1>Ingesta y almacenamiento de datos<a class="headerlink" href="#ingesta-y-almacenamiento-de-datos" title="Link to this heading">#</a></h1>
<section id="procesos-en-big-data">
<h2>Procesos en Big Data<a class="headerlink" href="#procesos-en-big-data" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Existen varias metodologías y modelos disponibles en el mercado para la recopilación, almacenamiento, consulta, visualización de datos, y su posterior acción.</p></li>
<li><p>Provienen del mundo de la minería de datos, y entre ellas se pueden mencionar KDD (<em>Knowledge Discovery in Databases</em>), SEMMA y CRISP-DM.</p></li>
<li><p>CRISP-DM (<em>Cross Industry Standard Process for Data Mining</em>) por ejemplo, es un modelo de procesos estandarizado e iterativo centrado en el negocio.</p></li>
<li><p>Fue desarrollado para ser distribuido libremente y promueve las mejores prácticas en minería de datos. Más información en la sección <a class="reference internal" href="BigData-es007.html#content-references-crisp-dm"><span class="std std-ref">Procesos en la ciencia de datos</span></a>.</p></li>
</ul>
<ul class="simple">
<li><p>Para el NIST Big Data interoperability Framework (NBDIF) - Version 3.0 Final <span id="id1">[<a class="reference internal" href="intro.html#id3" title="Wo Chang and Nancy Grady. Nist big data interoperability framework: volume 1, definitions. 2019-10-21 2019. doi:https://doi.org/10.6028/NIST.SP.1500-1r2.">CG19</a>]</span> (Pág.29), el ciclo de vida del análisis de los datos se compone de cinco fases:</p>
<ul>
<li><p>Captura de los datos en su formato original. Ingestión de datos (<em>Data Ingestion</em>).</p></li>
<li><p>Preparación y modelado. Almacenamiento de datos (<em>Data Storage</em>).</p></li>
<li><p>Análisis y consulta de datos (<em>Data Processing / Data Query</em>).</p></li>
<li><p>Visualización de los datos. (<em>Data Visualization</em>).</p></li>
<li><p>Acción con el uso de los mismos.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Se verán a continuación las fases una a una más en detalle.</p></li>
</ul>
</section>
<section id="ingestion-de-datos">
<h2>Ingestión de datos<a class="headerlink" href="#ingestion-de-datos" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Obtención, procesado (separación, agrupación, filtrado) y limpieza de datos (eliminar duplicados y errores).</p></li>
<li><p>Es el primer paso donde se obtienen los datos que provienen de varias fuentes y que irán a dispositivos de almacenamiento para su posterior acceso, uso y análisis por parte de la organización.</p></li>
<li><p>En esta etapa los datos son priorizados y categorizados.</p></li>
</ul>
<ul class="simple">
<li><p>Su destinación es generalmente:</p>
<ul>
<li><p>Un Almacén de datos (<em>data warehouse</em>): <em>Snowflake, Amazon Redshift, Google BigQuery, Azure Synapse</em>, o</p></li>
<li><p>Un Lago de datos: (<em>data lake</em>): <em>Databricks</em> con datos estructurados, semi estructurados y no estructurados.</p></li>
</ul>
</li>
</ul>
</section>
<section id="cuestiones-a-considerar">
<h2>Cuestiones a considerar<a class="headerlink" href="#cuestiones-a-considerar" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Velocidad de la entrada de datos (frecuencia: <em>Batch, Real-Time</em>).</p></li>
<li><p>Volumen de los datos.</p></li>
<li><p>Variedad (formato: datos estructurados, Semi-estructurados, no estructurados).</p></li>
</ul>
<ul class="simple">
<li><p>Otras cuestiones a tener en cuenta son la veracidad de esos datos (si son confiables), su variabilidad, y el valor de los mismos.</p></li>
</ul>
<ul class="simple">
<li><p>La velocidad de datos se ocupa de la velocidad a la que fluyen los datos desde diferentes fuentes, como máquinas, redes, IoT, interacción humana, sitios de medios, y redes sociales, entre otras.</p></li>
<li><p>El movimiento de datos puede ser masivo o continuo en la ingestión de datos.</p></li>
</ul>
<ul class="simple">
<li><p>El volumen de los datos gestionados puede ser enorme.</p></li>
<li><p>Los datos son generados desde diversas fuentes.</p></li>
<li><p>Éstas pueden aumentar cada día tanto en cantidad como en volumen de datos.</p></li>
</ul>
<ul class="simple">
<li><p>En cuanto a la frecuencia los datos se pueden procesar en tiempo real o por lotes.</p></li>
<li><p>En tiempo real el procesamiento ocurre cuando los datos se reciben al mismo tiempo que se generan.</p></li>
<li><p>Los datos por lotes se almacenan mediante un proceso por lotes fijo en algún intervalo de tiempo y luego se trasladan al flujo del proceso de administración de datos.</p></li>
</ul>
<ul class="simple">
<li><p>La ingestión de datos se puede realizar utilizando formatos de distinto tipo:</p>
<ul>
<li><p>Datos estructurados (formato tabular).</p></li>
<li><p>Semi-estructurados (ficheros JSON, CSV, etc.).</p></li>
<li><p>No estructurados (imágenes, audio, video, etc.).</p></li>
</ul>
</li>
</ul>
<p>Fuente: <span id="id2">[<a class="reference internal" href="intro.html#id7" title="Edd. Dumbill. Planning for Big Data: A CIO's Handbook to the Changing Data Landscape. O’Reilly Media, Inc., 2012.">Dum12</a>]</span></p>
</section>
<section id="buenas-practicas-en-ingestion-de-datos">
<h2>Buenas prácticas en ingestión de datos<a class="headerlink" href="#buenas-practicas-en-ingestion-de-datos" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Ancho de banda de la red:</p></li>
<li><p>El flujo de datos (<em>Data Pipeline</em>) debe poder competir con el tráfico comercial.</p></li>
<li><p>A veces el tráfico aumenta o disminuye, por lo que la escalabilidad del ancho de banda de la red es el mayor desafío del <em>Data Pipeline</em>.</p></li>
<li><p>Se requieren herramientas de ingestión de datos que permitan la limitación y compresión del ancho de banda en base a las necesidades del momento.</p></li>
</ul>
<ul class="simple">
<li><p>Soporte para red no confiable:</p></li>
<li><p>La canalización en la ingestión de datos toma datos con múltiples estructuras, es decir, archivos de texto, datos de archivos tabulares, archivos XML, archivos de registro, etc. y debido a la velocidad variable de los datos que llegan, es posible que viajen a través de una red poco confiable.</p></li>
<li><p>La implementación del flujo de datos o <em>Data Pipeline</em> también debería ser capaz de soportar esto.</p></li>
</ul>
<ul class="simple">
<li><p>Transmisión de datos:</p></li>
<li><p>Las mejores prácticas de ingestión de datos dependen de la necesidad empresarial, ya sea para procesar los datos por lotes, flujos o en tiempo real.</p></li>
<li><p>En ocasiones, es posible que se necesiten todos a la vez para el procesamiento a través de la canalización de ingesta de datos, por lo que las herramientas deben ser capaces de admitirlos.</p></li>
</ul>
<ul class="simple">
<li><p>Tecnologías y Sistemas Heterogéneos:</p></li>
<li><p>Las herramientas para la canalización de la ingesta de datos deben poder utilizar diferentes tecnologías de fuentes de datos y diferentes sistemas operativos.</p></li>
</ul>
<ul class="simple">
<li><p>Elección del formato de datos correcto:</p></li>
<li><p>Las herramientas de ingesta de datos deben proporcionar un formato de serialización de datos, lo que significa que, dado que los datos vienen en formatos variables, los convierte a un solo formato para proporcionar una forma más fácil de comprenderlos o relacionarlos.</p></li>
</ul>
<ul class="simple">
<li><p>Repositorio único:</p></li>
<li><p>El análisis crítico es más efectivo cuando se combinan datos de múltiples fuentes.</p></li>
<li><p>Para la toma de decisiones de negocio, se debe tener un repositorio único para todos los datos que llegan.</p></li>
</ul>
<ul class="simple">
<li><p>Integraciones:</p></li>
<li><p>La cantidad de datos aumenta continuamente en el proceso de ingesta de datos, llegan datos nuevos y se modifican los datos antiguos, por lo cual a veces cada nueva integración puede tardar entre unos días y unos meses en completarse.</p></li>
</ul>
<ul class="simple">
<li><p>Alta precisión:</p></li>
<li><p>La única forma de generar confianza con los datos es asegurarse de que los datos son auditables.</p></li>
<li><p>Una buena práctica que es fácil de implementar es nunca descartar entradas o formularios intermedios al modificar datos en el flujo del proceso de ingesta de datos.</p></li>
</ul>
<ul class="simple">
<li><p>Latencia:</p></li>
<li><p>Cuanto más actualizados sean los datos, más ágil puede ser la toma de decisiones en la organización, pero hay un coste a considerar.</p></li>
<li><p>La extracción de datos de APIs y bases de datos en tiempo real puede ser difícil, y muchas fuentes de datos de destino, incluidos grandes almacenes de objetos como Amazon S3 y bases de datos de análisis como Amazon Redshift, están optimizadas para recibir datos en fragmentos en lugar de una secuencia.</p></li>
</ul>
<ul class="simple">
<li><p>Mantener la escalabilidad:</p></li>
<li><p>La ingesta de datos se puede aumentar o disminuir durante algunos períodos de tiempo.</p></li>
<li><p>El uso y tratamiento de los datos no es uniforme.</p></li>
<li><p>Se debe hacer que la canalización sea tan escalable que pueda manejar cualquier volumen de datos que lleguen a una velocidad variable.</p></li>
</ul>
</section>
<section id="problemas-en-la-ingesta-de-datos">
<h2>Problemas en la ingesta de datos<a class="headerlink" href="#problemas-en-la-ingesta-de-datos" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Cuando existen numerosas fuentes de Big Data con diferentes formatos, el mayor desafío para el negocio es ingerir datos a una velocidad razonable y procesarlos de manera eficiente.</p></li>
<li><p>De esta manera los datos pueden priorizarse y en consecuencia mejorar la toma de decisiones de negocio.</p></li>
</ul>
<ul class="simple">
<li><p>Las fuentes de datos, las herramientas de ingestión de datos y las aplicaciones de consumo evolucionan permanentemente durante el proceso de ingestión de datos.</p></li>
<li><p>Los datos pueden modificar sus atributos sin previo aviso independientemente de la aplicación utilizada.</p></li>
</ul>
<ul class="simple">
<li><p>Detección y captura de datos modificados: esta tarea es difícil, no solo por la naturaleza semiestructurada o no estructurada de los datos.</p></li>
<li><p>También lo es por tratar con baja latencia (una red informática que está optimizada para procesar un volumen muy alto de mensajes de datos con un retraso mínimo).</p></li>
<li><p>Estas redes están diseñadas para admitir operaciones que requieren acceso casi en tiempo real a datos que cambian rápidamente.</p></li>
</ul>
</section>
<section id="procesamiento-de-datos-en-tiempo-real">
<h2>Procesamiento de datos en tiempo real<a class="headerlink" href="#procesamiento-de-datos-en-tiempo-real" title="Link to this heading">#</a></h2>
<p><img alt="Ingesta de datos en Big Data" src="_images/analitica-datos-fortinux.png" /></p>
<ul class="simple">
<li><p>Imagen: Ingesta de datos en tiempo real en Big Data. Autor: M.H.Fortino(2024).</p></li>
</ul>
</section>
<section id="apache-spark">
<h2>Apache Spark<a class="headerlink" href="#apache-spark" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Apache Spark es un motor de procesamiento rápido y general compatible con datos de Hadoop.</p></li>
<li><p>Puede ejecutarse en clústeres de Hadoop a través de YARN o de modo independiente.</p></li>
<li><p>Procesa datos en HDFS, HBase, Cassandra, Hive y cualquier formato de entrada de Hadoop.</p></li>
<li><p>Diseñado para realizar tanto procesamiento por lotes (similar a MapReduce) como nuevas cargas de trabajo como <em>streaming</em>, consultas interactivas y aprendizaje automático.</p></li>
</ul>
<ul class="simple">
<li><p>Extraído de las FAQs: <a class="reference external" href="https://spark.apache.org/faq.html">https://spark.apache.org/faq.html</a>.</p></li>
<li><p>Más información en la sección <em>Motores de consultas</em> de estos apuntes.</p></li>
</ul>
</section>
<section id="apache-flume">
<h2>Apache Flume<a class="headerlink" href="#apache-flume" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Un servicio distribuido, confiable y de alta disponibilidad que colecta, agrupa y mueve eficientemente grandes cantidades de logs y datos.</p></li>
<li><p>Extraído de: <a class="reference external" href="https://flume.apache.org/">https://flume.apache.org/</a>.</p></li>
</ul>
<ul class="simple">
<li><p>Es robusto y tolerante a fallas con mecanismos de confiabilidad ajustables.</p></li>
<li><p>Cuenta también con mecanismos de conmutación por error y recuperación.</p></li>
<li><p>Utiliza un modelo de datos extensible simple que permite la aplicación analítica en línea.</p></li>
</ul>
<ul class="simple">
<li><p>Un evento Flume se define como una unidad de flujo de datos que tiene una carga útil de bytes y un conjunto opcional de atributos de cadena.</p></li>
<li><p>Un agente de Flume es un proceso (JVM) que aloja los componentes a través de los cuales fluyen los eventos desde una fuente externa hasta el siguiente destino (salto).</p></li>
</ul>
<ul class="simple">
<li><p>Una fuente de Flume consume eventos que le envía una fuente externa como por ej. un servidor web.</p></li>
<li><p>La fuente externa envía eventos a Flume en un formato que es reconocido por la fuente de destino de Flume.</p></li>
</ul>
<ul class="simple">
<li><p>Extraído de: <a class="reference external" href="https://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html">https://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html</a>.</p></li>
</ul>
</section>
<section id="apache-flink">
<h2>Apache Flink<a class="headerlink" href="#apache-flink" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Framework utilizado para el procesamiento de flujos distribuidos (<em>distributed stream</em>) que facilita resultados precisos, aún en el caso de datos que están desordenados o que llegan con retraso en la distribución.</p></li>
<li><p>Extraído de: <a class="reference external" href="https://flink.apache.org/">https://flink.apache.org/</a>.</p></li>
</ul>
</section>
<section id="sistemas-de-mensajeria">
<h2>Sistemas de mensajería<a class="headerlink" href="#sistemas-de-mensajeria" title="Link to this heading">#</a></h2>
</section>
<section id="apache-kafka">
<h2>Apache Kafka<a class="headerlink" href="#apache-kafka" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Es una plataforma de transmisión de eventos distribuidos de código abierto utilizada por miles de empresas para canalizaciones de datos de alto rendimiento, análisis de streaming, integración de datos y aplicaciones de misión crítica.</p></li>
<li><p>Es también un sistema de mensajería escalable que permite a los usuarios publicar y consumir grandes cantidades de mensajes en tiempo real por suscripción.</p></li>
<li><p>Extraído de: <a class="reference external" href="https://kafka.apache.org/">https://kafka.apache.org/</a>.</p></li>
</ul>
<ul class="simple">
<li><p>La transmisión de eventos es el equivalente digital del sistema nervioso central del cuerpo humano.</p></li>
<li><p>Es la base tecnológica para el mundo ‘siempre activo’ donde las empresas están cada vez más definidas por software y automatizadas, y donde el usuario de software es más software (Inteligencia Artificial).</p></li>
</ul>
<ul class="simple">
<li><p>Técnicamente hablando, la transmisión de eventos es la práctica de capturar datos en tiempo real de fuentes de eventos como bases de datos, sensores, dispositivos móviles, servicios en la nube y aplicaciones de software en forma de flujos de eventos; almacenar estos flujos de eventos de forma duradera para su posterior recuperación; manipular, procesar y reaccionar a los flujos de eventos en tiempo real y retrospectivamente; y enrutar los flujos de eventos a diferentes tecnologías de destino según sea necesario.</p></li>
</ul>
<ul class="simple">
<li><p>La version comercial de Apache Kafka es Confluent <a class="reference external" href="https://www.confluent.io/es-es/">https://www.confluent.io/es-es/</a>.</p></li>
<li><p>Otro <em>broker</em> de mensajería es RabbitMQ <a class="reference external" href="https://www.rabbitmq.com/">https://www.rabbitmq.com/</a>.</p></li>
</ul>
</section>
<section id="apache-activemq">
<h2>Apache ActiveMQ<a class="headerlink" href="#apache-activemq" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Es el sistema de mensajería multi protocolo open source más popular del mercado.</p></li>
<li><p>Se conecta a clientes escritos en JavaScript, C, C++, Python, .Net, y más.</p></li>
<li><p>Integra aplicaciones multiplataforma utilizando el protocolo AMQP.</p></li>
<li><p>Intercambia mensajes mediante STOMP sobre <em>websockets</em>, gestiona dispositivos IoT con MQTT.</p></li>
<li><p>Soporta la infraestructura JMS (<em>Java Message Service</em>).</p></li>
</ul>
<ul class="simple">
<li><p>Fuente: <a class="reference external" href="https://activemq.apache.org/">https://activemq.apache.org/</a></p></li>
</ul>
</section>
<section id="apache-pulsar">
<h2>Apache Pulsar<a class="headerlink" href="#apache-pulsar" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Apache Pulsar es una plataforma de eventos distribuidos cloud similar a Kafka originalmente creada por Yahoo!</p></li>
<li><p><a class="reference external" href="https://pulsar.apache.org/">https://pulsar.apache.org/</a>.</p></li>
<li><p>La versión comercial de sus creadores es StreamNative <a class="reference external" href="https://streamnative.io/">https://streamnative.io/</a>.</p></li>
</ul>
</section>
<section id="pub-sub">
<h2>Pub/Sub<a class="headerlink" href="#pub-sub" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Es un sistema de mensajería que combina la escalabilidad horizontal de Apache Kafka y Pulsar con funciones del middleware como colas y filtros de mensajes no entregados de Apache ActiveMQ y RabbitMQ.</p></li>
<li><p>Se complementa con Dataflow, que controla la anulación de mensajes duplicados, el procesamiento “solo una vez” y generación de marcas de agua a partir de eventos con marcas de tiempo.</p></li>
<li><p>Para usar Dataflow se escribe la canalización con el SDK de Apache Beam y luego se ejecuta.</p></li>
<li><p><a class="reference external" href="https://cloud.google.com/pubsub/docs/overview">https://cloud.google.com/pubsub/docs/overview</a></p></li>
</ul>
</section>
<section id="otras-herramientas">
<h2>Otras herramientas<a class="headerlink" href="#otras-herramientas" title="Link to this heading">#</a></h2>
</section>
<section id="logstash">
<h2>Logstash<a class="headerlink" href="#logstash" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Canalización (<em>pipeline</em>) de procesamiento de datos del lado del servidor de código abierto que ingiere datos de una multitud de fuentes, los transforma simultáneamente y luego los envía al reservatorio (<em>stash</em>), por ejemplo Elasticsearch.</p></li>
<li><p>Extraído de: <a class="reference external" href="https://www.elastic.co/es/logstash">https://www.elastic.co/es/logstash</a>.</p></li>
</ul>
</section>
<section id="apache-nifi">
<h2>Apache Nifi<a class="headerlink" href="#apache-nifi" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Es una de las mejores herramientas de <em>data ingestion</em> del mercado.</p></li>
<li><p>Proveee un sistema fácil de usar, poderoso y confiable para procesar y distribuir datos.</p></li>
<li><p>Extraído de: <a class="reference external" href="https://nifi.apache.org/">https://nifi.apache.org/</a>, <a class="reference external" href="https://nifi.apache.org/documentation/v2/">https://nifi.apache.org/documentation/v2/</a>.</p></li>
</ul>
<ul class="simple">
<li><p>Documentación: <a class="reference external" href="https://nifi.apache.org/docs/nifi-docs/html/getting-started.html">https://nifi.apache.org/docs/nifi-docs/html/getting-started.html</a>.</p></li>
<li><p>Caso de uso: <em>Best practices and lessons learnt from Running Apache NiFi at Renault</em><br />
<a class="reference external" href="https://fr.slideshare.net/Hadoop_Summit/best-practices-and-lessons-learnt-from-running-apache-nifi-at-renault">https://fr.slideshare.net/Hadoop_Summit/best-practices-and-lessons-learnt-from-running-apache-nifi-at-renault</a>.</p></li>
</ul>
</section>
<section id="apache-beam">
<h2>Apache Beam<a class="headerlink" href="#apache-beam" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Es un modelo de programación unificado que permite implementar trabajos de procesamiento de datos por lotes y de <em>streaming</em> en cualquier motor de ejecución.</p></li>
<li><p>Lee los datos desde diversas fuentes, ejecuta la lógica del negocio para <em>batch</em> y <em>streaming</em>, y finalmente los deposita en las soluciones de almacenamiento disponibles.</p></li>
<li><p>Una canalización de Beam puede ejecutarse en los sistemas de procesamiento de datos distribuidos más populares, como Spark, Flink o Samza.</p></li>
</ul>
<ul class="simple">
<li><p>Fuente: <a class="reference external" href="https://beam.apache.org/">https://beam.apache.org/</a>.</p></li>
</ul>
</section>
<section id="apache-samza">
<h2>Apache Samza<a class="headerlink" href="#apache-samza" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Permite crear aplicaciones con estado que procesan datos en tiempo real desde múltiples fuentes, incluido Apache Kafka.</p></li>
<li><p>Admite opciones de implementación flexibles para ejecutarse en YARN o como una biblioteca independiente.</p></li>
<li><p>Tutorial: <a class="reference external" href="https://samza.apache.org/startup/hello-samza/1.6.0/">https://samza.apache.org/startup/hello-samza/1.6.0/</a>.</p></li>
<li><p>Fuente: <a class="reference external" href="https://samza.apache.org/">https://samza.apache.org/</a>.</p></li>
</ul>
</section>
<section id="apache-airflow">
<h2>Apache Airflow<a class="headerlink" href="#apache-airflow" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Apache Airflow es una plataforma que permite crear, programar temporalmente, y monitorar flujos de trabajo utilizando Python como lenguaje.</p></li>
<li><p>Automatiza la ingestas de datos, acciones de mantenimiento periódicas y realiza tareas de administración.</p></li>
<li><p>Extraído de: <a class="reference external" href="https://airflow.apache.org/">https://airflow.apache.org/</a>.</p></li>
</ul>
<ul class="simple">
<li><p>Un flujo de trabajo de ejemplo puede ser:</p>
<ul>
<li><p>Obtener datos de una base de datos relacional como PostgreSQL para enviarlos a Kafka.</p></li>
<li><p>Transformar los datos con Apache Spark y finalmente enviar un mensaje de finalización.</p></li>
</ul>
</li>
</ul>
</section>
<section id="astro">
<h2>Astro<a class="headerlink" href="#astro" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Astro es la versión comercial de Apache Airflow. Facilita la construcción, ejecución y observación de los datos de la organización en una única plataforma.</p></li>
<li><p>Permite integrar además la inteligencia artificial y los LLM (<em>Large Language Models</em>) para acelerar la innovación.</p></li>
</ul>
<ul class="simple">
<li><p>Fuente: <a class="reference external" href="https://www.astronomer.io/">https://www.astronomer.io/</a>.</p></li>
</ul>
</section>
<section id="dbt">
<h2>DBT<a class="headerlink" href="#dbt" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>DBT (<em>Data Build Tool</em>) permite a los ingenieros de datos y analistas realizar transformaciones en los datos escribiendo sentencias SQL de tipo SELECT.</p></li>
<li><p>Internamente, DBT traduce estas sentencias en tablas y en vistas, de esta forma facilita la creación de transformaciones sobre los datos disponibles en el almacén de datos.</p></li>
</ul>
<ul class="simple">
<li><p>Fuente: <a class="reference external" href="https://www.getdbt.com/">https://www.getdbt.com/</a>.</p></li>
</ul>
</section>
<section id="id3">
<h2>Otras herramientas<a class="headerlink" href="#id3" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Mage AI es una herramienta open source orientada a crear canalizaciones para transformar e integrar datos.</p>
<ul>
<li><p><a class="reference external" href="https://www.mage.ai/">https://www.mage.ai/</a>.</p></li>
</ul>
</li>
<li><p>Fivetran es una cloud-based platform para ETL.</p>
<ul>
<li><p><a class="reference external" href="https://www.fivetran.com/">https://www.fivetran.com/</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Stitch Data Loader mueve más de 130 tipos de fuentes al <em>data warehouse</em>.</p>
<ul>
<li><p><a class="reference external" href="https://www.stitchdata.com/">https://www.stitchdata.com/</a>.</p></li>
</ul>
</li>
<li><p>Airbyte es una herramienta open-source de integración de datos.</p>
<ul>
<li><p><a class="reference external" href="https://airbyte.com/">https://airbyte.com/</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Materialize es un almacén de datos útil para análisis en tiempo real que ofrece actualizaciones de vista incrementales.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://materialize.com/">https://materialize.com/</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="modelo-semantico-de-datos-sdm">
<h2>Modelo semántico de datos (SDM)<a class="headerlink" href="#modelo-semantico-de-datos-sdm" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>El modelo semántico de datos (SDM) también cambia con el tiempo.</p></li>
<li><p>Se necesita un modelo de datos (<em>DM</em>) en el que se incluya información semántica.</p></li>
<li><p>Un <em>DM</em> que incluya la capacidad de expresar e intercambiar información permite a las partes interpretar el significado (semántica) de las instancias.</p></li>
</ul>
<ul class="simple">
<li><p>Extraído de: Semantic Data Model: <a class="reference external" href="https://es.wikipedia.org/wiki/Modelo_sem%C3%A1ntico_de_datos">https://es.wikipedia.org/wiki/Modelo_semántico_de_datos</a>.</p></li>
</ul>
<ul class="simple">
<li><p>En un modelo semántico los hechos generalmente se expresan mediante relaciones binarias entre elementos de datos, mientras que las relaciones de orden superior se expresan como colecciones de relaciones binarias.</p></li>
<li><p>Típicamente las relaciones binarias tienen la forma de ternas: Objeto-&lt;Tipo de Relación&gt;-Objeto.</p></li>
<li><p>Por ejemplo: La Torre Eiffel <code class="docutils literal notranslate"><span class="pre">&lt;se</span> <span class="pre">encuentra</span> <span class="pre">en&gt;</span></code> París.</p></li>
</ul>
<ul class="simple">
<li><p>Según el conocido trabajo seminal de Smith y Smith (1977), tres abstracciones son muy importantes para el modelado de datos:</p>
<ul>
<li><p>Clasificación: modelo instancia_de_relaciones.</p></li>
<li><p>Agregación: modelo tiene_relaciones.</p></li>
<li><p>Generalización: modelo es_unas_relaciones.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Extraído de: Semantic Data Modelling: <a class="reference external" href="http://www.jhterbekke.net/SemanticDataModeling.html">http://www.jhterbekke.net/SemanticDataModeling.html</a>.</p></li>
</ul>
<ul class="simple">
<li><p>Integridad de datos: las especificaciones del modelo de datos implican la validez de ciertas reglas de integridad.</p></li>
<li><p>Relatividad: cada atributo en una definición de tipo está relacionado con uno y solo un tipo con el mismo nombre, mientras que cada tipo puede corresponder con varios atributos en otros tipos.</p></li>
<li><p>Convertibilidad: Cada definición de tipo es única: no hay definiciones de tipo que lleven el mismo nombre o la misma colección de atributos.</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">database</span> <span class="n">warehouse</span><span class="o">.</span>

<span class="n">base</span> <span class="n">description</span> <span class="p">(</span><span class="n">A16</span><span class="p">)</span><span class="o">.</span>
<span class="nb">type</span> <span class="n">product</span> <span class="n">kind</span> <span class="p">(</span><span class="n">A8</span><span class="p">)</span> <span class="o">=</span> <span class="n">description</span><span class="o">.</span>

<span class="n">base</span> <span class="n">color</span> <span class="p">(</span><span class="n">A10</span><span class="p">)</span><span class="o">.</span>
<span class="n">base</span> <span class="n">stock</span> <span class="p">(</span><span class="n">I8</span><span class="p">)</span><span class="o">.</span>
<span class="n">base</span> <span class="n">price</span> <span class="p">(</span><span class="n">R4</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span>
<span class="nb">type</span> <span class="n">product</span> <span class="p">(</span><span class="n">I7</span><span class="p">)</span> <span class="o">=</span> <span class="n">description</span><span class="p">,</span> <span class="n">color</span><span class="p">,</span> <span class="n">stock</span><span class="p">,</span> <span class="n">price</span><span class="p">,</span> <span class="n">product</span> <span class="n">kind</span><span class="o">.</span>

<span class="n">base</span> <span class="n">company</span> <span class="n">name</span> <span class="p">(</span><span class="n">A20</span><span class="p">)</span><span class="o">.</span>
<span class="n">base</span> <span class="n">address</span> <span class="p">(</span><span class="n">A20</span><span class="p">)</span><span class="o">.</span>
<span class="n">base</span> <span class="nb">zip</span> <span class="p">(</span><span class="n">A6</span><span class="p">)</span><span class="o">.</span>
<span class="n">base</span> <span class="n">city</span> <span class="p">(</span><span class="n">A16</span><span class="p">)</span><span class="o">.</span>
<span class="nb">type</span> <span class="n">supplier</span> <span class="p">(</span><span class="n">A8</span><span class="p">)</span> <span class="o">=</span> <span class="n">company</span> <span class="n">name</span><span class="p">,</span> <span class="n">address</span><span class="p">,</span> <span class="nb">zip</span><span class="p">,</span> <span class="n">city</span><span class="o">.</span>

<span class="nb">type</span> <span class="n">purchased</span> <span class="n">product</span> <span class="p">(</span><span class="n">A9</span><span class="p">)</span> <span class="o">=</span> <span class="n">supplier</span><span class="p">,</span> <span class="n">product</span><span class="p">,</span> <span class="n">price</span><span class="o">.</span>

<span class="o">...</span>

<span class="n">base</span> <span class="n">prepaid</span> <span class="p">(</span><span class="n">R4</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span>
<span class="nb">type</span> <span class="n">sale</span> <span class="p">(</span><span class="n">A7</span><span class="p">)</span> <span class="o">=</span> <span class="n">sold</span> <span class="n">product</span><span class="p">,</span> <span class="n">quantity</span><span class="p">,</span> <span class="n">price</span><span class="p">,</span> <span class="n">customer</span><span class="p">,</span> <span class="n">date</span><span class="p">,</span> <span class="n">prepaid</span><span class="o">.</span>

<span class="n">end</span><span class="o">.</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Artículo Semantic (Big) Data Analysis: An Extensive Literature Review.</p>
<ul>
<li><p><a class="reference external" href="https://latamt.ieeer9.org/index.php/transactions/article/download/673/207">https://latamt.ieeer9.org/index.php/transactions/article/download/673/207</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="almacenamiento-de-datos-data-storage">
<h2>Almacenamiento de datos (Data Storage)<a class="headerlink" href="#almacenamiento-de-datos-data-storage" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>El almacenamiento se convierte en un desafío cuando el tamaño de los datos es muy grande.</p></li>
<li><p>Varias posibles soluciones pueden ayudar a resolver este problema.</p></li>
<li><p>Encontrar la solución de almacenamiento más eficiente es el objetivo de este paso.</p></li>
</ul>
<ul class="simple">
<li><p>Dependiendo de las funciones y características del <em>dataset</em> los datos se pueden almacenar de la siguiente forma:</p>
<ul>
<li><p>Almacén de datos (<em>Data warehouse</em>) para el almacenamiento persistente.</p></li>
<li><p><em>Big Data volume system</em> para los datos originales antes de la preparación.</p></li>
<li><p><em>Big Data velocity application</em> durante la recoleción, preparación y análisis al vuelo.</p></li>
</ul>
</li>
</ul>
</section>
<section id="persistencia-poliglota">
<h2>Persistencia políglota<a class="headerlink" href="#persistencia-poliglota" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Se necesitan diferentes tipos de bases de datos para manejar las diferentes variedades de datos, pero el uso de las mismas crea una sobrecarga en el sistema.</p></li>
<li><p>Es por este motivo que hay un nuevo concepto en el mundo de las bases de datos: la persistencia políglota. Es la idea de usar múltiples bases de datos para impulsar una sola aplicación.</p>
<ul>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Polyglot_persistence">https://en.wikipedia.org/wiki/Polyglot_persistence</a></p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>La persistencia políglota es la forma de compartir o dividir los datos en múltiples bases de datos y aprovechar su poder juntas.</p>
<ul>
<li><p>BBDDs Relacionales.</p></li>
<li><p>BBDDs No SQL.</p></li>
<li><p>BBDDs de grafos.</p></li>
<li><p>BBDDs en memoria.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p><em>Polyglot Persistance</em> tiene tiempos de respuesta más rápidos.</p></li>
<li><p>Las bases de datos NoSQL escalan bien cuando se modelan correctamente para los datos que se desean almacenar.</p></li>
<li><p>La experiencia de usuario es mejor cuando se aprovecha el poder de múltiples bases de datos al mismo tiempo.</p></li>
</ul>
<ul class="simple">
<li><p>Por ejemplo, si desea buscar productos en una aplicación de comercio electrónico, se utiliza ElasticSearch, que devuelve los resultados en función de la relevancia, lo que MongoDB no puede hacer fácilmente.</p></li>
<li><p>Como contrapartida, tiene como desventaja la necesidad de contratar personal especializado para la integración de las bases de datos y una mayor cantidad de recursos de almacenamiento.</p></li>
</ul>
</section>
<section id="herramientas-de-almacenamiento-para-big-data">
<h2>Herramientas de almacenamiento para Big Data<a class="headerlink" href="#herramientas-de-almacenamiento-para-big-data" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>HDFS : <em>Hadoop Distributed File System</em>.</p></li>
<li><p>Ozone: Un <em>object store</em> para Hadoop, la próxima generación de HDFS.</p></li>
<li><p>GlusterFS: Sistema de archivos distribuido confiable.</p></li>
<li><p>Ceph: Proporciona almacenamiento de objetos, bloques y sistemas de archivos en un solo clúster.</p></li>
<li><p>MinIO: Un <em>object store</em> para la insfraestructura de datos de IA.</p></li>
<li><p><em>Cloud storage</em>: Amazon S3 Storage Service, IBM Cloud Object Storage, Azure Blob Storage, Google Cloud Storage.</p></li>
</ul>
</section>
<section id="hdfs">
<h2>HDFS<a class="headerlink" href="#hdfs" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>HDFS es un sistema de ficheros basado en Java que provee almacenamiento confiable y escalable.</p></li>
<li><p>Fue diseñado para abarcar grandes grupos de servidores básicos (commodity servers).</p></li>
<li><p>HDFS contiene una gran cantidad de datos y proporciona un acceso a los mismos de manera sencilla y fácil.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html">https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Para almacenar una inmensa cantidad de datos, los ficheros son guardados en varias máquinas.</p></li>
<li><p>Estos ficheros son guardados de forma redundante para poder rescatar el sistema en caso de pérdida de datos a causa de fallos.</p></li>
</ul>
<ul class="simple">
<li><p>HDFS también proporciona la disponibilidad de aplicaciones para procesamiento en paralelo durante el paso de ingestión de datos.</p></li>
<li><p>HDFS fue construido para soportar aplicaciones con grandes conjuntos de datos, incluyendo ficheros con terabytes de tamaño.</p></li>
</ul>
<ul class="simple">
<li><p>Utiliza una arquitectura maestro/esclavo, en la que cada clúster consta de un solo <em>Namenode</em> que administra las operaciones del sistema de archivos y admite <em>Datanodes</em> que administran el almacenamiento de datos en nodos de cómputo individuales.</p></li>
</ul>
<ul class="simple">
<li><p>Cuando HDFS toma datos, divide la información en partes separadas y las distribuye a diferentes nodos en un clúster, lo que permite el procesamiento paralelo.</p></li>
<li><p>El sistema de archivos en Ingestión de datos también copia cada pieza de datos varias veces y distribuye las copias a nodos individuales, colocando al menos una copia en un rack de servidor diferente.</p></li>
</ul>
</section>
<section id="apache-ozone">
<h2>Apache Ozone<a class="headerlink" href="#apache-ozone" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Ozone es un <em>object store</em> escalable, redundante, y distribuído para Hadoop.</p></li>
<li><p>Además de escalar a billones de objetos de cualquier tamaño, Ozone puede trabajar puede funcionar de manera efectiva en entornos en contenedores como Kubernetes y YARN.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://ozone.apache.org/">https://ozone.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Aplicaciones que utilizan frameworks como Apache Spark, YARN y Hive trabajan de forma nativa sin modificaciones.</p></li>
<li><p>Ozone está construido en una capa de almacenamiento en bloques altamente disponible y replicada llamada <em>Hadoop Distributed Data Store (HDDS)</em>.</p></li>
<li><p>Ozone viene un una biblioteca cliente para Java, soporte para el protocolo S3, y una interfaz de línea de comandos.</p></li>
</ul>
<ul class="simple">
<li><p>Ozone consta de volúmenes, cubos (<em>buckets</em>) y claves:</p>
<ul>
<li><p>Los volúmenes son similares a las cuentas de usuario. Solo los administradores pueden crear o eliminar volúmenes.</p></li>
<li><p>Los cubos son similares a los directorios. Un cubo puede contener cualquier cantidad de claves, pero los cubos no pueden contener otros cubos.</p></li>
<li><p>Las claves son similares a los archivos.</p></li>
</ul>
</li>
</ul>
</section>
<section id="glusterfs">
<h2>GlusterFS<a class="headerlink" href="#glusterfs" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Gluster es un sistema de ficheros en red escalable libre y de fuente abierta.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://docs.gluster.org/en/latest/">https://docs.gluster.org/en/latest/</a> | <a class="reference external" href="https://www.gluster.org/">https://www.gluster.org/</a></p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Los sistemas de almacenamiento de escalamiento horizontal basados en GlusterFS son adecuados para datos no estructurados, como documentos, imágenes, archivos de audio y video, y archivos de registro.</p></li>
<li><p>Con esto, podemos crear grandes soluciones de almacenamiento distribuido para transmisión de medios, análisis de datos, ingesta de datos y otras tareas intensivas en datos y ancho de banda.</p></li>
</ul>
<ul class="simple">
<li><p>La arquitectura GlusterFS agrega recursos informáticos, de almacenamiento y de E/S en un espacio de nombres global.</p></li>
<li><p>Cada servidor más el almacenamiento básico adjunto (configurado como almacenamiento adjunto directo, JBOD o utilizando una red de área de almacenamiento) se considera un nodo.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://en.wikipedia.org/wiki/Gluster">https://en.wikipedia.org/wiki/Gluster</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>La capacidad se escala agregando nodos adicionales o agregando almacenamiento adicional a cada nodo.</p></li>
<li><p>El rendimiento aumenta al implementar el almacenamiento entre más nodos.</p></li>
<li><p>La alta disponibilidad se logra mediante la replicación de datos de <em>n</em> vías entre nodos.</p></li>
</ul>
</section>
<section id="ceph">
<h2>Ceph<a class="headerlink" href="#ceph" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>La base de Ceph es el <em>Reliable Autonomic Distributed Object Store (RADOS)</em></p></li>
<li><p>Proporciona a las aplicaciones almacenamiento de objetos, bloques y sistemas de archivos en un solo clúster de almacenamiento unificado.</p></li>
<li><p>Esto lo hace altamente confiable y fácil de gestionar.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://ceph.io/">https://ceph.io/</a></p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>El algoritmo CRUSH de Ceph libera a los clústeres de almacenamiento de las limitaciones de escalabilidad y rendimiento impuestas por el mapeo de tablas de datos centralizados.</p></li>
<li><p>Replica y reequilibra los datos dentro del clúster de forma dinámica, eliminando esta tediosa tarea para los administradores, al tiempo que ofrece escalabilidad infinita y alto rendimiento.</p></li>
</ul>
<ul class="simple">
<li><p>Recursos:</p>
<ul>
<li><p>Democratising Data Storage. DIGITAL REPORT 2021:</p></li>
<li><p><a class="reference external" href="https://ceph.io/assets/pdfs/report-dec2021.pdf">https://ceph.io/assets/pdfs/report-dec2021.pdf</a>.</p></li>
<li><p>Ceph Quickstart: <a class="reference external" href="https://rook.io/docs/rook/v1.8/quickstart.html">https://rook.io/docs/rook/v1.8/quickstart.html</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="minio">
<h2>MinIO<a class="headerlink" href="#minio" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>MinIO es un <em>object store</em> de alto desempeño compatible con S3.</p></li>
<li><p>Ha sido construido para cargas de trabajo de larga escala AI/ML en <em>datalakes</em> y bases de datos.</p></li>
<li><p>Se puede ejecutar en cualquier <em>cloud vendor</em> o en infraestructuras <em>on-premises</em>.</p></li>
<li><p>Tiene licencia dual: open source GNU AGPL v3 y licencia comercial para empresas.</p></li>
</ul>
<ul class="simple">
<li><p>Fuente: <a class="reference external" href="https://min.io/">https://min.io/</a>.</p></li>
</ul>
</section>
<section id="amazon-services">
<h2>Amazon Services<a class="headerlink" href="#amazon-services" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Amazon Simple Storage Service (Amazon S3) es un almacenamiento de objetos con una interfaz web simple que permite almacenar y recuparar cualquier volumen de datos desde cualquier lugar en Internet.</p></li>
<li><p>Está diseñado para entregar un 99.999% de durabilidad y escalar a más de trillones de objetos en todo el mundo.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://aws.amazon.com/free/storage/s3/">https://aws.amazon.com/free/storage/s3/</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Amazon Redshift es un servicio de <em>data warehouse</em> en la nube.</p></li>
<li><p>Utiliza SQL para analizar datos estructurados y semiestructurados en almacenamientos de datos, bases de datos operativas y lagos de datos, con hardware y machine learning diseñado por AWS.</p></li>
<li><p>Redshift permite guardar los resultados de las consultas en el <em>S3 data lake</em> utilizando formatos abiertos como Apache Parquet para su posterior análisis con Amazon EMR, Amazon Athena, y Amazon SageMaker.</p>
<ul>
<li><p>Extraído de: Amazon Redshift <a class="reference external" href="https://aws.amazon.com/redshift/">https://aws.amazon.com/redshift/</a></p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Todos los servicios de Amazon para análisis en Amazon:</p>
<ul>
<li><p><a class="reference external" href="https://aws.amazon.com/es/big-data/datalakes-and-analytics/">https://aws.amazon.com/es/big-data/datalakes-and-analytics/</a></p></li>
</ul>
</li>
</ul>
</section>
<section id="microsoft-azure-data-lake-store">
<h2>Microsoft Azure Data Lake Store<a class="headerlink" href="#microsoft-azure-data-lake-store" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Lago de datos seguro y escalable de forma masiva para sus cargas de trabajo de análisis de alto rendimiento.</p></li>
<li><p>Fuente: <a class="reference external" href="https://azure.microsoft.com/es-es/services/storage/data-lake-storage/">https://azure.microsoft.com/es-es/services/storage/data-lake-storage/</a>.</p></li>
<li><p>Soluciones en Big Data: <a class="reference external" href="https://azure.microsoft.com/es-es/solutions/big-data/">https://azure.microsoft.com/es-es/solutions/big-data/</a>.</p></li>
</ul>
<ul class="simple">
<li><p>Microsoft Azure Data Lake Analytics</p></li>
<li><p>Servicio de análisis en la nube para desarrollar y ejecutar fácilmente programas de procesamiento y transformación de petabytes de datos en paralelo de forma masiva con los lenguajes U-SQL, R, Python y .NET.</p></li>
<li><p>Sin infraestructura para administrar, se procesan los datos a petición, escalando las unidades de análisis de forma instantánea.</p></li>
<li><p>Fuente: <a class="reference external" href="https://azure.microsoft.com/es-es/services/data-lake-analytics/#overview">https://azure.microsoft.com/es-es/services/data-lake-analytics/#overview</a>.</p></li>
</ul>
</section>
<section id="google-bigquery">
<h2>Google BigQuery<a class="headerlink" href="#google-bigquery" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Almacén de datos multinube de alta escalabilidad, rentable y sin servidor.</p>
<ul>
<li><p><a class="reference external" href="https://cloud.google.com/bigquery">https://cloud.google.com/bigquery</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Google Cloud Smart Analytics Platform:</p></li>
<li><p>Es una plataforma de analíticas flexible, abierta y segura que ayuda a convertirse en una organización basada en la inteligencia.</p></li>
<li><p>Se basa en décadas de innovación de Google en el sector de la inteligencia artificial y en el desarrollo de servicios a escala de Internet.</p>
<ul>
<li><p>Extraído de <a class="reference external" href="https://cloud.google.com/solutions/smart-analytics">https://cloud.google.com/solutions/smart-analytics</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="data-warehouses-data-lakes-lakehouses">
<h2>Data warehouses / Data lakes / Lakehouses<a class="headerlink" href="#data-warehouses-data-lakes-lakehouses" title="Link to this heading">#</a></h2>
</section>
<section id="snowflake">
<h2>Snowflake<a class="headerlink" href="#snowflake" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Nacido como almacén de datos Snowflake facilita el almacenamiento, procesamiento, y brinda soluciones analíticas flexibles y veloces de manera fácil con una escalabilidad casi infinita, habilitada automáticamente o sobre la marcha.</p></li>
<li><p>Está alojado en Amazon AWS.</p>
<ul>
<li><p>Fuente: <a class="reference external" href="https://www.snowflake.com/">https://www.snowflake.com/</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="databricks">
<h2>Databricks<a class="headerlink" href="#databricks" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Fundada en 2013 por los creadores originales de Apache Spark, Delta Lake y MLflow, Databricks reúne ingeniería de datos, ciencia y análisis en una plataforma abierta y unificada para que los equipos de datos puedan colaborar e innovar más rápido.</p></li>
<li><p>Está alojado en Microsoft Azure.</p>
<ul>
<li><p>Fuente: <a class="reference external" href="https://databricks.com/">https://databricks.com/</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="delta-lake">
<h2>Delta Lake<a class="headerlink" href="#delta-lake" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Delta Lake es un <em>framework</em> de almacenamiento de código abierto que permite crear una arquitectura <em>Lakehouse</em> independiente del formato sobre un lago de datos con motores informáticos que incluyen Spark, PrestoDB, Flink, Trino, Hive, Snowflake, Google BigQuery, Athena, Redshift, Databricks, y Azure Fabric.</p></li>
<li><p>Proporciona transacciones ACID, manejo escalable de metadatos y unifica el procesamiento de datos por lotes y streaming sobre lagos de datos existentes, como S3, ADLS, GCS y HDFS.</p></li>
<li><p>Cuenta con una API para los lenguajes de programación Scala, Java, Rust y Python.</p></li>
<li><p>Puede además leer tablas Delta con los clientes Iceberg y Hudi utilizando el formato <em>Delta Universal</em>, también llamado <em>UniForm</em>.</p></li>
</ul>
<ul class="simple">
<li><p>Fuente: <a class="reference external" href="https://delta.io/">https://delta.io/</a>.</p></li>
</ul>
</section>
<section id="apache-iceberg">
<h2>Apache Iceberg<a class="headerlink" href="#apache-iceberg" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><em>Iceberg es un formato de alto rendimiento para tablas analíticas enormes. Iceberg aporta la confiabilidad y simplicidad de las tablas SQL a big data, al tiempo que hace posible que motores como Spark, Trino, Flink, Presto, Hive e Impala trabajen de forma segura con las mismas tablas al mismo tiempo.</em></p></li>
</ul>
<ul class="simple">
<li><p>Fuente: <a class="reference external" href="https://iceberg.apache.org/">https://iceberg.apache.org/</a>.</p></li>
</ul>
</section>
<section id="apache-hudi">
<h2>Apache Hudi<a class="headerlink" href="#apache-hudi" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Apache Hudi es una plataforma de lago de datos transaccional que aporta capacidades de base de datos y almacén de datos al lago de datos.</p></li>
<li><p>Hudi reinventa el lento procesamiento de datos por lotes con un nuevo y potente framework de procesamiento incremental para análisis de baja latencia a nivel de minutos.</p></li>
</ul>
<ul class="simple">
<li><p>Fuente: <a class="reference external" href="https://hudi.apache.org/">https://hudi.apache.org/</a>.</p></li>
<li><p>Comparativa entre Hudi, Delta Lake e Iceberg:</p></li>
<li><p><a class="reference external" href="https://www.onehouse.ai/blog/apache-hudi-vs-delta-lake-vs-apache-iceberg-lakehouse-feature-comparison">https://www.onehouse.ai/blog/apache-hudi-vs-delta-lake-vs-apache-iceberg-lakehouse-feature-comparison</a>.</p></li>
</ul>
</section>
<section id="apache-xtable">
<h2>Apache XTable<a class="headerlink" href="#apache-xtable" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Apache XTable foca en la interoperabilidad entre los distintos formatos de tablas de lagos de datos como Apache Hudi, Delta Lake, y Apache Iceberg.</p></li>
<li><p>Actúa como capa intermedia que traduce los metadatos de los formatos de tablas de la fuente al destino sin necesidad de duplicar o reescribir los ficheros de datos.</p></li>
</ul>
<ul class="simple">
<li><p>Fuente: <a class="reference external" href="https://xtable.apache.org/">https://xtable.apache.org/</a>.</p></li>
</ul>
</section>
<section id="nosql-databases">
<h2>NoSQL databases<a class="headerlink" href="#nosql-databases" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Las bases de datos NoSQL, (no solo SQL) o no relacionales, se utilizan mayoritariamente para la recopilación y análisis de Big Data.</p></li>
<li><p>Permiten la organización dinámica de datos no estructurados.</p></li>
<li><p>Las bases de datos relacionales, por otro lado, tienen un diseño estructurado y tabular.</p></li>
</ul>
<ul class="simple">
<li><p>Bases de datos basadas en columnas están optimizadas para los trabajos analíticos intensivos de lectura.</p>
<ul>
<li><p><em>Online Analytical Processing (OLAP)</em>.</p></li>
</ul>
</li>
<li><p>Bases de datos basadas en filas son mejores para trabajos intensivos de escritura transaccional.</p>
<ul>
<li><p><em>Online Transactional Processing (OLTP)</em>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Existen diversos tipos de bases de datos No SQL:</p>
<ul>
<li><p>Bases de datos de documentos (MongoDB, Couch DB).</p></li>
<li><p>Pares de valores (Amazon DynamoDB, Redis).</p></li>
<li><p>Columnares (Apache Cassandra, Apache HBase).</p></li>
<li><p>De grafos (Neo4j, Stardog).</p></li>
</ul>
</li>
</ul>
</section>
<section id="herramientas-de-la-asf-para-big-data">
<h2>Herramientas de la ASF para Big Data<a class="headerlink" href="#herramientas-de-la-asf-para-big-data" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Algunas de las herramientas de la ASF (<em>Apache Software Foundation</em>) <a class="reference external" href="https://apache.org/">https://apache.org/</a> para Big Data:</p></li>
</ul>
</section>
<section id="apache-mesos">
<h2>Apache Mesos<a class="headerlink" href="#apache-mesos" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Un núcleo (<em>kernel</em>) de sistemas distribuidos.</p></li>
<li><p>Mesos está construido usando los mismos principios que el <em>kernel</em> de Linux, solo que en un nivel diferente de abstracción.</p></li>
<li><p>abstrae la CPU, la memoria, el almacenamiento y otros recursos informáticos de las máquinas (físicas o virtuales), lo que permite que los sistemas distribuidos elásticos y tolerantes a fallas se construyan fácilmente y se ejecuten de manera efectiva.</p></li>
</ul>
<ul class="simple">
<li><p>El <em>kernel</em> de Mesos se ejecuta en todas las máquinas y proporciona aplicaciones (p. ej., Hadoop, Spark, Kafka, Elasticsearch) y una API para la gestión y programación de recursos para todo el centro de datos y entornos de nube.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://mesos.apache.org/">https://mesos.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Una comparativa entre las tecnologías Apache Mesos junto al gestor de contenedores Marathon <a class="reference external" href="https://mesosphere.github.io/marathon/">https://mesosphere.github.io/marathon/</a> y Kubernetes:</p>
<ul>
<li><p><a class="reference external" href="https://www.baeldung.com/ops/mesos-kubernetes-comparison">https://www.baeldung.com/ops/mesos-kubernetes-comparison</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="apache-zookeeper">
<h2>Apache Zookeeper<a class="headerlink" href="#apache-zookeeper" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>ZooKeeper es un servicio centralizado para mantener la información de configuración, nombrar, brindar sincronización distribuida y servicios grupales.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://zookeeper.apache.org/">https://zookeeper.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="apache-ambari">
<h2>Apache Ambari<a class="headerlink" href="#apache-ambari" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>El proyecto Apache Ambari tiene como objetivo simplificar la administración de Hadoop mediante el desarrollo de software para el aprovisionamiento, la administración y el monitoreo de clústeres de Apache Hadoop.</p></li>
<li><p>Ambari proporciona una interfaz de usuario web de administración de Hadoop intuitiva y fácil de usar respaldada por sus API RESTful.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://ambari.apache.org/">https://ambari.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="apache-ranger">
<h2>Apache Ranger<a class="headerlink" href="#apache-ranger" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Apache Ranger™ es un framework para habilitar, monitorear y administrar la seguridad integral de los datos en toda la plataforma Hadoop.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://ranger.apache.org/">https://ranger.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="apache-sentry-attic">
<h2>Apache Sentry (Attic)<a class="headerlink" href="#apache-sentry-attic" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Apache Sentry™ es un sistema para hacer cumplir la autorización detallada basada en roles para datos y metadatos almacenados en un clúster de Hadoop. Está en el <em>attic</em> desde diciembre del 2020.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://sentry.apache.org/">https://sentry.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="BigData-es001.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Big Data: Definición y características</p>
      </div>
    </a>
    <a class="right-next"
       href="BigData-es003.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Bases de datos para Big Data</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#procesos-en-big-data">Procesos en Big Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ingestion-de-datos">Ingestión de datos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cuestiones-a-considerar">Cuestiones a considerar</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#buenas-practicas-en-ingestion-de-datos">Buenas prácticas en ingestión de datos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problemas-en-la-ingesta-de-datos">Problemas en la ingesta de datos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#procesamiento-de-datos-en-tiempo-real">Procesamiento de datos en tiempo real</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-spark">Apache Spark</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-flume">Apache Flume</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-flink">Apache Flink</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sistemas-de-mensajeria">Sistemas de mensajería</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-kafka">Apache Kafka</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-activemq">Apache ActiveMQ</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-pulsar">Apache Pulsar</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pub-sub">Pub/Sub</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#otras-herramientas">Otras herramientas</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#logstash">Logstash</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-nifi">Apache Nifi</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-beam">Apache Beam</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-samza">Apache Samza</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-airflow">Apache Airflow</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#astro">Astro</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dbt">DBT</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Otras herramientas</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-semantico-de-datos-sdm">Modelo semántico de datos (SDM)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#almacenamiento-de-datos-data-storage">Almacenamiento de datos (Data Storage)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#persistencia-poliglota">Persistencia políglota</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#herramientas-de-almacenamiento-para-big-data">Herramientas de almacenamiento para Big Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hdfs">HDFS</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-ozone">Apache Ozone</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#glusterfs">GlusterFS</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ceph">Ceph</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#minio">MinIO</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#amazon-services">Amazon Services</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#microsoft-azure-data-lake-store">Microsoft Azure Data Lake Store</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#google-bigquery">Google BigQuery</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-warehouses-data-lakes-lakehouses">Data warehouses / Data lakes / Lakehouses</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#snowflake">Snowflake</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#databricks">Databricks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#delta-lake">Delta Lake</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-iceberg">Apache Iceberg</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-hudi">Apache Hudi</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-xtable">Apache XTable</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nosql-databases">NoSQL databases</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#herramientas-de-la-asf-para-big-data">Herramientas de la ASF para Big Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-mesos">Apache Mesos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-zookeeper">Apache Zookeeper</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-ambari">Apache Ambari</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-ranger">Apache Ranger</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-sentry-attic">Apache Sentry (Attic)</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Fortinux - Marcelo Horacio Fortino
</p>

  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <div>
<a href="https://creativecommons.org/licenses/by-sa/4.0/"><img src="https://licensebuttons.net/l/by-sa/3.0/88x31.png"></a>
    Esta obra está sujeta a la licencia Reconocimiento-CompartirIgual 4.0 Internacional de Creative Commons. Para ver una copia de esta licencia, visite <a href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0 license</a>. Puede hallar permisos más allá de los concedidos con esta licencia en <a href="https://fortinux.com" rel="nofollow">https://fortinux.com</a>. Sugerencias y comentarios a <a href="mailto:info@fortinux.com">info@fortinux.com</a>.
</div>

</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>