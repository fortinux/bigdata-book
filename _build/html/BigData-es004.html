

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Consulta y visualización de datos &#8212; Curso Introducción a Big Data</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=ac02cc09edc035673794" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=ac02cc09edc035673794" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=ac02cc09edc035673794"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'BigData-es004';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Tutorial MongoDB" href="BigData-es004MongoDB.html" />
    <link rel="prev" title="Bases de datos para Big Data" href="BigData-es003.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Introducción a Big Data
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="BigData-es001.html">Definición y características</a></li>
<li class="toctree-l1"><a class="reference internal" href="BigData-es002.html">Ingesta y almacenamiento de datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="BigData-es003.html">Bases de datos para Big Data</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Consulta y visualización de datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="BigData-es004MongoDB.html">Tutorial MongoDB</a></li>
<li class="toctree-l1"><a class="reference internal" href="BigData-es005.html">Frameworks y aplicaciones</a></li>
<li class="toctree-l1"><a class="reference internal" href="BigData-es005Hadoop.html">Tutorial Apache Hadoop</a></li>
<li class="toctree-l1"><a class="reference internal" href="BigData-es005Kafka.html">Tutorial Apache Kafka</a></li>
<li class="toctree-l1"><a class="reference internal" href="BigData-es007.html">Big Data Science</a></li>
<li class="toctree-l1"><a class="reference internal" href="BigData-es008.html">Big Data stacks y Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="BigData-es008sparkMLlib.html">Tutorial Spark</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/fortinux/bigdata-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/fortinux/bigdata-book/issues/new?title=Issue%20on%20page%20%2FBigData-es004.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/BigData-es004.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Consulta y visualización de datos</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#procesos-en-big-data">Procesos en Big Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#procesamiento-analisis-y-consulta-de-datos">Procesamiento, análisis y consulta de datos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-scoop-attic">Apache Scoop (Attic)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-spark">Apache Spark</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-storm">Apache Storm</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#storm-vs-spark">Storm vs. Spark</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-impala">Apache Impala</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-kudu">Apache Kudu</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-hive">Apache Hive</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-drill">Apache Drill</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#presto">Presto</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#trino">Trino</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-hadoop-yarn">Apache Hadoop YARN</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#alluxio">Alluxio</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#otras-herramientas">Otras herramientas</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#perfilado-de-datos-y-linaje">Perfilado de datos y linaje</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#calidad-de-los-datos">Calidad de los datos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#limpieza-de-datos">Limpieza de datos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prevencion-y-perdida-de-datos">Prevención y pérdida de datos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizacion-de-datos">Visualización de datos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#elastic-stack">Elastic Stack</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#elasticsearch">Elasticsearch</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-lucene">Apache Lucene</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-solr">Apache Solr</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#logstash">Logstash</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kibana">Kibana</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tutorial-elasticsearch">Tutorial Elasticsearch</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#salesforce-amazon-google-y-microsoft">Salesforce, Amazon, Google y Microsoft</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-superset">Apache Superset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#monitoreo-de-datos">Monitoreo de datos</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="consulta-y-visualizacion-de-datos">
<h1>Consulta y visualización de datos<a class="headerlink" href="#consulta-y-visualizacion-de-datos" title="Permalink to this heading">#</a></h1>
<section id="procesos-en-big-data">
<h2>Procesos en Big Data<a class="headerlink" href="#procesos-en-big-data" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Para el NIST Big Data interoperability Framework (NBDIF) - Version 3.0 Final <span id="id1">[<a class="reference internal" href="intro.html#id3" title="Wo Chang and Nancy Grady. Nist big data interoperability framework: volume 1, definitions. 2019-10-21 2019. doi:https://doi.org/10.6028/NIST.SP.1500-1r2.">CG19</a>]</span> (Pág.29), el ciclo de vida del análisis de los datos se compone de cinco fases:</p>
<ul>
<li><p>Captura de los datos en su formato original. Ingestión de datos (<em>Data Ingestion</em>).</p></li>
<li><p>Preparación y modelado. Almacenamiento de datos (<em>Data Storage</em>).</p></li>
<li><p>Análisis y consulta de datos (<em>Data Processing / Data Query</em>).</p></li>
<li><p>Visualización de los datos. (<em>Data Visualization</em>).</p></li>
<li><p>Acción con el uso de los mismos.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>En este apartado se verán las fases de análisis y consulta de datos, y visualización.</p></li>
</ul>
</section>
<section id="procesamiento-analisis-y-consulta-de-datos">
<h2>Procesamiento, análisis y consulta de datos<a class="headerlink" href="#procesamiento-analisis-y-consulta-de-datos" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Los datos recolectados en la fase anterior serán procesados en este paso.</p></li>
<li><p>Aquí, el sistema de procesamiento de canalización de datos enruta los datos a un destino diferente, clasifica el flujo de datos y es el primer punto donde puede tener lugar el análisis.</p></li>
<li><p>Esta es la capa donde las consultas (<em>queries</em>) y el proceso analítico activo se ejecutan.</p></li>
</ul>
<ul class="simple">
<li><p>Para ello, los analistas emplean diferentes herramientas y estrategias como, por ejemplo:</p>
<ul>
<li><p>Modelado estadístico.</p></li>
<li><p>Algoritmos.</p></li>
<li><p>Inteligencia artificial (AI).</p></li>
<li><p>Minería de datos.</p></li>
<li><p>Aprendizaje automático (ML).</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Las consultas interactivas para el procesamiento de datos son necesarias y es una zona tradicionalmente dominada por desarrolladores expertos en SQL.</p></li>
<li><p>Con Hadoop, la ingesta de datos, el almacenamiento, el proceso y el análisis se volvieron fáciles de trabajar cuando se cuenta con una gran cantidad de datos.</p></li>
</ul>
<ul class="simple">
<li><p>Para análisis fuera de línea, se utiliza un sistema de procesamiento por lotes simple.</p></li>
<li><p>Apache Sqoop es la aplicación que se encarga de esto.</p></li>
<li><p>Transfiere eficientemente datos estructurados entre Apache Hadoop y las bases de datos relacionales.</p></li>
<li><p>Spark por otro lado, es utilizado mayoritariamente para el análisis y procesamiento de datos en tiempo real.</p></li>
<li><p>Otra herramienta pero menos utilizada es Apache Storm.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://sqoop.apache.org/">https://sqoop.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Otras herramientas a considerar útiles en este proceso son:</p></li>
</ul>
<ul class="simple">
<li><p>KNIME hace que la comprensión de datos y el diseño de flujos de trabajo de ciencia de datos y componentes reutilizables sean accesibles para todos.</p>
<ul>
<li><p><a class="reference external" href="https://www.knime.com/">https://www.knime.com/</a>.</p></li>
</ul>
</li>
<li><p>Apache Mahout es un framework distribuido de álgebra linear y Scala DSL matemáticamente expresivo.</p>
<ul>
<li><p><a class="reference external" href="https://mahout.apache.org/">https://mahout.apache.org/</a>.</p></li>
</ul>
</li>
<li><p>Weka 3: Machine Learning Software en Java para hacer análisis simple.</p>
<ul>
<li><p><a class="reference external" href="https://www.cs.waikato.ac.nz/ml/weka/">https://www.cs.waikato.ac.nz/ml/weka/</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="apache-scoop-attic">
<h2>Apache Scoop (Attic)<a class="headerlink" href="#apache-scoop-attic" title="Permalink to this heading">#</a></h2>
<p><em>Apache Attic <a class="reference external" href="https://attic.apache.org/">https://attic.apache.org/</a> es utilizado por la Apache Software Foundation como espacio para los proyectos que ya han llegado a su final de vida y no cuentan con más desarrollo ni mantenimiento.</em></p>
<ul class="simple">
<li><p>Transfiere eficientemente datos estructurados entre Apache Hadoop y las bases de datos relacionales.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://sqoop.apache.org/">https://sqoop.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Se puede usar Sqoop para importar datos desde un sistema de administración de bases de datos relacionales (RDBMS) como MySQL u Oracle o un mainframe al sistema de archivos distribuidos de Hadoop (HDFS), transformar los datos en Hadoop MapReduce y luego exportar los datos nuevamente a un RDBMS.</p></li>
</ul>
<ul class="simple">
<li><p>Apache Sqoop también puede ser utilizado para extraer datos de Hadoop y exportarlos a almacenes de datos estructurados externos.</p></li>
<li><p>Apache Sqoop trabaja con bases de datos relacionales como Teradata, Netezza, Oracle, MySQL, Postgres, y HSQLDB.</p></li>
</ul>
<ul class="simple">
<li><p>Sqoop automatiza la mayor parte de este proceso, basándose en la base de datos para describir el esquema de los datos que se importarán.</p></li>
<li><p>Sqoop utiliza MapReduce para importar y exportar los datos, lo cual proporciona procesamiento en paralelo y tolerancia a fallos.</p></li>
</ul>
</section>
<section id="apache-spark">
<h2>Apache Spark<a class="headerlink" href="#apache-spark" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Framework de procesamiento paralelo y de código abierto para ejecutar aplicaciones de análisis de datos a gran escala en sistemas agrupados.</p></li>
<li><p>Utilizado por más del 80% de las empresas <em>Fortune 500</em> y miles de otras empresas en todo el mundo.</p></li>
<li><p>Fue desarrollado en la <em>University of California</em>, Berkeley, EE.UU.</p></li>
</ul>
<ul class="simple">
<li><p>Extraído de: <a class="reference external" href="https://spark.apache.org/">https://spark.apache.org/</a>.</p></li>
</ul>
<ul class="simple">
<li><p>Sus funcionalidades básicas son:</p>
<ul>
<li><p>Procesamiento de datos en <em>batch/streaming</em> utilizando Python, SQL, Scala, Java o R.</p></li>
<li><p>Analíticas mediante SQL ejecutando consultas para <em>dashboards</em> e informes más rápudas que la mayoría de los <em>data warehouses</em>.</p></li>
<li><p>Ciencia de datos en escala realizando <em>Exploratory Data Analysis - EDA</em> con petabytes de datos.</p></li>
<li><p>Machine learning para entrenar algoritmos en un <em>laptop</em> usando el mismo código que luego se utilizará en clústeres de miles de máquinas.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>También es compatible con un amplio conjunto de herramientas de alto nivel, que incluyen:</p>
<ul>
<li><p>Spark SQL para SQL y procesamiento de datos estructurados,</p></li>
<li><p>MLlib para aprendizaje automático,</p></li>
<li><p>GraphX para procesamiento de gráficos, y</p></li>
<li><p>Transmisión estructurada para procesamiento incremental y de streaming.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Se utiliza para realizar trabajos informáticos con grandes cargas de datos junto a Apache Kafka.</p></li>
<li><p>Con Spark ejecutándose en Apache Hadoop YARN, los desarrolladores pueden crear aplicaciones para explotar el poder de Spark, obtener información y enriquecer sus cargas de trabajo de ciencia de datos dentro de un único conjunto de datos compartidos en Hadoop.</p></li>
</ul>
</section>
<section id="apache-storm">
<h2>Apache Storm<a class="headerlink" href="#apache-storm" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Es un sistema distribuido open source para procesar datos en tiempo real durante la ingesta de datos.</p></li>
<li><p>Es escalable, tiene tolerancia a fallos, y es fácil de configurar y operar.</p></li>
<li><p>Facilita el procesamiento confiable de flujos ilimitados de datos, haciendo para el procesamiento en tiempo real lo que Hadoop hizo para el procesamiento por lotes.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://storm.apache.org/">https://storm.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>No existe ningún truco que convierta a Hadoop en un sistema en tiempo real.</p></li>
<li><p>El procesamiento de datos en tiempo real tiene un conjunto de requisitos fundamentalmente diferente al procesamiento por lotes.</p></li>
<li><p>Apache Storm agrega a Hadoop esta funcionalidad de manera sencilla.</p></li>
</ul>
<ul class="simple">
<li><p>Casos de uso:</p>
<ul>
<li><p>Análisis en tiempo real</p></li>
<li><p>Aprendizaje automático</p></li>
<li><p>Monitoreo continuo de operaciones</p></li>
<li><p>RPC distribuido, ETL, y más.</p></li>
</ul>
</li>
</ul>
</section>
<section id="storm-vs-spark">
<h2>Storm vs. Spark<a class="headerlink" href="#storm-vs-spark" title="Permalink to this heading">#</a></h2>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Situation</p></th>
<th class="head"><p>Spark</p></th>
<th class="head"><p>Storm</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Stream processing</p></td>
<td><p>Batch processing</p></td>
<td><p>Micro-batch processing</p></td>
</tr>
<tr class="row-odd"><td><p>Latency</p></td>
<td><p>Latency of a few seconds</p></td>
<td><p>Latency of milliseconds</p></td>
</tr>
<tr class="row-even"><td><p>Multi-language support</p></td>
<td><p>Lesser language support</p></td>
<td><p>Multiple language support</p></td>
</tr>
<tr class="row-odd"><td><p>Languages</p></td>
<td><p>Java – Scala</p></td>
<td><p>Java – Scala – Clojure</p></td>
</tr>
<tr class="row-even"><td><p>Stream sources</p></td>
<td><p>HDFS</p></td>
<td><p>Spout</p></td>
</tr>
<tr class="row-odd"><td><p>Resource management</p></td>
<td><p>Yarn, Mesos</p></td>
<td><p>Yarn, Mesos</p></td>
</tr>
<tr class="row-even"><td><p>Provisioning</p></td>
<td><p>Basic using Ganglia</p></td>
<td><p>Apache Ambari</p></td>
</tr>
<tr class="row-odd"><td><p>Messaging</p></td>
<td><p>Netty, Akka</p></td>
<td><p>ZeroMQ, Netty</p></td>
</tr>
</tbody>
</table>
</section>
<section id="apache-impala">
<h2>Apache Impala<a class="headerlink" href="#apache-impala" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Impala eleva el nivel de rendimiento de las consultas SQL en Apache Hadoop al mismo tiempo que conserva una experiencia de usuario familiar.</p></li>
<li><p>Con Impala, se puede consultar datos, ya sea que estén almacenados en HDFS o Apache HBase, incluidas las funciones SELECT, JOIN y agregadas, en tiempo real.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://impala.apache.org/">https://impala.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Impala utiliza los mismos metadatos, sintaxis SQL (Hive SQL), controlador ODBC e interfaz de usuario (Hue Beeswax) que Apache Hive, lo que proporciona una plataforma familiar y unificada para consultas en tiempo real o por lotes.</p></li>
<li><p>Los usuarios de Hive pueden utilizar Impala con algunos pocos ajustes.</p></li>
</ul>
</section>
<section id="apache-kudu">
<h2>Apache Kudu<a class="headerlink" href="#apache-kudu" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Apache Kudu es un motor de almacenamiento columnar open source para datos estructurados.</p></li>
<li><p>Está diseñado y optimizado para análisis de big data en datos que cambian rápidamente o para un rendimiento rápido en consultas analíticas - OLAP.</p></li>
<li><p>Es distribuido, permite varios tipos de partición de datos y carga compartida en varios servidores.</p></li>
<li><p>Es parte del ecosistema Hadoop y se integra con frameworks de procesamiento de datos como Spark, Impala y MapReduce.</p>
<ul>
<li><p><a class="reference external" href="https://kudu.apache.org/">https://kudu.apache.org/</a></p></li>
</ul>
</li>
</ul>
</section>
<section id="apache-hive">
<h2>Apache Hive<a class="headerlink" href="#apache-hive" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Apache Hive es una infraestructura de almacenamiento de datos construida sobre Apache Hadoop para proporcionar resúmenes de datos, consultas ad-hoc y análisis de grandes conjuntos de datos.</p></li>
<li><p>Los analistas de datos usan Hive para consultar, resumir, explorar y analizar esos datos, y luego convertirlos en información empresarial procesable.</p>
<ul>
<li><p>Fuente: <a class="reference external" href="https://hive.apache.org/">https://hive.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>El software de almacenamiento de datos Apache Hive facilita la lectura, escritura y administración de grandes conjuntos de datos que residen en almacenamiento distribuido mediante SQL.</p></li>
<li><p>La estructura se puede proyectar sobre los datos que ya están almacenados.</p></li>
<li><p>Se proporciona una herramienta de línea de comandos y un controlador JDBC para conectar a los usuarios a Hive.</p></li>
<li><p>Proporciona un mecanismo para la estructura del proyecto de ingesta de datos en los datos de Hadoop y para consultar esos datos mediante con un lenguaje tipo SQL llamado HiveQL (HQL).</p></li>
</ul>
<ul class="simple">
<li><p>Sus características principales son:</p></li>
</ul>
<ul class="simple">
<li><p><em>Hive-Server 2 - HS2</em> para multi-client concurrency y autenticación.</p></li>
<li><p>Provee un repositorio central de metadatos mediante <em>Hive Metastore(HMS)</em> y soporta el almacenamiento en S3, adls, gs, etc. a través de HDFS.</p></li>
<li><p><em>Hive ACID</em> provee soporte completo ACID para las tabls ORC e <em>insert only</em> para todos los otros formatos.</p></li>
</ul>
<ul class="simple">
<li><p>Ofrece soporte de autenticación mediante kerberos y se integra con <em>Apache Ranger</em> y <em>Apache Atlas</em> para seguridad y <em>observability</em>.</p></li>
<li><p>Compactación de datos <em>out-of-the-box</em> y soporte para tablas de <em>Apache Iceberg</em>.</p></li>
<li><p>Incluye LLAP (<em>Low Latency Analytical Processing</em>), un planificador de consultas y costes utilizando <em>Apache Calcite</em> <a class="reference external" href="https://cwiki.apache.org/confluence/display/Hive/Cost-based+optimization+in+Hive">https://cwiki.apache.org/confluence/display/Hive/Cost-based+optimization+in+Hive</a> y replicación.</p></li>
</ul>
</section>
<section id="apache-drill">
<h2>Apache Drill<a class="headerlink" href="#apache-drill" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Es un motor SQL para Hadoop, NoSQL y almacenamiento en la nube.</p></li>
<li><p>Soporta variadas bases de datos NoSQL y sistemas de ficheros:</p>
<ul>
<li><p>HBase, MongoDB, HDFS, Amazon S3, Azure Blob Storage, Google Cloud Storage, NAS y ficheros locales.</p></li>
</ul>
</li>
<li><p>Una única consulta puede obtener datos de múltiples bases de datos.</p></li>
<li><p>Integración con <em>Apache Hive</em>:</p>
<ul>
<li><p>Consultas en las tablas y vistas, soporte para todos los formatos de ficheros y <em>User-Defined Functions - UDFs</em>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Fuente: <a class="reference external" href="https://drill.apache.org/">https://drill.apache.org/</a>.</p></li>
</ul>
</section>
<section id="presto">
<h2>Presto<a class="headerlink" href="#presto" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Motor SQL desarrollado por Meta (Facebook) para análisis ad-hoc e informes rápidos.</p></li>
<li><p>Es un motor de consulta SQL distribuido de código abierto que ejecuta consultas analíticas interactivas en fuentes de datos de todos los tamaños, desde gigabytes hasta petabytes.</p>
<ul>
<li><p>Fuente: <a class="reference external" href="https://prestodb.io/">https://prestodb.io/</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Meta utiliza Presto para consultas interactivas en varios almacenes de datos internos, incluido su almacén de datos de 300 PB.</p></li>
<li><p>Más de 1000 empleados de Meta usan Presto diariamente para ejecutar más de 30000 consultas que, en total, escanean más de un petabyte por día.</p></li>
</ul>
<ul class="simple">
<li><p>Se puede descargar el libro electrónico <em>Learning and operating presto</em> registrándose en <a class="reference external" href="https://prestodb.io/getting-started/">https://prestodb.io/getting-started/</a>.</p></li>
</ul>
</section>
<section id="trino">
<h2>Trino<a class="headerlink" href="#trino" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Trino es un motor de consulta SQL distribuido diseñado para consultar grandes conjuntos de datos distribuidos en una o más fuentes de datos heterogéneas.</p></li>
<li><p>Son los fundadores del proyecto Presto que tuvieron que cambiarle el nombre por cuestiones legales.</p>
<ul>
<li><p>Fuente: <a class="reference external" href="https://trino.io/">https://trino.io/</a></p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Se puede descargar el libro <em>Trino: The Definitive Guide, 2nd Edition</em> (los autores son los creadores de Trino) registrándose en <a class="reference external" href="https://www.starburst.io/info/oreilly-trino-guide/">https://www.starburst.io/info/oreilly-trino-guide/</a>.</p></li>
</ul>
</section>
<section id="apache-hadoop-yarn">
<h2>Apache Hadoop YARN<a class="headerlink" href="#apache-hadoop-yarn" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Tecnología de gestión de clústeres en Hadoop de segunda generación.</p></li>
<li><p>La idea de YARN es dividir las funcionalidades de gestión de recursos y programación/supervisión de trabajos en servicios separados: un <em>ResourceManager</em> (RM) global y un <em>ApplicationMaster</em> (AM) por aplicación.</p></li>
<li><p>Una aplicación es un solo trabajo o un DAG de trabajos.</p></li>
<li><p>El <em>ResourceManager</em> y el <em>NodeManager</em> forman el framework de cálculo de datos.</p></li>
</ul>
<ul class="simple">
<li><p>Fuente: <a class="reference external" href="https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html">https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html</a>.</p></li>
</ul>
<ul class="simple">
<li><p>El <em>ResourceManager</em> arbitra los recursos entre todas las aplicaciones del sistema.</p></li>
<li><p>El <em>NodeManager</em> es el agente del framework por máquina que es responsable de los contenedores, monitorea el uso de sus recursos (cpu, memoria, disco, red) e informa al <em>ResourceManager/Scheduler</em>.</p></li>
</ul>
<ul class="simple">
<li><p>La aplicación <em>ApplicationMaster</em> es en efecto una biblioteca específica del framework y tiene la tarea de negociar recursos del <em>ResourceManager</em> y trabajar con el/los <em>NodeManager(s)</em> para ejecutar y monitorear las tareas.</p></li>
</ul>
</section>
<section id="alluxio">
<h2>Alluxio<a class="headerlink" href="#alluxio" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Alluxio es una plataforma de orquestación de datos (<em>data orchestration platform</em>) que habilita la separación entre las capas de cómputo y almacenamiento.</p></li>
<li><p>Brinda velocidad y agilidad a las cargas de datos en Big Data e inteligencia artificial reduciendo costes gracias a la eliminación de datos duplicados.</p></li>
<li><p>Permite también trabajar con <em>object stores</em>.</p></li>
</ul>
<ul class="simple">
<li><p>Fuente: <a class="reference external" href="https://www.alluxio.io/data-orchestration/">https://www.alluxio.io/data-orchestration/</a>.</p></li>
</ul>
</section>
<section id="otras-herramientas">
<h2>Otras herramientas<a class="headerlink" href="#otras-herramientas" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Vertica es un almacén de datos (<em>data warehouse</em>) de análisis unificado.</p></li>
<li><p>Ha sido diseñado para ofrecer velocidad, escalabilidad y aprendizaje automático integrado para cargas de trabajo analíticamente intensivas.</p>
<ul>
<li><p>Extraído de <a class="reference external" href="https://www.vertica.com/landing-page/start-your-free-trial-today/">https://www.vertica.com/landing-page/start-your-free-trial-today/</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Hue es un asistente open source de SQL para bases de datos y <em>data warehouses</em>.</p></li>
<li><p>Provee un editor de código SQL con componentes y autocompletado que permite conectarse a cualquier base de datos.</p>
<ul>
<li><p>Fuente: <a class="reference external" href="https://gethue.com/">https://gethue.com/</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="perfilado-de-datos-y-linaje">
<h2>Perfilado de datos y linaje<a class="headerlink" href="#perfilado-de-datos-y-linaje" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Perfilado de datos y linaje (<em>data profiling and lineage</em>) son técnicas que permiten identificar la calidad de los datos y su ciclo de vida durante las varias fases que percorren.</p></li>
<li><p>Es importante capturar los metadatos en cada paso del proceso para que puedan ser utilizados posteriormente para verificación y personalización.</p></li>
<li><p>Algunas aplicacione disponibles: <em>Talend, Hive, Pig</em>.</p></li>
</ul>
<ul class="simple">
<li><p><em>Talend Data Fabric</em> es un conjunto de aplicaciones nativas de la nube que lidera la industria en integración y gestión de datos:</p>
<ul>
<li><p>Identifica elementos de datos.</p></li>
<li><p>Realiza un seguimiento hasta el origen de los datos.</p></li>
<li><p>Combina fuentes de datos y enlaces a los mismos.</p></li>
<li><p>Crea un mapa para cada sistema y un mapa maestro de la imagen completa.</p></li>
<li><p>Extraído de: <a class="reference external" href="https://www.talend.com/">https://www.talend.com/</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p><em>OpenLineage</em> es un framework open source para la recopilación y el análisis del linaje de datos.</p></li>
<li><p>Permite una recopilación consistente de metadatos de linaje, creando una comprensión más profunda de cómo se producen y utilizan los datos.</p></li>
<li><p>se integra con <em>Airflow, Spark</em> y <em>dbt</em>.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://openlineage.io/">https://openlineage.io/</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="calidad-de-los-datos">
<h2>Calidad de los datos<a class="headerlink" href="#calidad-de-los-datos" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>La ingesta de datos se considera de alta calidad si cumple con las necesidades comerciales y satisface el uso previsto, de modo que sea útil para tomar decisiones de negocio con éxito.</p></li>
<li><p>Por lo tanto, es un paso importante entender la dimensión de mayor interés e implementar métodos para lograrla.</p></li>
</ul>
</section>
<section id="limpieza-de-datos">
<h2>Limpieza de datos<a class="headerlink" href="#limpieza-de-datos" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>La limpieza de datos (<em>data cleansing</em>) significa implementar varias soluciones para corregir datos incorrectos o corruptos.</p></li>
</ul>
</section>
<section id="prevencion-y-perdida-de-datos">
<h2>Prevención y pérdida de datos<a class="headerlink" href="#prevencion-y-perdida-de-datos" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Deben existir políticas para asegurarse de que se resuelvan las lagunas en la pérdida de datos.</p></li>
<li><p>La identificación de dicha pérdida de datos necesita un control cuidadoso y procesos de evaluación de la calidad en el flujo del proceso de ingesta de datos.</p></li>
</ul>
</section>
<section id="visualizacion-de-datos">
<h2>Visualización de datos<a class="headerlink" href="#visualizacion-de-datos" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>La fase de visualización o presentación es donde los usuarios pueden sentir el VALOR de los DATOS.</p></li>
<li><p>La visualización de hallazgos ayuda a tomar mejores decisiones de negocios.</p></li>
<li><p>Aquí se generan informes por tipo de audiencia (comerciales, marketing, estrategia, técnicos, etc).</p></li>
</ul>
<ul class="simple">
<li><p>Si bien está diseñado para manejar y almacenar grandes volúmenes de datos, Hadoop y otras herramientas no tienen disposiciones integradas para la visualización de datos y la distribución de información, lo que no permite que los usuarios finales del negocio puedan consumir fácilmente esos datos en la canalización de ingesta de datos.</p></li>
</ul>
<ul class="simple">
<li><p>Los paneles personalizados son útiles para crear vistas generales únicas que presentan los datos de manera diferente.</p></li>
<li><p>Puede mostrar la información de la aplicación web y móvil, la información del servidor, los datos de métricas personalizadas y los datos de métricas de complementos, todo en un único tablero personalizado.</p></li>
<li><p>Los paneles en tiempo real guardan, comparten y comunican información.</p></li>
<li><p>Ayuda a los usuarios a generar preguntas al revelar la profundidad, el rango y el contenido de los almacenes de datos.</p></li>
</ul>
<ul class="simple">
<li><p>Los paneles de visualización de datos siempre cambian a medida que llegan nuevos datos.</p></li>
<li><p>Los tableros pueden contener múltiples visualizaciones de múltiples conexiones una al lado de la otra.</p></li>
<li><p>Se pueden crear, editar, filtrar y eliminar tableros rápidamente y moverlos y cambiar su tamaño y luego compartirlos o integrarlos en su aplicación web.</p></li>
<li><p>Se puede exportar un tablero como una imagen o utilizando una configuración de archivo tipo JSON.</p></li>
</ul>
<ul class="simple">
<li><p>De acuerdo con el NIST Big Data interoperability Framework (NBDIF) - Version 3.0 Final <span id="id2">[<a class="reference internal" href="intro.html#id3" title="Wo Chang and Nancy Grady. Nist big data interoperability framework: volume 1, definitions. 2019-10-21 2019. doi:https://doi.org/10.6028/NIST.SP.1500-1r2.">CG19</a>]</span> (Pág.31) tres son los tipos de visualizaciones que varían en técnicas y en propósito:</p>
<ul>
<li><p>Visualización exploratoria: técnicas para entender la distribución de los valores en los elementos. Se pueden necesitar también técnicas de agregación o de resumen.</p></li>
<li><p>Visualización evaluatoria: permite comprender el desempeño y exactitud de un método particular de análisis o <em>machine learning</em>.</p>
<ul>
<li><p>Los datos pequeños (<em>small data</em>) se refieren a los límites en el tamaño de los conjuntos de datos que los analistas pueden evaluar y comprender por completo.</p></li>
</ul>
</li>
<li><p>Visualización exploratoria: la presentación de datos complejos de manera fácil para ser entendidos por quienes toman decisiones.</p></li>
</ul>
</li>
</ul>
</section>
<section id="elastic-stack">
<h2>Elastic Stack<a class="headerlink" href="#elastic-stack" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>En sus inicios el ELK Stack se componía de las aplicaciones Elasticsearch, Logstash, Kibana, y Beats.</p></li>
<li><p>Actualmente se lo conoce como Elastic Stack, nombre que le permite agregar nuevas funcionalidades.</p></li>
<li><p>Conocido por sus API REST simples, naturaleza distribuida, velocidad y escalabilidad, Elasticsearch es el componente central de Elastic Stack, un conjunto de herramientas de código abierto para la ingesta, el enriquecimiento, el almacenamiento, el análisis y la visualización de datos.</p></li>
<li><p>Kibana es la interfaz de usuario gratuita y abierta que permite visualizar los datos.</p></li>
</ul>
<ul class="simple">
<li><p>Extraído de: <a class="reference external" href="https://www.elastic.co/what-is/elasticsearch">https://www.elastic.co/what-is/elasticsearch</a>.</p></li>
</ul>
<ul class="simple">
<li><p>Casos de uso:</p></li>
</ul>
<ul class="simple">
<li><p>Búsqueda de aplicaciones.</p></li>
<li><p>Búsqueda de sitio web.</p></li>
<li><p>Búsqueda Empresarial.</p></li>
<li><p>Logging y analíticas de log.</p></li>
</ul>
<ul class="simple">
<li><p>Métricas de infraestructura y monitoreo de contenedores.</p></li>
<li><p>Monitoreo de rendimiento de aplicaciones.</p></li>
<li><p>Análisis y visualización de datos geoespaciales.</p></li>
<li><p>Analítica de Seguridad.</p></li>
<li><p>Analítica de Negocios.</p></li>
</ul>
</section>
<section id="elasticsearch">
<h2>Elasticsearch<a class="headerlink" href="#elasticsearch" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Elasticsearch es un motor de análisis y búsqueda de código abierto distribuido para todo tipo de datos, incluidos textuales, numéricos, geoespaciales, estructurados y no estructurados.</p></li>
<li><p>Elasticsearch se basa en Apache Lucene y fue lanzado por primera vez en 2010 por Elasticsearch N.V. (ahora conocido como Elastic).</p></li>
</ul>
<ul class="simple">
<li><p>La ingesta de datos es el proceso mediante el cual estos datos sin procesar se analizan, normalizan y enriquecen antes de indexarlos en Elasticsearch.</p></li>
<li><p>Los datos sin procesar fluyen hacia Elasticsearch desde una variedad de fuentes, incluidos registros, métricas del sistema y aplicaciones web.</p></li>
</ul>
<ul class="simple">
<li><p>Extraído de: <a class="reference external" href="https://www.elastic.co/">https://www.elastic.co/</a>.</p></li>
</ul>
</section>
<section id="apache-lucene">
<h2>Apache Lucene<a class="headerlink" href="#apache-lucene" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Lucene Core es una biblioteca de Java que proporciona potentes funciones de indexación y búsqueda, así como funciones de corrección ortográfica, resaltado de aciertos y análisis/tokenización avanzados.</p></li>
<li><p>El subproyecto PyLucene proporciona enlaces de Python para Lucene Core.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://lucene.apache.org/">https://lucene.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>PyLucene incorpora una VM de Java con Lucene en un proceso de Python.</p></li>
<li><p>El módulo de Python llamado <em>lucene</em> es generado por máquina por JCC.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://lucene.apache.org/pylucene/">https://lucene.apache.org/pylucene/</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Lucene Core tiene una serie de proyectos relacionados, entre los cuales se encuentran:</p></li>
</ul>
<ul class="simple">
<li><p>Manifold: Framework de código abierto para conectar repositorios de contenido de origen, como Microsoft Sharepoint y EMC Documentum, a repositorios o índices de destino, como Apache Solr, Open Search Server o ElasticSearch.</p>
<ul>
<li><p><a class="reference external" href="https://manifoldcf.apache.org/en_US/index.html">https://manifoldcf.apache.org/en_US/index.html</a>.</p></li>
</ul>
</li>
<li><p><a class="reference external" href="http://LUCENE.net">LUCENE.net</a>: biblioteca de motor de búsqueda de alto rendimiento para .NET.</p>
<ul>
<li><p><a class="reference external" href="https://lucenenet.apache.org/">https://lucenenet.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Apache Tika: El kit de herramientas Apache Tika detecta y extrae metadatos y texto de más de mil tipos de archivos diferentes (como PPT, XLS y PDF). Todos estos tipos de archivos se pueden analizar a través de una sola interfaz, lo que hace que Tika sea útil para la indexación de motores de búsqueda, el análisis de contenido, la traducción y mucho más.</p>
<ul>
<li><p><a class="reference external" href="https://tika.apache.org/">https://tika.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Nutch es un rastreador web altamente extensible, altamente escalable, maduro y listo para producción que permite una configuración detallada y se adapta a una amplia variedad de tareas de adquisición de datos.</p>
<ul>
<li><p><a class="reference external" href="https://nutch.apache.org/">https://nutch.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>La biblioteca Apache OpenNLP es un conjunto de herramientas basado en el aprendizaje automático para el procesamiento de texto en lenguaje natural.</p></li>
<li><p>Admite las tareas más comunes de NLP, como la tokenización, la segmentación de oraciones, el etiquetado de partes del discurso, la extracción de entidades nombradas, la fragmentación, el análisis y la resolución de correferencias.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://opennlp.apache.org/">https://opennlp.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Apache Mahout es un framework distribuido de álgebra linear y Scala DSL que tiene como objetivo crear aplicaciones de aprendizaje automático (ML) escalables y eficaces.</p>
<ul>
<li><p><a class="reference external" href="https://mahout.apache.org/">https://mahout.apache.org/</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="apache-solr">
<h2>Apache Solr<a class="headerlink" href="#apache-solr" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Solr es un servidor de búsqueda de alto rendimiento creado con Lucene Core.</p></li>
<li><p>Solr es altamente escalable y proporciona indexación, búsqueda y análisis distribuidos totalmente tolerantes a fallas.</p></li>
<li><p>Expone las características de Lucene a través de interfaces JSON/HTTP fáciles de usar o clientes nativos para Java y otros lenguajes.</p></li>
</ul>
<ul class="simple">
<li><p>Extraído de: <a class="reference external" href="https://solr.apache.org/">https://solr.apache.org/</a>.</p></li>
<li><p>Imagen Docker Sorl: <a class="reference external" href="https://hub.docker.com/_/solr">https://hub.docker.com/_/solr</a>.</p></li>
</ul>
</section>
<section id="logstash">
<h2>Logstash<a class="headerlink" href="#logstash" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Logstash se usa para agregar y procesar datos y enviarlos a Elasticsearch.</p></li>
<li><p>Es una canalización (<em>pipeline</em>) de procesamiento de datos del lado del servidor de código abierto que le permite ingerir datos de múltiples fuentes simultáneamente y enriquecerlos y transformarlos antes de que se indexen en Elasticsearch.</p></li>
</ul>
<ul class="simple">
<li><p>Un índice de Elasticsearch es una colección de documentos que están relacionados entre sí.</p></li>
<li><p>Elasticsearch almacena datos como documentos JSON.</p></li>
<li><p>Cada documento correlaciona un conjunto de claves (nombres de campos o propiedades) con sus valores correspondientes (cadenas, números, booleanos, fechas, matrices de valores, geolocalizaciones u otros tipos de datos).</p></li>
</ul>
<ul class="simple">
<li><p>Elasticsearch utiliza una estructura de datos denominada índice invertido, que está diseñada para permitir búsquedas de texto completo muy rápidas.</p></li>
<li><p>Un índice invertido enumera cada palabra única que aparece en cualquier documento e identifica todos los documentos en los que aparece cada palabra.</p></li>
</ul>
<ul class="simple">
<li><p>La indexación se inicia con la API de índice, a través de la cual puede agregar o actualizar un documento JSON en un índice específico.</p></li>
<li><p>Durante el proceso de indexación, Elasticsearch almacena documentos y crea un índice invertido para que los datos del documento se puedan buscar casi en tiempo real.</p></li>
</ul>
<ul class="simple">
<li><p>Una vez indexados en Elasticsearch, los usuarios pueden ejecutar consultas complejas en sus datos y usar agregaciones para recuperar resúmenes complejos de sus datos.</p></li>
<li><p>Desde Kibana, los usuarios pueden crear potentes visualizaciones de sus datos, compartir paneles y administrar el Elastic Stack.</p></li>
</ul>
</section>
<section id="kibana">
<h2>Kibana<a class="headerlink" href="#kibana" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Kibana es una herramienta de visualización y gestión de datos para Elasticsearch que brinda histogramas en tiempo real, gráficos circulares y mapas.</p></li>
<li><p>Kibana también incluye aplicaciones avanzadas, como Canvas, que permite a los usuarios crear infografías dinámicas personalizadas con base en sus datos, y Elastic Maps para visualizar los datos geoespaciales.</p></li>
</ul>
<ul class="simple">
<li><p>Elasticsearch soporta una variedad de lenguajes de programación facilitando clientes para:</p></li>
</ul>
<ul class="simple">
<li><p>Java.</p></li>
<li><p>JavaScript (Node.js).</p></li>
<li><p>Go.</p></li>
<li><p>.NET (C#).</p></li>
<li><p>PHP.</p></li>
<li><p>Perl.</p></li>
<li><p>Python.</p></li>
<li><p>Ruby.</p></li>
</ul>
<ul class="simple">
<li><p>Cuenta además con herramientas para la línea de comandos:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">elasticsearch</span><span class="o">-</span><span class="n">certgen</span>
<span class="n">elasticsearch</span><span class="o">-</span><span class="n">certutil</span>
<span class="n">elasticsearch</span><span class="o">-</span><span class="n">croneval</span>
<span class="n">elasticsearch</span><span class="o">-</span><span class="n">keystore</span>
<span class="n">elasticsearch</span><span class="o">-</span><span class="n">migrate</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">line</span> <span class="mi">1</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">elasticsearch</span><span class="o">-</span><span class="n">certgen</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="n">elasticsearch</span><span class="o">-</span><span class="n">certutil</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="n">elasticsearch</span><span class="o">-</span><span class="n">croneval</span>

<span class="ne">NameError</span>: name &#39;elasticsearch&#39; is not defined
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">elasticsearch</span><span class="o">-</span><span class="n">node</span>
<span class="n">elasticsearch</span><span class="o">-</span><span class="n">saml</span><span class="o">-</span><span class="n">metadata</span>
<span class="n">elasticsearch</span><span class="o">-</span><span class="n">setup</span><span class="o">-</span><span class="n">passwords</span>
<span class="n">elasticsearch</span><span class="o">-</span><span class="n">shard</span>
<span class="n">elasticsearch</span><span class="o">-</span><span class="n">syskeygen</span>
<span class="n">elasticsearch</span><span class="o">-</span><span class="n">users</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Fuente: <a class="reference external" href="https://www.elastic.co/guide/en/elasticsearch/reference/current/commands.html">https://www.elastic.co/guide/en/elasticsearch/reference/current/commands.html</a>.</p></li>
</ul>
<ul class="simple">
<li><p>Un documento en Kibana se compone de campos con valores:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Un documento puede contener varios campos con valores</span>
<span class="p">{</span>
  <span class="s2">&quot;name&quot;</span> <span class="p">:</span> <span class="s2">&quot;Elastic&quot;</span><span class="p">,</span>
  <span class="o">...</span>
  <span class="o">&lt;</span><span class="n">field</span><span class="o">&gt;</span> <span class="p">:</span> <span class="o">&lt;</span><span class="n">value</span><span class="o">&gt;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Fuente: (<a class="reference external" href="http://assets.contentstack.io">assets.contentstack.io</a>) [<a class="reference external" href="https://assets.contentstack.io/v3/assets/bltefdd0b53724fa2ce/blt56ad3f4e2c755f29/5d37c1602a506857d64eff48/es_commands.txt">https://assets.contentstack.io/v3/assets/bltefdd0b53724fa2ce/blt56ad3f4e2c755f29/5d37c1602a506857d64eff48/es_commands.txt</a>].</p></li>
</ul>
<section id="tutorial-elasticsearch">
<h3>Tutorial Elasticsearch<a class="headerlink" href="#tutorial-elasticsearch" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Descargar e instalar la máquina virtual de elasticsearch en Bitnami.</p></li>
<li><p><a class="reference external" href="https://bitnami.com/stack/elasticsearch/virtual-machine">https://bitnami.com/stack/elasticsearch/virtual-machine</a>.</p></li>
</ul>
</section>
</section>
<section id="salesforce-amazon-google-y-microsoft">
<h2>Salesforce, Amazon, Google y Microsoft<a class="headerlink" href="#salesforce-amazon-google-y-microsoft" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Otras herramientas de modelización y visualización de datos son las proporcionadas por Salesforce, Google y Microsoft.</p></li>
<li><p>Salesforce adquirió Tableau y google hizo lo mismo con Looker en 2019.</p></li>
<li><p>La reciente integración entre estos productos le permitirán al usuario modelar datos con LookML y usar Tableau, o Looker para explorar ese modelo.</p></li>
</ul>
<ul class="simple">
<li><p>Tableau es una plataforma de análisis de datos que puede ser implementada en la nube, localmente o integrada de forma nativa con Salesforce CRM.</p></li>
<li><p>Contiene capacidades de IA/ML completamente integradas, gobernanza y gestión de datos, narración visual y colaboración.</p>
<ul>
<li><p>Extraído de: <a class="reference external" href="https://www.tableau.com/">https://www.tableau.com/</a>.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Amazon ofrece Amazon QuickSight, una herramienta de inteligencia empresarial unificada a hiperescala.</p>
<ul>
<li><p>Fuente: <a class="reference external" href="https://aws.amazon.com/es/quicksight/">https://aws.amazon.com/es/quicksight/</a>.## Apache Superset</p></li>
</ul>
</li>
<li><p>Apache Superset es una moderna plataforma de exploración de datos y visualización.</p></li>
<li><p>Documentación: <a class="reference external" href="https://superset.apache.org/docs/intro">https://superset.apache.org/docs/intro</a>.</p></li>
<li><p>Sus características principales son:</p></li>
<li><p>Más de 40+ visualizaciones pre-instaladas.</p></li>
<li><p>Soporte para <em>drag-and-drop</em> y consultas SQL.</p></li>
<li><p>Uso de cache para datos que acelera la carga de informes y gráficos.</p></li>
<li><p>Plantillas <em>Jinja</em> para crear <em>dashboards</em> interactivos.</p></li>
<li><p>Plantillas CSS para personalizar gráficos e informes.</p></li>
<li><p>Capa semántica de transformaciones con el lenguaje SQL.</p></li>
<li><p>Filtros avanzados para análisis de datos más profundos.</p></li>
<li><p>Acceso a nuevas funcionalidades mediante <em>feature flags</em>.</p></li>
<li><p>Fuente <a class="reference external" href="https://superset.apache.org/">https://superset.apache.org/</a>.## Apache Superset</p></li>
<li><p>Apache Superset es una moderna plataforma de exploración de datos y visualización.</p></li>
<li><p>Documentación: <a class="reference external" href="https://superset.apache.org/docs/intro">https://superset.apache.org/docs/intro</a>.</p></li>
<li><p>Sus características principales son:</p></li>
<li><p>Más de 40+ visualizaciones pre-instaladas.</p></li>
<li><p>Soporte para <em>drag-and-drop</em> y consultas SQL.</p></li>
<li><p>Uso de cache para datos que acelera la carga de informes y gráficos.</p></li>
<li><p>Plantillas <em>Jinja</em> para crear <em>dashboards</em> interactivos.</p></li>
<li><p>Plantillas CSS para personalizar gráficos e informes.</p></li>
<li><p>Capa semántica de transformaciones con el lenguaje SQL.</p></li>
<li><p>Filtros avanzados para análisis de datos más profundos.</p></li>
<li><p>Acceso a nuevas funcionalidades mediante <em>feature flags</em>.</p></li>
<li><p>Fuente <a class="reference external" href="https://superset.apache.org/">https://superset.apache.org/</a>.## Apache Superset</p></li>
<li><p>Apache Superset es una moderna plataforma de exploración de datos y visualización.</p></li>
<li><p>Documentación: <a class="reference external" href="https://superset.apache.org/docs/intro">https://superset.apache.org/docs/intro</a>.</p></li>
<li><p>Sus características principales son:</p></li>
<li><p>Más de 40+ visualizaciones pre-instaladas.</p></li>
<li><p>Soporte para <em>drag-and-drop</em> y consultas SQL.</p></li>
<li><p>Uso de cache para datos que acelera la carga de informes y gráficos.</p></li>
<li><p>Plantillas <em>Jinja</em> para crear <em>dashboards</em> interactivos.</p></li>
<li><p>Plantillas CSS para personalizar gráficos e informes.</p></li>
<li><p>Capa semántica de transformaciones con el lenguaje SQL.</p></li>
<li><p>Filtros avanzados para análisis de datos más profundos.</p></li>
<li><p>Acceso a nuevas funcionalidades mediante <em>feature flags</em>.</p></li>
<li><p>Fuente <a class="reference external" href="https://superset.apache.org/">https://superset.apache.org/</a>.## Apache Superset</p></li>
<li><p>Apache Superset es una moderna plataforma de exploración de datos y visualización.</p></li>
<li><p>Documentación: <a class="reference external" href="https://superset.apache.org/docs/intro">https://superset.apache.org/docs/intro</a>.</p></li>
<li><p>Sus características principales son:</p></li>
<li><p>Más de 40+ visualizaciones pre-instaladas.</p></li>
<li><p>Soporte para <em>drag-and-drop</em> y consultas SQL.</p></li>
<li><p>Uso de cache para datos que acelera la carga de informes y gráficos.</p></li>
<li><p>Plantillas <em>Jinja</em> para crear <em>dashboards</em> interactivos.</p></li>
<li><p>Plantillas CSS para personalizar gráficos e informes.</p></li>
<li><p>Capa semántica de transformaciones con el lenguaje SQL.</p></li>
<li><p>Filtros avanzados para análisis de datos más profundos.</p></li>
<li><p>Acceso a nuevas funcionalidades mediante <em>feature flags</em>.</p></li>
<li><p>Fuente <a class="reference external" href="https://superset.apache.org/">https://superset.apache.org/</a>.## Apache Superset</p></li>
<li><p>Apache Superset es una moderna plataforma de exploración de datos y visualización.</p></li>
<li><p>Documentación: <a class="reference external" href="https://superset.apache.org/docs/intro">https://superset.apache.org/docs/intro</a>.</p></li>
<li><p>Sus características principales son:</p></li>
<li><p>Más de 40+ visualizaciones pre-instaladas.</p></li>
<li><p>Soporte para <em>drag-and-drop</em> y consultas SQL.</p></li>
<li><p>Uso de cache para datos que acelera la carga de informes y gráficos.</p></li>
<li><p>Plantillas <em>Jinja</em> para crear <em>dashboards</em> interactivos.</p></li>
<li><p>Plantillas CSS para personalizar gráficos e informes.</p></li>
<li><p>Capa semántica de transformaciones con el lenguaje SQL.</p></li>
<li><p>Filtros avanzados para análisis de datos más profundos.</p></li>
<li><p>Acceso a nuevas funcionalidades mediante <em>feature flags</em>.</p></li>
<li><p>Fuente <a class="reference external" href="https://superset.apache.org/">https://superset.apache.org/</a>.## Apache Superset</p></li>
<li><p>Apache Superset es una moderna plataforma de exploración de datos y visualización.</p></li>
<li><p>Documentación: <a class="reference external" href="https://superset.apache.org/docs/intro">https://superset.apache.org/docs/intro</a>.</p></li>
<li><p>Sus características principales son:</p></li>
<li><p>Más de 40+ visualizaciones pre-instaladas.</p></li>
<li><p>Soporte para <em>drag-and-drop</em> y consultas SQL.</p></li>
<li><p>Uso de cache para datos que acelera la carga de informes y gráficos.</p></li>
<li><p>Plantillas <em>Jinja</em> para crear <em>dashboards</em> interactivos.</p></li>
<li><p>Plantillas CSS para personalizar gráficos e informes.</p></li>
<li><p>Capa semántica de transformaciones con el lenguaje SQL.</p></li>
<li><p>Filtros avanzados para análisis de datos más profundos.</p></li>
<li><p>Acceso a nuevas funcionalidades mediante <em>feature flags</em>.</p></li>
<li><p>Fuente <a class="reference external" href="https://superset.apache.org/">https://superset.apache.org/</a>.## Apache Superset</p></li>
<li><p>Apache Superset es una moderna plataforma de exploración de datos y visualización.</p></li>
<li><p>Documentación: <a class="reference external" href="https://superset.apache.org/docs/intro">https://superset.apache.org/docs/intro</a>.</p></li>
<li><p>Sus características principales son:</p></li>
<li><p>Más de 40+ visualizaciones pre-instaladas.</p></li>
<li><p>Soporte para <em>drag-and-drop</em> y consultas SQL.</p></li>
<li><p>Uso de cache para datos que acelera la carga de informes y gráficos.</p></li>
<li><p>Plantillas <em>Jinja</em> para crear <em>dashboards</em> interactivos.</p></li>
<li><p>Plantillas CSS para personalizar gráficos e informes.</p></li>
<li><p>Capa semántica de transformaciones con el lenguaje SQL.</p></li>
<li><p>Filtros avanzados para análisis de datos más profundos.</p></li>
<li><p>Acceso a nuevas funcionalidades mediante <em>feature flags</em>.</p></li>
<li><p>Fuente <a class="reference external" href="https://superset.apache.org/">https://superset.apache.org/</a>.</p></li>
</ul>
<ul class="simple">
<li><p>Google Looker conecta, analiza, y visualiza datos en ambientes multicloud.</p></li>
<li><p>Looker puede facilitar la creación de una plataforma de exploración de datos que facilite el acceso a datos de una manera significativa e intuitiva para la organización.</p></li>
<li><p>Fuente: <a class="reference external" href="https://looker.com/google-cloud">https://looker.com/google-cloud</a>.</p></li>
</ul>
<ul class="simple">
<li><p>Microsoft cuenta por su parte con PowerBI.</p></li>
<li><p>PowerBI se conecta a las fuentes de datos, los modela y presenta en paneles con facilidad.</p></li>
<li><p>Permite obtener respuestas rápidas y con tecnología de IA a preguntas empresariales.</p>
<ul>
<li><p>Fuente: <a class="reference external" href="https://powerbi.microsoft.com/es-es/">https://powerbi.microsoft.com/es-es/</a>.</p></li>
</ul>
</li>
</ul>
</section>
<section id="apache-superset">
<h2>Apache Superset<a class="headerlink" href="#apache-superset" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Apache Superset es una moderna plataforma de exploración de datos y visualización.</p></li>
<li><p>Documentación: <a class="reference external" href="https://superset.apache.org/docs/intro">https://superset.apache.org/docs/intro</a>.</p></li>
</ul>
<ul class="simple">
<li><p>Sus características principales son:</p></li>
</ul>
<ul class="simple">
<li><p>Más de 40+ visualizaciones pre-instaladas.</p></li>
<li><p>Soporte para <em>drag-and-drop</em> y consultas SQL.</p></li>
<li><p>Uso de cache para datos que acelera la carga de informes y gráficos.</p></li>
<li><p>Plantillas <em>Jinja</em> para crear <em>dashboards</em> interactivos.</p></li>
</ul>
<ul class="simple">
<li><p>Plantillas CSS para personalizar gráficos e informes.</p></li>
<li><p>Capa semántica de transformaciones con el lenguaje SQL.</p></li>
<li><p>Filtros avanzados para análisis de datos más profundos.</p></li>
<li><p>Acceso a nuevas funcionalidades mediante <em>feature flags</em>.</p></li>
</ul>
<ul class="simple">
<li><p>Fuente <a class="reference external" href="https://superset.apache.org/">https://superset.apache.org/</a>.</p></li>
</ul>
</section>
<section id="monitoreo-de-datos">
<h2>Monitoreo de datos<a class="headerlink" href="#monitoreo-de-datos" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>El seguimiento continuo de los datos es una parte importante de los mecanismos de gobernanza.</p></li>
<li><p>Apache Flume es útil para procesar datos de registro.</p></li>
<li><p>Apache Storm se utiliza para el monitoreo de operaciones</p></li>
<li><p>Apache Spark sirve para transmisión de datos, procesamiento de gráficos y aprendizaje automático.</p></li>
<li><p>El monitoreo puede ocurrir en el paso de almacenamiento de datos.</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="BigData-es003.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Bases de datos para Big Data</p>
      </div>
    </a>
    <a class="right-next"
       href="BigData-es004MongoDB.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Tutorial MongoDB</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#procesos-en-big-data">Procesos en Big Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#procesamiento-analisis-y-consulta-de-datos">Procesamiento, análisis y consulta de datos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-scoop-attic">Apache Scoop (Attic)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-spark">Apache Spark</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-storm">Apache Storm</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#storm-vs-spark">Storm vs. Spark</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-impala">Apache Impala</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-kudu">Apache Kudu</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-hive">Apache Hive</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-drill">Apache Drill</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#presto">Presto</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#trino">Trino</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-hadoop-yarn">Apache Hadoop YARN</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#alluxio">Alluxio</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#otras-herramientas">Otras herramientas</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#perfilado-de-datos-y-linaje">Perfilado de datos y linaje</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#calidad-de-los-datos">Calidad de los datos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#limpieza-de-datos">Limpieza de datos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prevencion-y-perdida-de-datos">Prevención y pérdida de datos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizacion-de-datos">Visualización de datos</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#elastic-stack">Elastic Stack</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#elasticsearch">Elasticsearch</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-lucene">Apache Lucene</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-solr">Apache Solr</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#logstash">Logstash</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kibana">Kibana</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tutorial-elasticsearch">Tutorial Elasticsearch</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#salesforce-amazon-google-y-microsoft">Salesforce, Amazon, Google y Microsoft</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apache-superset">Apache Superset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#monitoreo-de-datos">Monitoreo de datos</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Fortinux - Marcelo Horacio Fortino
</p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <div>
<a href="https://creativecommons.org/licenses/by-sa/4.0/"><img src="https://licensebuttons.net/l/by-sa/3.0/88x31.png"></a>
    Esta obra está sujeta a la licencia Reconocimiento-CompartirIgual 4.0 Internacional de Creative Commons. Para ver una copia de esta licencia, visite <a href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0 license</a>. Puede hallar permisos más allá de los concedidos con esta licencia en <a href="https://fortinux.com" rel="nofollow">https://fortinux.com</a>. Sugerencias y comentarios a <a href="mailto:info@fortinux.com">info@fortinux.com</a>.
</div>

</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=ac02cc09edc035673794"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>