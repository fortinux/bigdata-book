{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "149cb3a8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Consulta y visualización de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a4ea0b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Procesos en Big Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c851634",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Para el NIST Big Data interoperability Framework (NBDIF) - Version 3.0 Final {cite:ps}`249226` (Pág.29), el ciclo de vida del análisis de los datos se compone de cinco fases:\n",
    "    - Captura de los datos en su formato original. Ingestión de datos (*Data Ingestion*).\n",
    "    - Preparación y modelado. Almacenamiento de datos (*Data Storage*).\n",
    "    - Análisis y consulta de datos (*Data Processing / Data Query*).\n",
    "    - Visualización de los datos. (*Data Visualization*).\n",
    "    - Acción con el uso de los mismos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c21ac2-06e4-4bda-be97-0f93bf864629",
   "metadata": {},
   "source": [
    "- En este apartado se verán las fases de procesamiento, análisis y consulta de datos; y visualización."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c425d9e6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Procesamiento, análisis y consulta de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8122cb08",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Los datos recolectados en la fase anterior serán procesados en este paso.\n",
    "- Aquí, el sistema de procesamiento de canalización de datos enruta los datos a un destino diferente, clasifica el flujo de datos y es el primer punto donde puede tener lugar el análisis.\n",
    "- Esta es la capa donde las consultas (*queries*) y el proceso analítico activo se ejecutan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10130ce6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Para ello, los analistas emplean diferentes herramientas y estrategias como, por ejemplo:\n",
    "    - Modelado estadístico.\n",
    "    - Algoritmos.\n",
    "    - Inteligencia artificial (AI).\n",
    "    - Minería de datos.\n",
    "    - Aprendizaje automático (ML)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925f69e5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Las consultas interactivas para el procesamiento de datos son necesarias y es una zona tradicionalmente dominada por desarrolladores expertos en SQL.\n",
    "- Con Hadoop, la ingesta de datos, el almacenamiento, el proceso y el análisis se volvieron fáciles de trabajar cuando se cuenta con una gran cantidad de datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2742eb8e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Para análisis fuera de línea, se utiliza un sistema de procesamiento por lotes simple. \n",
    "- Apache Sqoop es la aplicación que se encarga de esto.\n",
    "- Transfiere eficientemente datos estructurados entre Apache Hadoop y las bases de datos relacionales.\n",
    "- Spark por otro lado, es utilizado mayoritariamente para el análisis y procesamiento de datos en tiempo real.\n",
    "- Otra herramienta pero menos utilizada es Apache Storm.\n",
    "    - Extraído de: <https://sqoop.apache.org/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357d4205-3cd1-43ed-95b5-aedc1de5e318",
   "metadata": {},
   "source": [
    "- Otras herramientas a considerar útiles en este proceso son:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fb84c1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- KNIME hace que la comprensión de datos y el diseño de flujos de trabajo de ciencia de datos y componentes reutilizables sean accesibles para todos.\n",
    "    - <https://www.knime.com/>.\n",
    "- Apache Mahout es un framework distribuido de álgebra linear y Scala DSL matemáticamente expresivo.  \n",
    "    - <https://mahout.apache.org/>.\n",
    "- Weka 3: Machine Learning Software en Java para hacer análisis simple.\n",
    "    - <https://www.cs.waikato.ac.nz/ml/weka/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded0f15c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Apache Scoop (Attic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9fd94f-b417-4769-a43e-189aaaf7c9b5",
   "metadata": {},
   "source": [
    "*Apache Attic <https://attic.apache.org/> es utilizado por la Apache Software Foundation como espacio para los proyectos que ya han llegado a su final de vida y no cuentan con más desarrollo ni mantenimiento.* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3833c8b6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Transfiere eficientemente datos estructurados entre Apache Hadoop y las bases de datos relacionales.\n",
    "    - Extraído de: <https://sqoop.apache.org/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7299983b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Se puede usar Sqoop para importar datos desde un sistema de administración de bases de datos relacionales (RDBMS) como MySQL u Oracle o un mainframe al sistema de archivos distribuidos de Hadoop (HDFS), transformar los datos en Hadoop MapReduce y luego exportar los datos nuevamente a un RDBMS.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756d067b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Apache Sqoop también puede ser utilizado para extraer datos de Hadoop y exportarlos a almacenes de datos estructurados externos.\n",
    "- Apache Sqoop trabaja con bases de datos relacionales como Teradata, Netezza, Oracle, MySQL, Postgres, y HSQLDB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d3f045",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Sqoop automatiza la mayor parte de este proceso, basándose en la base de datos para describir el esquema de los datos que se importarán.\n",
    "- Sqoop utiliza MapReduce para importar y exportar los datos, lo cual proporciona procesamiento en paralelo y tolerancia a fallos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7324c1a4-3532-45ac-b6b9-6bd0cd0934f6",
   "metadata": {},
   "source": [
    "## Motores de consultas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f883bc4d-3a30-40e8-9a2d-cc71df7f86f1",
   "metadata": {},
   "source": [
    "- Los motores de consultas SQL (*SQL query engine*) permiten realizar consultas a grandes cantidades de datos (*terabytes* o *petabytes*) en distintas fuentes simultáneamente. \n",
    "- Las consultas pueden localizar datos, actualizarlos, agregarlos, etc.\n",
    "- Entre las herramientas más populares de esta categoría se encuentran *Spark, Impala, Hive*, y *Presto/Trino*; entre otras. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9918909",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Apache Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486d0928",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Framework de procesamiento paralelo y de código abierto para ejecutar aplicaciones de análisis de datos a gran escala en sistemas agrupados.\n",
    "- Utilizado por más del 80% de las empresas *Fortune 500* y miles de otras empresas en todo el mundo.  \n",
    "- Fue desarrollado en la *University of California*, Berkeley, EE.UU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e797f1-ce79-4d28-a055-5947b8adba0c",
   "metadata": {},
   "source": [
    "- Extraído de: <https://spark.apache.org/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99350d3b-f78a-41ef-894e-0d0de0f19cc8",
   "metadata": {},
   "source": [
    "- Sus funcionalidades básicas son:\n",
    "    - Procesamiento de datos en *batch/streaming* utilizando Python, SQL, Scala, Java o R.\n",
    "    - Analíticas mediante SQL ejecutando consultas para *dashboards* e informes de forma más rápida que la mayoría de los *data warehouses*.\n",
    "    - Ciencia de datos en escala realizando *Exploratory Data Analysis - EDA* con petabytes de datos.\n",
    "    - *Machine learning* para entrenar algoritmos en un *laptop* usando el mismo código que luego se utilizará en clústeres de miles de máquinas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af111679",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- También es compatible con un amplio conjunto de herramientas de alto nivel, que incluyen:\n",
    "    - Spark SQL para SQL y procesamiento de datos estructurados, \n",
    "    - MLlib para aprendizaje automático, \n",
    "    - GraphX para procesamiento de gráficos, y \n",
    "    - Transmisión estructurada para procesamiento incremental y de streaming."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b034ed",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Se utiliza para realizar trabajos informáticos con grandes cargas de datos junto a Apache Kafka. \n",
    "- Con Spark ejecutándose en Apache Hadoop YARN, los desarrolladores pueden crear aplicaciones para explotar el poder de Spark, obtener información y enriquecer sus cargas de trabajo de ciencia de datos dentro de un único conjunto de datos compartidos en Hadoop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b98ac4b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Apache Impala"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da949bd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Impala eleva el nivel de rendimiento de las consultas SQL en Apache Hadoop al mismo tiempo que conserva una experiencia de usuario familiar.\n",
    "- Con Impala, se puede consultar datos, ya sea que estén almacenados en HDFS o Apache HBase, incluidas las funciones SELECT, JOIN y agregadas, en tiempo real. \n",
    "    - Extraído de: <https://impala.apache.org/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636fada5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Impala utiliza los mismos metadatos, sintaxis SQL (Hive SQL), controlador ODBC e interfaz de usuario (Hue Beeswax) que Apache Hive, lo que proporciona una plataforma familiar y unificada para consultas en tiempo real o por lotes.\n",
    "- Los usuarios de Hive pueden utilizar Impala con algunos pocos ajustes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43451a7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Apache Kudu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1939bfc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Apache Kudu es un motor de almacenamiento columnar open source para datos estructurados.\n",
    "- Está diseñado y optimizado para análisis de big data en datos que cambian rápidamente o para un rendimiento rápido en consultas analíticas - OLAP. \n",
    "- Es distribuido, permite varios tipos de partición de datos y carga compartida en varios servidores. \n",
    "- Es parte del ecosistema Hadoop y se integra con frameworks de procesamiento de datos como Spark, Impala y MapReduce.\n",
    "    - <https://kudu.apache.org/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c3fe16",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Apache Hive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfd3258",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Apache Hive es una infraestructura de almacenamiento de datos (*data warehouse*) construida sobre Apache Hadoop para proporcionar resúmenes de datos, consultas ad-hoc y análisis de grandes conjuntos de datos.\n",
    "- Los analistas de datos usan Hive para consultar, resumir, explorar y analizar esos datos, y luego convertirlos en información empresarial procesable. \n",
    "    - Fuente: <https://hive.apache.org/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e7ac6c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- El software de almacenamiento de datos Apache Hive facilita la lectura, escritura y administración de grandes conjuntos de datos que residen en almacenamiento distribuido mediante SQL.\n",
    "- La estructura se puede proyectar sobre los datos que ya están almacenados.\n",
    "- Se proporciona una herramienta de línea de comandos y un controlador JDBC para conectar a los usuarios a Hive.\n",
    "- Proporciona un mecanismo para la estructura del proyecto de ingesta de datos en los datos de Hadoop y para consultar esos datos mediante con un lenguaje tipo SQL llamado HiveQL (HQL). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ea2610-230b-48fa-9504-8c3895197ffd",
   "metadata": {},
   "source": [
    "- Sus características principales son:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc434f3-a843-4544-b316-63be455795e8",
   "metadata": {},
   "source": [
    "- *Hive-Server 2 - HS2* para multi-client concurrency y autenticación. \n",
    "- Provee un repositorio central de metadatos mediante *Hive Metastore(HMS)* y soporta el almacenamiento en S3, adls, gs, etc. a través de HDFS.\n",
    "- *Hive ACID* provee soporte completo ACID para las tabls ORC e *insert only* para todos los otros formatos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50396854-f75f-485e-ae54-c4b702d83922",
   "metadata": {},
   "source": [
    "- Ofrece soporte de autenticación mediante kerberos y se integra con *Apache Ranger* y *Apache Atlas* para seguridad y *observability*. \n",
    "- Compactación de datos *out-of-the-box* y soporte para tablas de *Apache Iceberg*.\n",
    "- Incluye LLAP (*Low Latency Analytical Processing*), un planificador de consultas y costes utilizando *Apache Calcite* <https://calcite.apache.org/> y replicación: <https://cwiki.apache.org/confluence/display/Hive/Cost-based+optimization+in+Hive>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a6144c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Apache Drill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba36413",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Es un motor SQL para Hadoop, NoSQL y almacenamiento en la nube.\n",
    "- Soporta variadas bases de datos NoSQL y sistemas de ficheros:\n",
    "    - HBase, MongoDB, HDFS, Amazon S3, Azure Blob Storage, Google Cloud Storage, NAS y ficheros locales.\n",
    "- Una única consulta puede obtener datos de múltiples bases de datos.\n",
    "- Integración con *Apache Hive*:\n",
    "    - Consultas en las tablas y vistas, soporte para todos los formatos de ficheros y *User-Defined Functions - UDFs*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e236903-d50b-4142-9971-f233ba456f74",
   "metadata": {},
   "source": [
    "- Fuente: <https://drill.apache.org/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec38a67e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Presto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e670af75",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Motor SQL desarrollado por Meta (Facebook) para análisis ad-hoc e informes rápidos.\n",
    "- Es un motor de consulta SQL distribuido de código abierto que ejecuta consultas analíticas interactivas en fuentes de datos de todos los tamaños, desde gigabytes hasta petabytes.\n",
    "    - Fuente: <https://prestodb.io/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0bb7fe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Meta utiliza Presto para consultas interactivas en varios almacenes de datos internos, incluido su almacén de datos de 300 PB. \n",
    "- Más de 1000 empleados de Meta usan Presto diariamente para ejecutar más de 30000 consultas que, en total, escanean más de un petabyte por día."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a4a0ab-f93a-405a-a5d1-ccaab7d0acd9",
   "metadata": {},
   "source": [
    "- Se puede descargar el libro electrónico *Learning and operating presto* registrándose en <https://prestodb.io/getting-started/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b33f21",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Trino"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fff0e9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Trino es un motor de consulta SQL distribuido diseñado para consultar grandes conjuntos de datos distribuidos en una o más fuentes de datos heterogéneas.\n",
    "- Son los fundadores del proyecto Presto que tuvieron que cambiarle el nombre por cuestiones legales.\n",
    "    - Fuente: <https://trino.io/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55848fda-ffbd-47e6-b5c6-1f4ce3aaff89",
   "metadata": {},
   "source": [
    "- Se puede descargar el libro *Trino: The Definitive Guide, 2nd Edition* (los autores son los creadores de Trino) registrándose en <https://www.starburst.io/info/oreilly-trino-guide/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8243b6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Otras herramientas: Hue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b0a77d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Hue es un asistente open source de SQL para bases de datos y *data warehouses*.\n",
    "- Provee un editor de código SQL con componentes y autocompletado que permite conectarse a cualquier base de datos. \n",
    "    - Fuente: <https://gethue.com/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbc0ab2-1d5e-4d29-ae2c-cc3615a62e96",
   "metadata": {},
   "source": [
    "## Alluxio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d47cd42-6bca-438e-a860-38dd94cb37d6",
   "metadata": {},
   "source": [
    "- Alluxio es una plataforma de orquestación de datos (*data orchestration platform*) que habilita la separación entre las capas de cómputo y almacenamiento.\n",
    "- Brinda velocidad y agilidad a las cargas de datos en Big Data e inteligencia artificial reduciendo costes gracias a la eliminación de datos duplicados.\n",
    "- Permite también trabajar con *object stores*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58e77d9-3f48-41f7-aa88-d26c637d0e8c",
   "metadata": {},
   "source": [
    "- Fuente: <https://www.alluxio.io/data-orchestration/>. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdab130-b079-4677-b796-a20ebdf20045",
   "metadata": {},
   "source": [
    "## Analítica de datos en tiempo real"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e52fe25-9463-48fb-8ec6-43da0f45608c",
   "metadata": {},
   "source": [
    "## Apache Doris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895b96d6-9fdc-4913-83f3-d07925253e0c",
   "metadata": {},
   "source": [
    "- Apache Doris es un moderno *data warehouse open source* para analíticas en tiempo real.\n",
    "- Puede ser utilizado para realizar informes de análisis, consultas *ad-hoc*, unificar almacenes de datos o acelerar consultas a lagos de datos. \n",
    "- Permite construir aplicaciones para análisis del comportamiento del usuario, *A/B testing, log analysis*, análisis de perfiles de usuario, o de pedidos de ventas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5847ec9d-4c7d-42e6-b215-8dfae6d45236",
   "metadata": {},
   "source": [
    "- Fuente: <https://doris.apache.org/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e57428-0e7b-4be1-861d-266cb811e17e",
   "metadata": {},
   "source": [
    "## Apache Druid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682c056b-7c05-495b-b926-b212a96043eb",
   "metadata": {},
   "source": [
    "- Apache Druid es una base de datos diseñada para análisis en tiempo real (consultas OLAP) en grandes conjuntos de datos.\n",
    "- Se especializa en casos de uso donde la ingesta de datos en tiempo real, un desempeño veloz en las consultas y una disponibulidad alta son importantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc596e11-79c3-40b8-9685-8f700d33f060",
   "metadata": {},
   "source": [
    "- Fuente: <https://druid.apache.org/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f884537e-4f00-4b8e-a707-1fe1b9162d0b",
   "metadata": {},
   "source": [
    "## Apache Kylin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7890dbf5-7d7f-4c70-982c-215570fc79bf",
   "metadata": {},
   "source": [
    "- Apache Kylin es un almacén de datos analíticos distribuido de código abierto para Big Data.\n",
    "- Diseñado para proporcionar capacidad OLAP (procesamiento analítico en línea) para Big Data.\n",
    "- Al renovar el cubo multidimensional y la tecnología de precálculo en Hadoop y Spark, Kylin puede lograr una velocidad de consulta casi constante independientemente del volumen de datos en constante crecimiento. \n",
    "- Al reducir la latencia de las consultas de minutos a menos de un segundo, Kylin devuelve la analítica en línea a los grandes datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a765f61-2199-41db-b52b-8f158d266901",
   "metadata": {},
   "source": [
    "- Fuente: <https://kylin.apache.org/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51aa990-04ce-4ad2-9c85-36e2da997a9d",
   "metadata": {},
   "source": [
    "## Apache Pinot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de260ea1-e08a-4224-928d-2767f0bce583",
   "metadata": {},
   "source": [
    "- Apache Pinot es una plataforma de código abierto de analítica en tiempo real ideal para obtener información ultrarrápida, escalabilidad sin esfuerzo y decisiones rentables basadas en datos.\n",
    "- Fuente: <https://pinot.apache.org/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b12906-f961-4382-bdf7-4228ecf91516",
   "metadata": {},
   "source": [
    "## Vertica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a812a59",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Vertica es un almacén de datos (*data warehouse*) de análisis unificado.\n",
    "- Ha sido diseñado para ofrecer velocidad, escalabilidad y aprendizaje automático integrado para cargas de trabajo analíticamente intensivas.\n",
    "    - Extraído de <https://www.vertica.com/landing-page/start-your-free-trial-today/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34f5646",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Perfilado de datos y linaje"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739dddfa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Perfilado de datos y linaje (*data profiling and lineage*) son técnicas que permiten identificar la calidad de los datos y su ciclo de vida durante las varias fases que percorren. \n",
    "- Es importante capturar los metadatos en cada paso del proceso para que puedan ser utilizados posteriormente para verificación y personalización.\n",
    "- Algunas aplicacione disponibles: *Talend, Hive, Pig*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7b1d1f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- *Talend Data Fabric* es un conjunto de aplicaciones nativas de la nube que lidera la industria en integración y gestión de datos:\n",
    "    - Identifica elementos de datos.\n",
    "    - Realiza un seguimiento hasta el origen de los datos.\n",
    "    - Combina fuentes de datos y enlaces a los mismos.\n",
    "    - Crea un mapa para cada sistema y un mapa maestro de la imagen completa. \n",
    "    - Extraído de: <https://www.talend.com/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68e3b39",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- *OpenLineage* es un framework open source para la recopilación y el análisis del linaje de datos.\n",
    "- Permite una recopilación consistente de metadatos de linaje, creando una comprensión más profunda de cómo se producen y utilizan los datos. \n",
    "- se integra con *Airflow, Spark* y *dbt*.\n",
    "    - Extraído de: <https://openlineage.io/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeea3bd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Calidad de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e479d622",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- La ingesta de datos se considera de alta calidad si cumple con las necesidades comerciales y satisface el uso previsto, de modo que sea útil para tomar decisiones de negocio con éxito.\n",
    "- Por lo tanto, es un paso importante entender la dimensión de mayor interés e implementar métodos para lograrla.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9501b88",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Limpieza de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66dd791",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- La limpieza de datos (*data cleansing*) significa implementar varias soluciones para corregir datos incorrectos o corruptos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb98ca29",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Prevención y pérdida de datos "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d9f5dc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Deben existir políticas para asegurarse de que se resuelvan las lagunas en la pérdida de datos.\n",
    "- La identificación de dicha pérdida de datos necesita un control cuidadoso y procesos de evaluación de la calidad en el flujo del proceso de ingesta de datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42df12c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Visualización de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497ce4da",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- La fase de visualización o presentación es donde los usuarios pueden sentir el VALOR de los DATOS. \n",
    "- La visualización de hallazgos ayuda a tomar mejores decisiones de negocios.\n",
    "- Aquí se generan informes por tipo de audiencia (comerciales, marketing, estrategia, técnicos, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14ff58f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Si bien está diseñado para manejar y almacenar grandes volúmenes de datos, Hadoop y otras herramientas no tienen disposiciones integradas para la visualización de datos y la distribución de información, lo que no permite que los usuarios finales del negocio puedan consumir fácilmente esos datos en la canalización de ingesta de datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46f38a1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Los paneles personalizados son útiles para crear vistas generales únicas que presentan los datos de manera diferente.\n",
    "- Puede mostrar la información de la aplicación web y móvil, la información del servidor, los datos de métricas personalizadas y los datos de métricas de complementos, todo en un único tablero personalizado.\n",
    "- Los paneles en tiempo real guardan, comparten y comunican información.\n",
    "- Ayuda a los usuarios a generar preguntas al revelar la profundidad, el rango y el contenido de los almacenes de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2f392b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Los paneles de visualización de datos siempre cambian a medida que llegan nuevos datos.\n",
    "- Los tableros pueden contener múltiples visualizaciones de múltiples conexiones una al lado de la otra.\n",
    "- Se pueden crear, editar, filtrar y eliminar tableros rápidamente y moverlos y cambiar su tamaño y luego compartirlos o integrarlos en su aplicación web.\n",
    "- Se puede exportar un tablero como una imagen o utilizando una configuración de archivo tipo JSON. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7b9fc0-39ea-42ef-bd24-242f95915f32",
   "metadata": {},
   "source": [
    "- De acuerdo con el NIST Big Data interoperability Framework (NBDIF) - Version 3.0 Final {cite:ps}`249226` (Pág.31) tres son los tipos de visualizaciones que varían en técnicas y en propósito:\n",
    "    - Visualización exploratoria: técnicas para entender la distribución de los valores en los elementos. Se pueden necesitar también técnicas de agregación o de resumen.\n",
    "    - Visualización evaluatoria: permite comprender el desempeño y exactitud de un método particular de análisis o *machine learning*.\n",
    "        - Los datos pequeños (*small data*) se refieren a los límites en el tamaño de los conjuntos de datos que los analistas pueden evaluar y comprender por completo.\n",
    "    - Visualización exploratoria: la presentación de datos complejos de manera fácil para ser entendidos por quienes toman decisiones. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ebcc83-d0b1-40c3-83a0-cc7885b41af3",
   "metadata": {},
   "source": [
    "## Elastic Stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8088f8-b372-4c41-a464-710ef46e9c6a",
   "metadata": {},
   "source": [
    "- En sus inicios el ELK Stack se componía de las aplicaciones Elasticsearch, Logstash, Kibana, y Beats.\n",
    "- Actualmente se lo conoce como Elastic Stack, nombre que le permite agregar nuevas funcionalidades.\n",
    "- Conocido por sus API REST simples, naturaleza distribuida, velocidad y escalabilidad, Elasticsearch es el componente central de Elastic Stack, un conjunto de herramientas de código abierto para la ingesta, el enriquecimiento, el almacenamiento, el análisis y la visualización de datos.\n",
    "- Kibana es la interfaz de usuario gratuita y abierta que permite visualizar los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade2a4a5-6f6b-496c-9b0c-8331f6dfd735",
   "metadata": {},
   "source": [
    "- Extraído de: <https://www.elastic.co/what-is/elasticsearch>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad57952-1791-49df-843f-fb3885d05a06",
   "metadata": {},
   "source": [
    "- Casos de uso:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534b349d-8da6-4866-9bec-2f4b830ce9b9",
   "metadata": {},
   "source": [
    "- Búsqueda de aplicaciones.\n",
    "- Búsqueda de sitio web.\n",
    "- Búsqueda Empresarial.\n",
    "- Logging y analíticas de log."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1445a5e-a3a1-4af9-9bed-4cd92b100450",
   "metadata": {},
   "source": [
    "- Métricas de infraestructura y monitoreo de contenedores.\n",
    "- Monitoreo de rendimiento de aplicaciones.\n",
    "- Análisis y visualización de datos geoespaciales.\n",
    "- Analítica de Seguridad.\n",
    "- Analítica de Negocios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e0b82a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7d7c49",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Elasticsearch es un motor de análisis y búsqueda de código abierto distribuido para todo tipo de datos, incluidos textuales, numéricos, geoespaciales, estructurados y no estructurados.\n",
    "- Elasticsearch se basa en Apache Lucene y fue lanzado por primera vez en 2010 por Elasticsearch N.V. (ahora conocido como Elastic). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0648d44-3aae-4b4a-983f-840004cdb324",
   "metadata": {},
   "source": [
    "- La ingesta de datos es el proceso mediante el cual estos datos sin procesar se analizan, normalizan y enriquecen antes de indexarlos en Elasticsearch.\n",
    "- Los datos sin procesar fluyen hacia Elasticsearch desde una variedad de fuentes, incluidos registros, métricas del sistema y aplicaciones web."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a13c4be-735b-4ec5-b081-71509e949a6c",
   "metadata": {},
   "source": [
    "- Extraído de: <https://www.elastic.co/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0f374b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Apache Lucene"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ce9352",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Lucene Core es una biblioteca de Java que proporciona potentes funciones de indexación y búsqueda, así como funciones de corrección ortográfica, resaltado de aciertos y análisis/tokenización avanzados.\n",
    "- El subproyecto PyLucene proporciona enlaces de Python para Lucene Core. \n",
    "    - Extraído de: <https://lucene.apache.org/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e11ca56-ca5c-41dc-963b-f7e4bfc84528",
   "metadata": {},
   "source": [
    "- PyLucene incorpora una VM de Java con Lucene en un proceso de Python.\n",
    "- El módulo de Python llamado *lucene* es generado por máquina por JCC.\n",
    "    - Extraído de: <https://lucene.apache.org/pylucene/>.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b56815-d041-45cb-a806-9b63a35770e5",
   "metadata": {},
   "source": [
    "- Lucene Core tiene una serie de proyectos relacionados, entre los cuales se encuentran:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38596482-8fb8-4367-9b52-77a3d33bab8a",
   "metadata": {},
   "source": [
    "- Manifold: Framework de código abierto para conectar repositorios de contenido de origen, como Microsoft Sharepoint y EMC Documentum, a repositorios o índices de destino, como Apache Solr, Open Search Server o ElasticSearch.\n",
    "    - <https://manifoldcf.apache.org/en_US/index.html>. \n",
    "- LUCENE.net: biblioteca de motor de búsqueda de alto rendimiento para .NET.\n",
    "    - <https://lucenenet.apache.org/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3dc828-b6e8-47f3-aea6-f54d69dfcf26",
   "metadata": {},
   "source": [
    "- Apache Tika: El kit de herramientas Apache Tika detecta y extrae metadatos y texto de más de mil tipos de archivos diferentes (como PPT, XLS y PDF). Todos estos tipos de archivos se pueden analizar a través de una sola interfaz, lo que hace que Tika sea útil para la indexación de motores de búsqueda, el análisis de contenido, la traducción y mucho más.\n",
    "    - <https://tika.apache.org/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6095c06-f2d9-4d8c-a2ca-731580fed515",
   "metadata": {},
   "source": [
    "- Nutch es un rastreador web altamente extensible, altamente escalable, maduro y listo para producción que permite una configuración detallada y se adapta a una amplia variedad de tareas de adquisición de datos.\n",
    "    - <https://nutch.apache.org/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b306ec-2b56-4eef-8eb6-8b4b1f6973e4",
   "metadata": {},
   "source": [
    "- La biblioteca Apache OpenNLP es un conjunto de herramientas basado en el aprendizaje automático para el procesamiento de texto en lenguaje natural.\n",
    "- Admite las tareas más comunes de NLP, como la tokenización, la segmentación de oraciones, el etiquetado de partes del discurso, la extracción de entidades nombradas, la fragmentación, el análisis y la resolución de correferencias.\n",
    "    - Extraído de: <https://opennlp.apache.org/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a4f01e-3bce-4c02-a543-71a94002f2a9",
   "metadata": {},
   "source": [
    "- Apache Mahout es un framework distribuido de álgebra linear y Scala DSL que tiene como objetivo crear aplicaciones de aprendizaje automático (ML) escalables y eficaces. \n",
    "    - <https://mahout.apache.org/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a8da04",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Apache Solr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6500dc17",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Solr es un servidor de búsqueda de alto rendimiento creado con Lucene Core.\n",
    "- Solr es altamente escalable y proporciona indexación, búsqueda y análisis distribuidos totalmente tolerantes a fallas.\n",
    "- Expone las características de Lucene a través de interfaces JSON/HTTP fáciles de usar o clientes nativos para Java y otros lenguajes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85366e51-6ecd-41ce-8f24-f9908ca9a1b0",
   "metadata": {},
   "source": [
    "- Extraído de: <https://solr.apache.org/>.\n",
    "- Imagen Docker Sorl: <https://hub.docker.com/_/solr>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02961dd6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Logstash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a131ff95",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Logstash se usa para agregar y procesar datos y enviarlos a Elasticsearch.\n",
    "- Es una canalización (*pipeline*) de procesamiento de datos del lado del servidor de código abierto que le permite ingerir datos de múltiples fuentes simultáneamente y enriquecerlos y transformarlos antes de que se indexen en Elasticsearch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9542228d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Un índice de Elasticsearch es una colección de documentos que están relacionados entre sí.\n",
    "- Elasticsearch almacena datos como documentos JSON.\n",
    "- Cada documento correlaciona un conjunto de claves (nombres de campos o propiedades) con sus valores correspondientes (cadenas, números, booleanos, fechas, matrices de valores, geolocalizaciones u otros tipos de datos)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6434ad18-1894-4557-9546-a5873d7f76f0",
   "metadata": {},
   "source": [
    "- Elasticsearch utiliza una estructura de datos denominada índice invertido, que está diseñada para permitir búsquedas de texto completo muy rápidas.\n",
    "- Un índice invertido enumera cada palabra única que aparece en cualquier documento e identifica todos los documentos en los que aparece cada palabra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c8e6bb-de3e-4172-80e4-27eb3e5a3d95",
   "metadata": {},
   "source": [
    "- La indexación se inicia con la API de índice, a través de la cual puede agregar o actualizar un documento JSON en un índice específico.\n",
    "- Durante el proceso de indexación, Elasticsearch almacena documentos y crea un índice invertido para que los datos del documento se puedan buscar casi en tiempo real."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ddacb7-3a53-4c8b-8fe7-c1d560b640c7",
   "metadata": {},
   "source": [
    "- Una vez indexados en Elasticsearch, los usuarios pueden ejecutar consultas complejas en sus datos y usar agregaciones para recuperar resúmenes complejos de sus datos.\n",
    "- Desde Kibana, los usuarios pueden crear potentes visualizaciones de sus datos, compartir paneles y administrar el Elastic Stack."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682d341e-581e-4784-9dcf-e4211f8394ac",
   "metadata": {},
   "source": [
    "- Fuente: <https://www.elastic.co/logstash>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaef331",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Kibana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a909590f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Kibana es una herramienta de visualización y gestión de datos para Elasticsearch que brinda histogramas en tiempo real, gráficos circulares y mapas. \n",
    "- Kibana también incluye aplicaciones avanzadas, como Canvas, que permite a los usuarios crear infografías dinámicas personalizadas con base en sus datos, y Elastic Maps para visualizar los datos geoespaciales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbad06a6-bcbd-4adc-8184-a841560628ba",
   "metadata": {},
   "source": [
    "- Elasticsearch soporta una variedad de lenguajes de programación facilitando clientes para:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e454886f-e6b8-4947-9890-0c1ccc145fcd",
   "metadata": {},
   "source": [
    "- Java.\n",
    "- JavaScript (Node.js).\n",
    "- Go.\n",
    "- .NET (C#).\n",
    "- PHP.\n",
    "- Perl.\n",
    "- Python.\n",
    "- Ruby."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f784be6a-f867-4143-9be3-d5be86b218b5",
   "metadata": {},
   "source": [
    "- Cuenta además con herramientas para la línea de comandos:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d444e0-3a1c-4e51-a555-27e8322ab84f",
   "metadata": {},
   "source": [
    "elasticsearch-certgen\n",
    "elasticsearch-certutil\n",
    "elasticsearch-croneval\n",
    "elasticsearch-keystore\n",
    "elasticsearch-migrate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2c1d42-2120-4285-bbea-6e2d018802eb",
   "metadata": {},
   "source": [
    "elasticsearch-node\n",
    "elasticsearch-saml-metadata\n",
    "elasticsearch-setup-passwords\n",
    "elasticsearch-shard\n",
    "elasticsearch-syskeygen\n",
    "elasticsearch-users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b907240e-3df6-49d7-8ca8-a6a1b5a2914f",
   "metadata": {},
   "source": [
    "- Fuente: <https://www.elastic.co/guide/en/elasticsearch/reference/current/commands.html>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8641c67-1ccd-4d44-b49b-5d7922c8b645",
   "metadata": {},
   "source": [
    "- Un documento en Kibana puede contener varios campos con valores: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c09359-6d7a-4d96-8b96-e1e788eb5dff",
   "metadata": {},
   "source": [
    "{\n",
    "  \"name\" : \"Elastic\",\n",
    "  ...\n",
    "  <field> : <value>\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447493db-283d-448d-876f-59653608caeb",
   "metadata": {},
   "source": [
    "- Fuente: (assets.contentstack.io) [<https://assets.contentstack.io/v3/assets/bltefdd0b53724fa2ce/blt56ad3f4e2c755f29/5d37c1602a506857d64eff48/es_commands.txt>]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311b5319-3b97-4924-9276-67da5f53f5f8",
   "metadata": {},
   "source": [
    "### Tutorial Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da841b27-73fe-43d0-9c8e-904006b06aab",
   "metadata": {},
   "source": [
    "- Descargar e instalar la máquina virtual de elasticsearch en Bitnami.\n",
    "- <https://bitnami.com/stack/elasticsearch/virtual-machine>. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d45d556",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Salesforce, Amazon, Google y Microsoft  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafd69b1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Otras herramientas de modelización y visualización de datos son las proporcionadas por Salesforce, Amazon, Google y Microsoft.\n",
    "- Salesforce adquirió Tableau y google hizo lo mismo con Looker en 2019.\n",
    "- La reciente integración entre estos productos le permitirán al usuario modelar datos con LookML y usar Tableau, o Looker para explorar ese modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a93d1f1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Tableau es una plataforma de análisis de datos que puede ser implementada en la nube, localmente o integrada de forma nativa con Salesforce CRM. \n",
    "- Contiene capacidades de IA/ML completamente integradas, gobernanza y gestión de datos, narración visual y colaboración.\n",
    "    - Extraído de: <https://www.tableau.com/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734cb26a-aa60-45c4-8334-26ad1423e810",
   "metadata": {},
   "source": [
    "- Amazon ofrece Amazon QuickSight, una herramienta de inteligencia empresarial unificada a hiperescala.\n",
    "    - Fuente: <https://aws.amazon.com/es/quicksight/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8b7557-cda4-4509-9c29-334ea524e5ce",
   "metadata": {},
   "source": [
    "- Google Looker conecta, analiza, y visualiza datos en ambientes multicloud. \n",
    "- Looker puede facilitar la creación de una plataforma de exploración de datos que facilite el acceso a datos de una manera significativa e intuitiva para la organización.\n",
    "    - Fuente: <https://looker.com/google-cloud>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfeb6df",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Microsoft cuenta por su parte con PowerBI.\n",
    "- PowerBI se conecta a las fuentes de datos, los modela y presenta en paneles con facilidad.\n",
    "- Permite obtener respuestas rápidas y con tecnología de IA a preguntas empresariales.\n",
    "    - Fuente: <https://powerbi.microsoft.com/es-es/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb46537-5777-4b90-9dca-6f6914a9d10f",
   "metadata": {},
   "source": [
    "## Apache Superset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6600b20-4e09-46fe-91bc-0512201c39e3",
   "metadata": {},
   "source": [
    "\n",
    "- Apache Superset es una moderna plataforma de exploración de datos y visualización.\n",
    "- Documentación: <https://superset.apache.org/docs/intro>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a288c0d5-a9ec-4dfb-aa77-d9b6b4c0a110",
   "metadata": {},
   "source": [
    "- Sus características principales son:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8509d146-8d00-484a-96a7-ec6e05cf0c6d",
   "metadata": {},
   "source": [
    "- Más de 40+ visualizaciones pre-instaladas.\n",
    "- Soporte para *drag-and-drop* y consultas SQL.\n",
    "- Uso de cache para datos que acelera la carga de informes y gráficos.\n",
    "- Plantillas *Jinja* para crear *dashboards* interactivos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad47996-5404-4f33-a94b-1eeaee031ba6",
   "metadata": {},
   "source": [
    "- Plantillas CSS para personalizar gráficos e informes.\n",
    "- Capa semántica de transformaciones con el lenguaje SQL.\n",
    "- Filtros avanzados para análisis de datos más profundos.\n",
    "- Acceso a nuevas funcionalidades mediante *feature flags*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd3da44-d3b7-436b-8d5c-d4b46455c034",
   "metadata": {},
   "source": [
    "- Fuente <https://superset.apache.org/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf445b3b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Monitoreo de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758a75a9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- El seguimiento continuo de los datos es una parte importante de los mecanismos de gobernanza.\n",
    "- Apache Flume es útil para procesar datos de registro.\n",
    "- Apache Storm se utiliza para el monitoreo de operaciones\n",
    "- Apache Spark sirve para transmisión de datos, procesamiento de gráficos y aprendizaje automático."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}