{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "149cb3a8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Big Data stacks y Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9469beb0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Big data stacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962eaba0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Teniendo en cuenta las numerosas opciones que existen en el mercado para implantar una solución de Big data en la organización, se enumeran a continuación tres arquitecturas que contemplan los procesos de ingestión de datos, almacenamiento, tratamiento y análisis de datos, y presentación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beff4559",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Apache Hadoop Stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56975425",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- La biblioteca de software Apache Hadoop es un framework para el procesamiento distribuido de grandes conjuntos de datos en grupos de computadoras.\n",
    "    - Fuente: <https://hadoop.apache.org/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ddf4e2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Ingestión de datos: Apache Flume, Apache Nifi. \n",
    "    - Mensajería: Apache Kafka.\n",
    "- Almacenamiento: \n",
    "    - Gestión de recursos: Apache Hadoop YARN.\n",
    "    - Sistema de ficheros: HDFS.\n",
    "    - Datalakes/Datawarehouses: Apache Hudi, Apache Iceberg, Apache XTable.\n",
    "    - Bases de datos: Apache Cassandra, Apache HBase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544728bc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Análisis y tratamiento de los datos: Apache Hadoop MapReduce, Apache Spark, Apache Flink.\n",
    "    - SQL: Apache Hive, Apache Pig.\n",
    "    - ML: Apache Mahout, Apache Spark MLLib.\n",
    "    - Orquestación: Apache Zookeeper, Apache Airflow.\n",
    "- Presentación: Apache Superset, Kibana.\n",
    "- Gestión: \n",
    "    - Seguridad: Apache Zookeeper.\n",
    "    - Gobernanza: Apache Atlas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e1562d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## BDAS - Berkeley Data Analytics Stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16a34a3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- BDAS (*Berkeley Data Analytics Stack*) es un stack de software open source que integra componentes creados por el AMPLab para Big Data, entre ellos, el framework *Apache Spark*.\n",
    "    - Fuente: <https://amplab.cs.berkeley.edu/software/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a611f0b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Ingestión de datos: Apache Flume, Apache Nifi. \n",
    "    - Mensajería: Apache Kafka.\n",
    "- Almacenamiento: \n",
    "    - Gestión de recursos: Apache Mesos, Apache Hadoop YARN.\n",
    "    - Sistema de ficheros: HDFS.\n",
    "    - Almacenamiento: Alluxio, S3, Ceph.\n",
    "    - Bases de datos: Apache Cassandra, Apache HBase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfd5e26",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Análisis y tratamiento de los datos: Apache Spark.\n",
    "    - ML: Apache Spark MLLib.\n",
    "    - Orquestación: Apache Zookeeper, Apache Airflow.\n",
    "- Presentación: Google Looker, Microsoft Power BI, Tableau.\n",
    "- Gestión: \n",
    "    - Seguridad: Apache Zookeeeper.\n",
    "    - Gobernanza: Apache Atlas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9105ad09",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Big data stack alternativo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ced06a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Este es un ejemplo de un stack basado en un artículo de la empresa *dbt*.\n",
    "    - <https://blog.getdbt.com/future-of-the-modern-data-stack/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7dd40d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Ingestión de datos: Fivetran, Stitch. \n",
    "- Almacenamiento: \n",
    "    - Gestión de recursos: Kubernetes.\n",
    "    - Sistema de ficheros: Compatible con Hadoop: Ceph, Minio.\n",
    "    - Datalakes/Datawarehouses: Snowflake, Databricks, Bigquery, Redshift.\n",
    "- Análisis y tratamiento de los datos: dbt.\n",
    "- Presentación: Looker, Mode, Periscope."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02d8192-ab0b-483b-bbd5-450fde6e2976",
   "metadata": {},
   "source": [
    "## Cloudera"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d7f3ab-37e8-4cca-be19-672e8f903f0b",
   "metadata": {},
   "source": [
    "- Cloudera es una empresa de software que provee una plataforma de Big Data para análisis de datos, ML e inteligencia artificial.\n",
    "- La plataforma CDP (*Cloudera Data Platform*) está basada en Apache Hadoop e integra las aplicaciones más populares de ese ecosistema en una única solución que se puede instalar *on premises* o en la nube (Amazon, Azure, Google Cloud). \n",
    "- Los fundadores de Cloudera fueron de los primeros desarrolladores de Hadoop que ofrecieron una solución comercial basada en este software."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b41c0a-3595-4643-87d4-ffce84fffbb5",
   "metadata": {},
   "source": [
    "- Sitio web: <https://www.cloudera.com/>.\n",
    "- Tutoriales y documentación: <https://www.cloudera.com/services-and-support/tutorials.html>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead0bc7a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Big data cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e267e2e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- En esta comparación de productos para big data y análisis se presentan las soluciones que ofrecen los tres grandes actores del mundo de servicios *cloud computing*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a1c029",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Ingestión de datos: Amazon Kinesis/Glue, Azure Synapse Analytics, Google Dataflow.\n",
    "- Almacenamiento: \n",
    "    - AWS Simple Storage Service (S3), Azure Blob Storage, Google Cloud Storage.\n",
    "- Datalakes/Datawarehouses: \n",
    "    - Amazon Redshift, Azure SQL Data Warehouse (SQL DW), Google BigQuery.\n",
    "- Bases de datos: \n",
    "    - Amazon Relational Database Service, Azure SQL Database, Google Cloud SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d8771f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Análisis y tratamiento de los datos: \n",
    "    - Amazon Kinesis, Azure Synapse Analytics, Google Cloud Smart Analytics Platform.\n",
    "    - ML: Amazon SageMaker, Azure Machine Learning, Google Cloud Machine Learning Engine.\n",
    "- Presentación: \n",
    "    - Amazon OpenSearch, Microsoft Power BI, Google Looker."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d65408",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Amazon EMR es un servicio gestionado que permite procesar y analizar datos utilizando herramientas y frameworks como Apache Hadoop, Spark, HBase, y Presto.\n",
    "    - <https://aws.amazon.com/es/emr/>\n",
    "- Azure HDInsight es una solución completa de Apache Hadoop, Spark, R Server, HBase y Storm en la nube.\n",
    "    - <https://azure.microsoft.com/es-es/services/hdinsight/>\n",
    "- Google Dataproc es un servicio totalmente gestionado y escalable que permite ejecutar Apache Spark, Apache Flink, y más de 30 herramientas y frameworks de código abierto. \n",
    "    - <https://cloud.google.com/dataproc>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8666e8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Enlaces:\n",
    "    - <https://aws.amazon.com/es/big-data/datalakes-and-analytics/>.\n",
    "    - <https://aws.amazon.com/es/architecture/analytics-big-data/>\n",
    "    - <https://azure.microsoft.com/es-es/services/>.\n",
    "    - <https://cloud.google.com/solutions/smart-analytics>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d267bd4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Arquitectura Big data en Amazon\n",
    "    - Modern Data Analytics Reference Architecture on AWS.\n",
    "    - <https://d1.awsstatic.com/architecture-diagrams/ArchitectureDiagrams/modern-data-analytics-using-lake-house-ra.pdf>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baed3630",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Ejemplo Azure\n",
    "    - Análisis de un extremo a otro con Azure Synapse.\n",
    "    - <https://docs.microsoft.com/es-es/azure/architecture/example-scenario/dataplate2e/data-platform-end-to-end>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec7eb3c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Ejemplo Google\n",
    "    - How Renault solved scaling and cost challenges on its Industrial Data platform using BigQuery and Dataflow.\n",
    "    - <https://cloud.google.com/blog/topics/manufacturing/renault-improves-its-industrial-data-platform-with-bigquery>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a340894-113c-49eb-a46f-3227f7c9e208",
   "metadata": {},
   "source": [
    "## Infraestructura de prueba de Big Data (BDTI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33475785-ab70-42ea-b6a7-11b70a86a11c",
   "metadata": {},
   "source": [
    "- La Infraestructura de prueba de Big Data (BDTI) es un *stack* analítico realizado con software libre y de fuente abierta gratuito listo para usar que se ofrece a todas las administraciones públicas europeas para experimentar con herramientas de código abierto y fomentar la reutilización de datos del sector público.\n",
    "- Ofrece además un curso también gratuito y recursos para poder aprender a implementar soluciones de Big Data en todas las administraciones europeas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b721ab1-c7b9-4bfb-80cb-dd03de48d4d7",
   "metadata": {},
   "source": [
    "- La oferta de servicios de BDTI está organizada en las siguientes categorías:\n",
    "    - Bases de datos (PostgreSQL, MongoDB, Virtuoso).\n",
    "    - Lago de datos (MinIO).\n",
    "    - Entornos de desarrollo (JupyterLab, Rstudio, KNIME, H20).\n",
    "    - Procesamiento avanzado (Apache Spark, Elasticsearch, Kibana).\n",
    "    - Visualización (Apache Superset, Metabase).\n",
    "    - Orquestación (Apache Airflow, MageAI)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea95b0f6-74cc-4185-8a19-5059a9a54551",
   "metadata": {},
   "source": [
    "- Fuente: <https://big-data-test-infrastructure.ec.europa.eu/index_en>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a4ea0b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af722f4-15bc-41d2-89cf-a8af82d0986f",
   "metadata": {},
   "source": [
    "- Si bien se viene estudiando la forma de hacer que las máquinas puedan aprender por si solas desde 1970 aproximadamente, no fue hasta 1983 cuando se publicó *Machine learning: The AI Apprioach*, que la disciplina de *Machine learning* tomó el impulso luego sistematizado en el libro de T. Mitchell *Machine Learning* (1997).     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac6f90e-0150-4d67-b7d9-22135a36ce47",
   "metadata": {},
   "source": [
    "Fuente: {cite:ps}`Kubat2017`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd363f91-fccc-4cd4-9726-74c66e44a64d",
   "metadata": {},
   "source": [
    "## TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e004b44e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- El aprendizaje automático es la práctica de ayudar al software a realizar una tarea sin programación o reglas explícitas.\n",
    "- En la programación tradicional de computadoras, un programador especifica las reglas que debe usar la computadora.\n",
    "    - Extraído de TensorFlow: <https://www.tensorflow.org/about>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc4533c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Sin embargo, ML requiere una mentalidad diferente.\n",
    "- El aprendizaje automático del mundo real se centra mucho más en el análisis de datos que en la codificación.\n",
    "- Los programadores proporcionan un conjunto de ejemplos y la computadora aprende patrones a partir de los datos.\n",
    "- Se puede entender el aprendizaje automático como \"programación con datos\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63551504",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pasos en ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184a44e1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Paso 1: recopilar datos.\n",
    "- Paso 2: Explorar los datos.\n",
    "- Paso 2.5: Eligir un modelo.\n",
    "- Paso 3: Preparar los datos.\n",
    "- Paso 4: construir, entrenar y evaluar el modelo.\n",
    "- Paso 5: Sintonizar los hiperparámetros.\n",
    "- Paso 6: Implementar el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9ded75",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Extraído de Maching Learning:    \n",
    "- <https://developers.google.com/machine-learning/guides/text-classification/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c401dcb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b462395",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Es un tipo de modelo que se puede entrenar para reconocer patrones.\n",
    "- Está compuesto por capas, incluidas las de entrada y salida, y al menos una capa oculta.\n",
    "- Las neuronas de cada capa aprenden representaciones cada vez más abstractas de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28882d75",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Extraído de TensorFlow: <https://www.tensorflow.org/about>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df0ad38",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Entrenar una red neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd7a361",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Las redes neuronales se entrenan por descenso de gradiente.\n",
    "- Los pesos en cada capa comienzan con valores aleatorios, y estos se mejoran iterativamente con el tiempo para hacer que la red sea más precisa.\n",
    "- Se usa una función de pérdida para cuantificar qué tan imprecisa es la red, y se usa un procedimiento llamado retropropagación para determinar si se debe aumentar o disminuir cada peso para reducir la pérdida."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f2870e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Apache MLlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0833657f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- MLlib es la biblioteca escalable de aprendizaje automático (ML) de Apache Spark.\n",
    "- Su objetivo es hacer que el aprendizaje automático práctico sea escalable y fácil.\n",
    "    - Fuente: <https://spark.apache.org/mllib/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9583402",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Las utilidades de flujo de trabajo de ML incluyen:\n",
    "     - Algoritmos de ML: algoritmos de aprendizaje comunes como clasificación, regresión, agrupamiento y filtrado colaborativo.\n",
    "     - Caracterización: extracción de características, transformación, reducción de dimensionalidad y selección.\n",
    "        - Fuente: <https://spark.apache.org/docs/latest/ml-guide.html>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e5a435",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Canalizaciones: \n",
    "    - Incluye herramientas para construir, evaluar y ajustar canalizaciones de ML.\n",
    "- Persistencia: \n",
    "    - Guarda y carga algoritmos, modelos y Pipelines.\n",
    "- Utilidades: \n",
    "    - Disponibles para álgebra lineal, estadística, manejo de datos, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee81a714",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lenguajes soportados por MLlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd30d1f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- MLlib utiliza las API de Spark e interactúa con NumPy en las bibliotecas de Python y R.\n",
    "- Puede usar cualquier fuente de datos de Hadoop (por ejemplo, HDFS, HBase o archivos locales), lo que facilita la conexión a los flujos de trabajo de Hadoop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42df12c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Desempeño de MLlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497ce4da",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Algoritmos de alta calidad, 100 veces más rápidos que MapReduce.\n",
    "- Spark sobresale en el cálculo iterativo, lo que permite que MLlib se ejecute rápidamente.\n",
    "- MLlib contiene algoritmos de alta calidad que aprovechan la iteración y pueden generar mejores resultados que las aproximaciones de un solo paso que a veces se usan en MapReduce."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e479d622",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Se puede ejecutar Spark con su modo de clúster independiente, en EC2, en Hadoop YARN, en Mesos o en Kubernetes.\n",
    "- Acceso a datos en HDFS, Apache Cassandra, Apache HBase, Apache Hive y cientos de otras fuentes de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeea3bd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Estadísticas en MLlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e338e5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Correlación:\n",
    "     - Los métodos admitidos actualmente son la correlación de Pearson y Spearman.\n",
    "- Prueba de hipótesis:\n",
    "     - spark.ml actualmente es compatible con las pruebas de independencia chi-cuadrado (*Chi-squared - χ2*) de Pearson."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66dd791",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Resumidor (*summarizer*):\n",
    "     - Proporciona estadísticas de resumen de columnas vectoriales para el *dataframe* a través de *Summarizer*. \n",
    "     - Las métricas disponibles son el máximo, el mínimo, la media, la suma, la varianza, la desviación estándar y la cantidad de valores distintos de cero por columna, así como el recuento total."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb98ca29",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Estadísticas: correlación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67d9497",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- La correlación calcula la matriz de correlación para el conjunto de datos de vectores de entrada utilizando el método especificado. \n",
    "- La salida será un *dataframe* que contiene la matriz de correlación de la columna de vectores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5b553bd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Ejemplo de correlación en Python \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Fuente:\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# https://spark.apache.org/docs/latest/ml-statistics.html\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Vectors\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Correlation\n\u001b[1;32m      8\u001b[0m data \u001b[38;5;241m=\u001b[39m [(Vectors\u001b[38;5;241m.\u001b[39msparse(\u001b[38;5;241m4\u001b[39m, [(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m), (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2.0\u001b[39m)]),),\n\u001b[1;32m      9\u001b[0m         (Vectors\u001b[38;5;241m.\u001b[39mdense([\u001b[38;5;241m4.0\u001b[39m, \u001b[38;5;241m5.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m3.0\u001b[39m]),),\n\u001b[1;32m     10\u001b[0m         (Vectors\u001b[38;5;241m.\u001b[39mdense([\u001b[38;5;241m6.0\u001b[39m, \u001b[38;5;241m7.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m8.0\u001b[39m]),),\n\u001b[1;32m     11\u001b[0m         (Vectors\u001b[38;5;241m.\u001b[39msparse(\u001b[38;5;241m4\u001b[39m, [(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m9.0\u001b[39m), (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1.0\u001b[39m)]),)]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "# Ejemplo de correlación en Python \n",
    "# Fuente:\n",
    "# https://spark.apache.org/docs/latest/ml-statistics.html\n",
    "\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.stat import Correlation\n",
    "\n",
    "data = [(Vectors.sparse(4, [(0, 1.0), (3, -2.0)]),),\n",
    "        (Vectors.dense([4.0, 5.0, 0.0, 3.0]),),\n",
    "        (Vectors.dense([6.0, 7.0, 0.0, 8.0]),),\n",
    "        (Vectors.sparse(4, [(0, 9.0), (3, 1.0)]),)]\n",
    "\n",
    "df = spark.createDataFrame(data, [\"features\"])\n",
    "\n",
    "r1 = Correlation.corr(df, \"features\").head()\n",
    "print(\"Pearson correlation matrix:\\n\" + str(r1[0]))\n",
    "\n",
    "r2 = Correlation.corr(df, \"features\", \"spearman\").head()\n",
    "print(\"Spearman correlation matrix:\\n\" + str(r2[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675198df",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- El código fuente del ejemplo completo se encuentra en *examples/src/main/python/ml/correlation_example.py* en el repositorio de Spark. \n",
    "- Fuente: <https://spark.apache.org/docs/latest/ml-guide.html>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433fb9e2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tácticas adversarias en ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e9fb52",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Adversarial Machine Learning Threat Matrix es un framework abierto centrado en la industria que ayuda a los analistas de seguridad a detectar, responder y remediar amenazas contra sistemas de ML. \n",
    "- Recientemente este framework se ha ampliado conviertiéndose en MITRE ATLAS, *Adversarial Threat Landscape for Artificial-Intelligence Systems*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bedc0f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- MITRE ATLAS, Adversarial Threat Landscape for Artificial-Intelligence Systems, es una base de conocimiento de tácticas adversarias, técnicas y estudios de casos para sistemas de aprendizaje automático (ML) basados en observaciones del mundo real, demostraciones de equipos rojos y grupos de seguridad de ML, y el estado de lo posible a partir de la investigación académica. \n",
    "- ATLAS sigue el modelo del marco MITRE ATT&CK® y sus tácticas y técnicas son complementarias a las de ATT&CK.\n",
    "    - Extraído de: <https://atlas.mitre.org/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fccf0c1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Estas tácticas adversarias pueden ser:\n",
    "    - Hacer que el sistema ML aprenda algo incorrecto (envenenamiento de datos),\n",
    "    - Hacer algo incorrecto (ataques de evasión), o\n",
    "    - Revelar lo incorrecto (inversión del modelo)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8098436",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Extraído de: [SEI](https://insights.sei.cmu.edu/cert/2020/10/adversarial-ml-threat-matrix-adversarial-tactics-techniques-and-common-knowledge-of-machine-learning.html).\n",
    "- Repositorio Github: \n",
    "- <https://github.com/mitre/advmlthreatmatrix>. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ef350c-6edc-4be7-8647-454495261cb4",
   "metadata": {},
   "source": [
    "## Caldera + Atlas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb7ed67-7161-4710-816b-369617220840",
   "metadata": {},
   "source": [
    "- Caldera + Atlas es una solución que une varios proyectos y los plugins de MITRE ATLAS™ en la imagen de Docker MITRE CALDERA™.\n",
    "- Esta solución facilita la emulación de adversarios y red-teaming en sistemas de machine learning - ML.\n",
    "- Provee además muestras de servicios y ambientes de ML para testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85663564-abfd-44ab-b33e-ea500339a0de",
   "metadata": {},
   "source": [
    "- Sus componentes son:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e9b9de-7eec-4a7f-b385-be7c67cc77a4",
   "metadata": {},
   "source": [
    "- CALDERA: una plataforma de ciberseguridad diseñada para automatizar facilmente la emulación de adversarios, asistencia a *red teams*,  manuales y automatización de respuesta a incidentes.\n",
    "- MITRE ATLAS (*The Adversarial Threat Landscape for AI Systems*): la base de datos de conocimiento sobre tácticas, técnicas y procedimientos del adversario dirigidos a sistemas de aprendizaje automático - ML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65200b4d-6c59-4e3a-8124-a5fc45ac8728",
   "metadata": {},
   "source": [
    "- ATLAS CALDERA Plugins:\n",
    "    - Almanac: Agrega el *ATLAS Navigator* a CALDERA.\n",
    "    - Arsenal: Implementa las técnicas de ATLAS en CALDERA y provee muestras de adversarios de CALDERA que apuntan a sistemas ML.\n",
    "    - ML-Vulhub: Colección de scripts para instanciar servicios y modelar ambientes ML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a63a931-6927-4faf-a6e2-20593b4cab11",
   "metadata": {},
   "source": [
    "- Fuente: <https://github.com/mitre-atlas/caldera-atlas>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b17935",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tutorial MLlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556db67c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Práctica: Aplicaciones de ML en datasets.\n",
    "- <https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb>.\n",
    "- <https://towardsdatascience.com/machine-learning-with-spark-f1dbc1363986>.\n",
    "- <https://sparkbyexamples.com/>."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}